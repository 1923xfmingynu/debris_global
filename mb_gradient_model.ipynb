{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "Compute debris thickness through sub-debris and temperature inversion methods\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from scipy import ndimage\n",
    "# from scipy.optimize import curve_fit\n",
    "from scipy.optimize import minimize\n",
    "# from scipy.stats import median_absolute_deviation\n",
    "import xarray as xr\n",
    "\n",
    "import debrisglobal.globaldebris_input as debris_prms\n",
    "import class_climate_debris\n",
    "\n",
    "\n",
    "# debug=True\n",
    "\n",
    "# Degree-day factor of clean ice (m w.e. d-1 degC-1)\n",
    "output_fp = debris_prms.output_fp + 'mb_grad_model/'\n",
    "if not os.path.exists(output_fp):\n",
    "    os.makedirs(output_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_yrfrac_to_yyyymm(date_yrfrac):\n",
    "    if int(date_yrfrac)%4 == 0:\n",
    "        doy = date_yrfrac%1*366\n",
    "    else:\n",
    "        doy = date_yrfrac%1*365\n",
    "    return datetime.strptime(str(int(date_yrfrac)) + '-' + str(int(doy)),'%Y-%j').date().strftime('%Y-%m')\n",
    "\n",
    "def create_datestable(startdate, enddate):\n",
    "    \"\"\"\n",
    "    Create table of year, month, day, water year, season and number of days in the month.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    startdate, enddate : str\n",
    "        start and end data in string format ('YYYY-MM')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dates_table : pd.DataFrame\n",
    "        table where each row is a timestep and each column is attributes (date, year) of that timestep\n",
    "    \"\"\"\n",
    "    # Generate dates_table using date_range function\n",
    "    # Automatically generate dates from start date to end data using a monthly frequency (MS), which generates\n",
    "    # monthly data using the 1st of each month\n",
    "    dates_table = pd.DataFrame({'date' : pd.date_range(startdate, enddate, freq='MS')})\n",
    "    # Select attributes of DateTimeIndex (dt.year, dt.month, and dt.daysinmonth)\n",
    "    dates_table['year'] = dates_table['date'].dt.year\n",
    "    dates_table['month'] = dates_table['date'].dt.month\n",
    "    dates_table['daysinmonth'] = dates_table['date'].dt.daysinmonth\n",
    "    dates_table['timestep'] = np.arange(len(dates_table['date']))\n",
    "    # Set date as index\n",
    "    dates_table.set_index('timestep', inplace=True)\n",
    "    return dates_table\n",
    "\n",
    "\n",
    "def annualweightedmean_array(var, dates_table):\n",
    "    \"\"\" Calculate annual mean of variable according to the timestep \"\"\"        \n",
    "    dayspermonth = dates_table['daysinmonth'].values.reshape(-1,12)\n",
    "    #  creates matrix (rows-years, columns-months) of the number of days per month\n",
    "    daysperyear = dayspermonth.sum(axis=1)\n",
    "    #  creates an array of the days per year (includes leap years)\n",
    "    weights = (dayspermonth / daysperyear[:,np.newaxis]).reshape(-1)\n",
    "    #  computes weights for each element, then reshapes it from matrix (rows-years, columns-months) to an array, \n",
    "    #  where each column (each monthly timestep) is the weight given to that specific month\n",
    "    var_annual = (var*weights[np.newaxis,:]).reshape(-1,12).sum(axis=1).reshape(-1,daysperyear.shape[0])\n",
    "    #  computes matrix (rows - bins, columns - year) of weighted average for each year\n",
    "    #  explanation: var*weights[np.newaxis,:] multiplies each element by its corresponding weight; .reshape(-1,12) \n",
    "    #    reshapes the matrix to only have 12 columns (1 year), so the size is (rows*cols/12, 12); .sum(axis=1) \n",
    "    #    takes the sum of each year; .reshape(-1,daysperyear.shape[0]) reshapes the matrix back to the proper \n",
    "    #    structure (rows - bins, columns - year)\n",
    "    # If averaging a single year, then reshape so it returns a 1d array\n",
    "    if var_annual.shape[1] == 1:\n",
    "        var_annual = var_annual.reshape(var_annual.shape[0])\n",
    "    return var_annual\n",
    "\n",
    "\n",
    "def calc_mb_mwea(bin_elev, glacier_gcm_prec, glacier_gcm_temp, glacier_gcm_lr, glacier_gcm_elev, dates_table, \n",
    "                 prec_factor=1, temp_change=0, ddf_ice=0.006, ddf_snow=None):\n",
    "    \"\"\" Climatic mass balance (accumulation + refreeze - melt) according to PyGEM \"\"\"\n",
    "    \n",
    "    # Degree-day factor\n",
    "    if ddf_snow is not None:\n",
    "        ddf = ddf_snow\n",
    "    else:\n",
    "        ddf = ddf_ice\n",
    "    \n",
    "    # Temperature based on lapse rate\n",
    "    bin_gcm_temp = glacier_gcm_temp + glacier_gcm_lr * (bin_elev - glacier_gcm_elev) + temp_change\n",
    "    \n",
    "    # Accumulation\n",
    "    bin_snow = prec_factor * glacier_gcm_prec.copy()\n",
    "    bin_snow[bin_gcm_temp > debris_prms.Tsnow_threshold] = 0\n",
    "    bin_snow[bin_snow < debris_prms.snow_min] = 0\n",
    "    bin_acc_mwea = bin_snow.sum() / 12\n",
    "    \n",
    "    # Melt (clean ice)\n",
    "    # Monthly temperature superimposed with daily temperature variability\n",
    "    # daily temperature variation in each bin for the monthly timestep\n",
    "    melt_total = 0\n",
    "    np.random.seed(0)\n",
    "    for step, dayspermonth in enumerate(dates_table['daysinmonth'].values):\n",
    "        bin_tempstd_daily = (np.random.normal(loc=0, scale=glacier_gcm_tempstd[step], size=dayspermonth)\n",
    "                             .reshape(1,dayspermonth))\n",
    "        # daily temperature in each bin for the monthly timestep\n",
    "        bin_temp_daily = bin_gcm_temp[step] + bin_tempstd_daily\n",
    "        # remove negative values\n",
    "        bin_temp_daily[bin_temp_daily < 0] = 0\n",
    "        # Melt\n",
    "        melt_month = bin_temp_daily.sum() * ddf_ice\n",
    "        melt_total += melt_month\n",
    "    bin_melt_mwea = melt_total / 12    \n",
    "    \n",
    "    # Refreeze based on annual air temperature (Woodward etal. 1997)\n",
    "    #  R(m) = (-0.69 * Tair + 0.0096) * 1 m / 100 cm\n",
    "    if dates_table.shape[0]%12 > 0:\n",
    "        dates_table_cropped = dates_table.loc[0:dates_table.shape[0]-1-dates_table.shape[0]%12,:]\n",
    "        bin_gcm_temp_cropped = bin_gcm_temp[0:dates_table.shape[0]-dates_table.shape[0]%12]\n",
    "    else:\n",
    "        dates_table_cropped = dates_table\n",
    "        bin_gcm_temp_cropped = bin_gcm_temp\n",
    "    bin_temp_annual = annualweightedmean_array(bin_gcm_temp_cropped, dates_table_cropped)\n",
    "    bin_refreezepotential_annual = (-0.69 * bin_temp_annual + 0.0096) * 1/100\n",
    "    # Remove negative refreezing values\n",
    "    bin_refreezepotential_annual[bin_refreezepotential_annual < 0] = 0\n",
    "    bin_refreeze_mwea = bin_refreezepotential_annual.mean()\n",
    "    if bin_refreeze_mwea > bin_melt_mwea:\n",
    "        bin_refreeze_mwea = bin_melt_mwea\n",
    "        \n",
    "    # Mass balance (mwea)\n",
    "    bin_mb_mwea = bin_acc_mwea + bin_refreeze_mwea - bin_melt_mwea \n",
    "    \n",
    "    return bin_mb_mwea\n",
    "\n",
    "\n",
    "def calc_mbclim_ela(elev_bins, zmin_mb_mwea, zmax_mb_mwea, z_ela, mf_values):\n",
    "    mbclim_grad_mwea = np.zeros(elev_bins.shape)\n",
    "    elev_ltzmed_idx = np.where(elev_bins < z_ela)[0]\n",
    "    mbclim_grad_mwea[elev_ltzmed_idx] = (\n",
    "        -1*zmin_mb_mwea * (elev_bins[elev_ltzmed_idx] - z_ela) / (z_ela - zmin))\n",
    "    elev_gtzmed_idx = np.where(elev_bins > z_ela)[0]\n",
    "    mbclim_grad_mwea[elev_gtzmed_idx] = zmax_mb_mwea * (elev_bins[elev_gtzmed_idx] - z_ela) / (zmax - z_ela)\n",
    "    return mbclim_grad_mwea\n",
    "\n",
    "\n",
    "def weighted_percentile(sorted_list, weights, percentile):\n",
    "    \"\"\"\n",
    "    Calculate weighted percentile of a sorted list\n",
    "    \"\"\"\n",
    "    weights_cumsum_norm_high = np.cumsum(weights) / np.sum(weights)\n",
    "#     print(weights_cumsum_norm_high)\n",
    "    weights_norm = weights / np.sum(weights)\n",
    "    weights_cumsum_norm_low = weights_cumsum_norm_high - weights_norm\n",
    "#     print(weights_cumsum_norm_low)\n",
    "    \n",
    "    percentile_idx_high = np.where(weights_cumsum_norm_high >= percentile)[0][0]\n",
    "#     print(percentile_idx_high)\n",
    "    percentile_idx_low = np.where(weights_cumsum_norm_low <= percentile)[0][-1]\n",
    "#     print(percentile_idx_low)\n",
    "    \n",
    "    if percentile_idx_low == percentile_idx_high:\n",
    "        value_percentile = sorted_list[percentile_idx_low]\n",
    "    else:\n",
    "        value_percentile = np.mean([sorted_list[percentile_idx_low], sorted_list[percentile_idx_high]])\n",
    "\n",
    "    return value_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8834 glaciers in region 13 are included in this model run: ['00067', '00080', '00093', '00137', '00175', '00188', '00190', '00198', '00199', '00200', '00202', '00203', '00209', '00210', '00211', '00217', '00218', '00221', '00222', '00223', '00226', '00228', '00233', '00235', '00236', '00240', '00246', '00248', '00250', '00299', '00335', '00345', '00358', '00386', '00391', '00394', '00399', '00400', '00402', '00413', '00420', '00500', '00502', '00503', '00505', '00507', '00508', '00515', '00516', '00517'] and more\n",
      "This study is focusing on 8834 glaciers in region [13]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roi_zemp_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2ba827d6a469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mmain_glac_rgi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mb_obs_mwea_std'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmb_shean_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshean_rgiid_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mb_mwea_sigma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdata_source\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'regional'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mmain_glac_rgi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mb_obs_mwea'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroi_zemp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0mmain_glac_rgi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mb_obs_mwea_std'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroi_zemp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roi_zemp_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Glaciers optimized\n",
    "overwrite = False\n",
    "# rois = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15', '16','17','18']\n",
    "rois = ['13','14','15']\n",
    "\n",
    "data_source = 'regional'\n",
    "# data_source = 'individual_glaciers'\n",
    "\n",
    "if data_source in ['individual_glaciers']:\n",
    "    mb_shean_fullfn = ('/Users/davidrounce/Documents/Dave_Rounce/HiMAT/DEMs/Shean_2019_0213/' + \n",
    "                       'hma_mb_20190215_0815_std+mean_all_filled_bolch.csv')\n",
    "    mb_shean_df = pd.read_csv(mb_shean_fullfn)\n",
    "    mb_shean_df['RGIId'] = ['RGI60-' + str(int(x)) + '.' + str(int(np.round((x - int(x)) * 1e5,0))).zfill(5) \n",
    "                            for x in mb_shean_df.RGIId.values]\n",
    "elif data_source in ['regional']:\n",
    "    roi_mbobs_dict = {'01': [-0.85, 0.19],\n",
    "                      '02': [-0.83, 0.40],\n",
    "                      '03': [-0.57, 0.80],\n",
    "                      '04': [-0.57, 0.70],\n",
    "                      '05': [-0.63, 0.21],\n",
    "                      '06': [-0.71, 0.43],\n",
    "                      '07': [-0.47, 0.23],\n",
    "                      '08': [-0.49, 0.27],\n",
    "                      '09': [-0.47, 0.37],\n",
    "                      '10': [-0.37, 0.31],\n",
    "                      '11': [-0.87, 0.07],\n",
    "                      '12': [-0.90, 0.57],\n",
    "                      '13': [-0.19, 0.15],\n",
    "                      '14': [-0.11, 0.15],\n",
    "                      '15': [-0.44, 0.15],\n",
    "                      '16': [-1.03, 0.83],\n",
    "                      '17': [-1.18, 0.38],\n",
    "                      '18': [-0.68, 1.15]}\n",
    "\n",
    "\n",
    "reg_output_cns = ['roi', 'area_km2', 'mb_obs_mwea', 'mb_obs_mwea_std', 'mb_mod_mwea', 'mb_mod_mwea_clean']\n",
    "reg_output_df = pd.DataFrame(np.zeros((len(rois),len(reg_output_cns))), columns=reg_output_cns)\n",
    "for nroi, roi in enumerate(rois):\n",
    "    \n",
    "    output_fn = roi + '_mb_grad_model_opt.csv'\n",
    "    \n",
    "    if overwrite or not os.path.exists(output_fp + output_fn):\n",
    "    \n",
    "        if roi in ['13','14','15']:\n",
    "            roi_4dict = 'HMA'\n",
    "        else:\n",
    "            roi_4dict = roi\n",
    "\n",
    "        rgiids = []\n",
    "        mb_bin_fns_whd = []\n",
    "        mb_bin_fns = []\n",
    "        # Filepaths\n",
    "        mb_bin_fp = debris_prms.output_fp + 'mb_bins/csv/_wdebris_hdts/'\n",
    "        mb_bin_fp_extrap = debris_prms.output_fp + 'mb_bins/csv/_wdebris_hdts_extrap/'\n",
    "        mb_bin_fp_all = debris_prms.output_fp + 'mb_bins_all/csv/' + roi_4dict + '/'\n",
    "        mb_bin_fp_all_nodhdt = debris_prms.output_fp + 'mb_bins_all/csv/' + roi_4dict + '/no_dhdt/'\n",
    "        \n",
    "        # Filepaths\n",
    "        mb_bin_fp = debris_prms.output_fp + 'mb_bins/csv/_wdebris_hdts/'\n",
    "        mb_bin_fp_extrap = debris_prms.output_fp + 'mb_bins/csv/_wdebris_hdts_extrap/'\n",
    "\n",
    "        # Glaciers optimized\n",
    "        mb_bin_fullfns = []\n",
    "        for i in os.listdir(mb_bin_fp):\n",
    "            if i.endswith('.csv'):\n",
    "                reg_str = str(int(i.split('.')[0])).zfill(2)\n",
    "                if reg_str == roi:\n",
    "                    mb_bin_fns_whd.append(mb_bin_fp + i)\n",
    "                    rgiids.append(i.split('_')[0])\n",
    "\n",
    "        # Glaciers extrapolated\n",
    "        for i in os.listdir(mb_bin_fp_extrap):\n",
    "            if i.endswith('_extrap.csv'):\n",
    "                reg_str = str(int(i.split('.')[0])).zfill(2)\n",
    "                if reg_str == roi:\n",
    "                    mb_bin_fns_whd.append(mb_bin_fp_extrap + i)\n",
    "                    rgiids.append(i.split('_')[0])\n",
    "\n",
    "        # Sorted files        \n",
    "        mb_bin_fns_whd = [x for _,x in sorted(zip(rgiids, mb_bin_fns_whd))]\n",
    "        rgiids = sorted(rgiids)     \n",
    "        \n",
    "        # Sorted files        \n",
    "        rgiids = sorted(rgiids)  \n",
    "        \n",
    "        rgiids_wdata = []\n",
    "        for nrgiid, rgiid in enumerate(rgiids):\n",
    "            mb_bin_fn = rgiid + '_mb_bins.csv'\n",
    "            mb_bin_fn_nodhdt = rgiid + '_bins.csv'\n",
    "            if os.path.exists(mb_bin_fp_all + mb_bin_fn):\n",
    "                mb_bin_fns.append(mb_bin_fp_all + mb_bin_fn)\n",
    "                rgiids_wdata.append(rgiid)\n",
    "            elif os.path.exists(mb_bin_fp_all_nodhdt + mb_bin_fn_nodhdt):\n",
    "                mb_bin_fns.append(mb_bin_fp_all_nodhdt + mb_bin_fn_nodhdt)\n",
    "                rgiids_wdata.append(rgiid)\n",
    "            else:\n",
    "                print(rgiid)\n",
    "\n",
    "        assert len(mb_bin_fns_whd) == len(rgiids_wdata), 'mismatch between mb_bin_fns and rgiids_wdata'\n",
    "        \n",
    "        \n",
    "        # ===== LOAD GLACIER DATA =====\n",
    "        main_glac_rgi = debris_prms.selectglaciersrgitable(rgiids_wdata)\n",
    "        main_glac_rgi['CenLon_360'] = main_glac_rgi['CenLon']\n",
    "        main_glac_rgi.loc[main_glac_rgi['CenLon_360'] < 0, 'CenLon_360'] = (\n",
    "            360 + main_glac_rgi.loc[main_glac_rgi['CenLon_360'] < 0, 'CenLon_360'])\n",
    "        main_glac_rgi['mb_bin_fullfn'] = mb_bin_fns\n",
    "        main_glac_rgi['mb_bin_fullfn_whd'] = mb_bin_fns_whd\n",
    "        \n",
    "        # Add mass balance data\n",
    "        if data_source in ['individual_glaciers']:\n",
    "            shean_rgiid_idx = [i for i, item in enumerate(list(mb_shean_df.RGIId.values)) \n",
    "                               if item in list(main_glac_rgi.RGIId.values)]\n",
    "            main_glac_rgi['mb_obs_mwea'] = mb_shean_df.loc[shean_rgiid_idx,'mb_mwea'].values\n",
    "            main_glac_rgi['mb_obs_mwea_std'] = mb_shean_df.loc[shean_rgiid_idx,'mb_mwea_sigma'].values\n",
    "        elif data_source in ['regional']:\n",
    "            main_glac_rgi['mb_obs_mwea'] = roi_mbobs_dict[roi][0]\n",
    "            main_glac_rgi['mb_obs_mwea_std'] = roi_mbobs_dict[roi][1]\n",
    "            \n",
    "        # ===== LOAD CLIMATE DATA =====\n",
    "        # Dates\n",
    "        if data_source in ['individual_glaciers']:\n",
    "            start_date = date_yrfrac_to_yyyymm(debris_prms.mb_yrfrac_dict[roi_4dict][0])\n",
    "            end_date = date_yrfrac_to_yyyymm(debris_prms.mb_yrfrac_dict[roi_4dict][1])\n",
    "            dates_table = create_datestable(start_date, end_date)\n",
    "        elif data_source in ['regional']:\n",
    "            if roi in ['13','14','15']:\n",
    "                dates_table = create_datestable('2000-06', '2018-05')\n",
    "            else:    \n",
    "                dates_table = create_datestable('2006-06', '2015-05')\n",
    "\n",
    "        # GCM\n",
    "        gcm = class_climate_debris.GCM(name='ERA5')\n",
    "        # Air temperature [degC]\n",
    "        gcm_temp, gcm_dates = gcm.importGCMvarnearestneighbor_xarray(gcm.temp_fn, gcm.temp_vn, main_glac_rgi,\n",
    "                                                                     dates_table)\n",
    "        gcm_tempstd, gcm_dates = gcm.importGCMvarnearestneighbor_xarray(gcm.tempstd_fn, gcm.tempstd_vn,\n",
    "                                                                        main_glac_rgi, dates_table)\n",
    "        # Precipitation [m]\n",
    "        gcm_prec, gcm_dates = gcm.importGCMvarnearestneighbor_xarray(gcm.prec_fn, gcm.prec_vn, main_glac_rgi,\n",
    "                                                                     dates_table)\n",
    "        # Elevation [m asl]\n",
    "        gcm_elev = gcm.importGCMfxnearestneighbor_xarray(gcm.elev_fn, gcm.elev_vn, main_glac_rgi)\n",
    "        # Lapse rate\n",
    "        gcm_lr, gcm_dates = gcm.importGCMvarnearestneighbor_xarray(gcm.lr_fn, gcm.lr_vn, main_glac_rgi, dates_table)\n",
    "        \n",
    "        \n",
    "        # ===== LOOP THROUGH THE GLACIERS ============================================================================\n",
    "        output_cns = ['rgiid', 'area_km2', 'mb_obs_mwea', 'mb_mod_mwea', 'mb_mod_mwea_clean', 'zela', 'zmed', \n",
    "                      'zmin', 'z25', 'z75', 'zmax', 'zmin_mb_mwea', 'zmax_mb_mwea', 'ela_opt_percentile', 'ddfice',\n",
    "                      'precfactor', 'tempchange']\n",
    "        output_df = pd.DataFrame(np.zeros((main_glac_rgi.shape[0], len(output_cns))), columns=output_cns)\n",
    "\n",
    "#     for batman in [0]:\n",
    "#         debug = True\n",
    "#         for nglac, glac_idx in enumerate(main_glac_rgi.index.values[36:37]):\n",
    "        debug = False\n",
    "        for nglac, glac_idx in enumerate(main_glac_rgi.index.values): \n",
    "\n",
    "            glac_str = main_glac_rgi.loc[glac_idx,'rgino_str']\n",
    "            rgiid = main_glac_rgi.loc[glac_idx,'RGIId']\n",
    "            region = glac_str.split('.')[0]\n",
    "\n",
    "            if int(region) < 10:\n",
    "                glac_str_noleadzero = str(int(glac_str.split('.')[0])) + '.' + glac_str.split('.')[1]\n",
    "            else:\n",
    "                glac_str_noleadzero = glac_str\n",
    "\n",
    "            if nglac%200 == 0:\n",
    "#             if nglac%1 == 0:\n",
    "                print(nglac, glac_str)\n",
    "\n",
    "            # Select climate data\n",
    "            glacier_gcm_elev = gcm_elev[glac_idx]\n",
    "            glacier_gcm_prec = gcm_prec[glac_idx,:]\n",
    "            glacier_gcm_temp = gcm_temp[glac_idx,:]\n",
    "            glacier_gcm_tempstd = gcm_tempstd[glac_idx,:]\n",
    "            glacier_gcm_lr = gcm_lr[glac_idx,:]\n",
    "\n",
    "            # Load bins\n",
    "            mb_df = pd.read_csv(main_glac_rgi.loc[glac_idx,'mb_bin_fullfn'])\n",
    "            mb_df.loc[:,:] = mb_df.values.astype(np.float64)\n",
    "            mb_df_whd = pd.read_csv(main_glac_rgi.loc[glac_idx,'mb_bin_fullfn_whd'])\n",
    "            mb_df_whd.loc[:,:] = mb_df_whd.values.astype(np.float64)\n",
    "            # Weighted melt factor according to debris-covered area in the bin\n",
    "            mf_values = mb_df['dc_bin_area_perc']/100 * mb_df_whd['mf_ts_mean'] + (100-mb_df['dc_bin_area_perc'])/100\n",
    "\n",
    "            # Min, max, median elevations\n",
    "            elev_bins = mb_df.bin_center_elev_m.values\n",
    "            area_bins = mb_df.z1_bin_area_valid_km2.values\n",
    "            zmin = elev_bins.min()\n",
    "            zmax = elev_bins.max()\n",
    "            zmed = weighted_percentile(elev_bins, area_bins, 0.5)\n",
    "            z25 = weighted_percentile(elev_bins, area_bins, 0.25)\n",
    "            z75 = weighted_percentile(elev_bins, area_bins, 0.75)\n",
    "\n",
    "            # Calibrate the ELA against the observation\n",
    "            mb_obs_mwea = main_glac_rgi.loc[glac_idx, 'mb_obs_mwea']\n",
    "            mb_obs_mwea_std = main_glac_rgi.loc[glac_idx, 'mb_obs_mwea_std']\n",
    "\n",
    "            if debug:\n",
    "                print('mb_obs:', np.round(mb_obs_mwea,2))\n",
    "                \n",
    "            # Bounds\n",
    "            ddfice = 0.006\n",
    "            ddfice_step = 0.005\n",
    "            ddfice_bndlow, ddfice_bndhigh = 0.0035, 0.009\n",
    "            precfactor = 1.5\n",
    "            precfactor_step = 0.25\n",
    "            precfactor_bndlow, precfactor_bndhigh = 0.8, 2\n",
    "            tc = 0\n",
    "            tc_step = 0.05\n",
    "            tc_bndlow, tc_bndhigh = -10, 10\n",
    "            # Boundaries and steps\n",
    "            zstep = 10\n",
    "            dif_mb_mwea_threshold = 0.01\n",
    "            zlimit_lower = z25\n",
    "            if zlimit_lower == zmin:\n",
    "                zlimit_lower = zmin + 10\n",
    "            continue_while_loop = True\n",
    "            nround = 0\n",
    "            dif_mb_mwea = 1e6\n",
    "            abs_dif_mb_mwea_opt = 1e6\n",
    "            ela_perc_thresholds = [40, 85]\n",
    "            while continue_while_loop:\n",
    "#                 if debug:\n",
    "#                     print('\\nRound', nround)\n",
    "                # Maximum accumulation (mwea)\n",
    "                ddfsnow = ddfice / 1.5\n",
    "                zmax_mb_mwea = calc_mb_mwea(zmax, glacier_gcm_prec, glacier_gcm_temp, glacier_gcm_lr, \n",
    "                                            glacier_gcm_elev, dates_table, prec_factor=precfactor, \n",
    "                                            temp_change=tc, ddf_snow=ddfsnow)\n",
    "            \n",
    "                # Maximum melt (mwea)\n",
    "                zmin_mb_mwea = calc_mb_mwea(zmin, glacier_gcm_prec, glacier_gcm_temp, glacier_gcm_lr, \n",
    "                                            glacier_gcm_elev, dates_table, prec_factor=precfactor, \n",
    "                                            temp_change=tc, ddf_ice=ddfice)\n",
    "    \n",
    "                if debug:\n",
    "                    print('zmax mb:', np.round(zmax_mb_mwea,2), 'zmin_mb:', np.round(zmin_mb_mwea,2))\n",
    "                \n",
    "                # Calibrate ELA\n",
    "                if nround == 0:\n",
    "                    z_list = list(np.arange(zlimit_lower, zmax+zstep/2, zstep))\n",
    "                for z_ela in z_list:\n",
    "                    # Mass balance gradient model\n",
    "                    mbclim_grad_mwea = calc_mbclim_ela(elev_bins, zmin_mb_mwea, zmax_mb_mwea, z_ela, mf_values)\n",
    "                    mbclim_grad_mwea_wmf = mbclim_grad_mwea * mf_values\n",
    "\n",
    "                    # Glacier-wide mass balance\n",
    "                    glac_mb_mwea = (mbclim_grad_mwea_wmf * area_bins).sum() / area_bins.sum()\n",
    "                    glac_mb_mwea_clean = (mbclim_grad_mwea * area_bins).sum() / area_bins.sum()\n",
    "                    dif_mb_mwea = glac_mb_mwea - mb_obs_mwea\n",
    "\n",
    "                    \n",
    "                    if nround > 0 and debug:\n",
    "                        print('z_ela:', z_ela, 'prms:', ddfice, precfactor, tc, \n",
    "                              'mb opt/mod/obs/dif:', np.round(glac_mb_mwea_opt,2), np.round(glac_mb_mwea,2), \n",
    "                              np.round(mb_obs_mwea,2), np.round(dif_mb_mwea,2))\n",
    "                \n",
    "#                 continue_while_loop = False\n",
    "\n",
    "                    # Get best value\n",
    "                    if abs(dif_mb_mwea) < abs_dif_mb_mwea_opt:\n",
    "                        z_ela_opt = z_ela\n",
    "                        ddfice_opt = ddfice\n",
    "                        pf_opt = precfactor\n",
    "                        tc_opt = tc\n",
    "                        glac_mb_mwea_opt = glac_mb_mwea\n",
    "                        glac_mb_mwea_clean_opt = glac_mb_mwea_clean\n",
    "                        dif_mb_mwea_opt = dif_mb_mwea\n",
    "                        abs_dif_mb_mwea_opt = abs(dif_mb_mwea)\n",
    "                        \n",
    "\n",
    "                    # If jump over the best value, then stop optimization and go with the minimum\n",
    "                    if -1*np.sign(dif_mb_mwea_opt) == np.sign(dif_mb_mwea):\n",
    "                        continue_while_loop = False\n",
    "\n",
    "                # Get upper and lower limits\n",
    "                if nround == 0:\n",
    "                    if z_ela_opt < zmed:\n",
    "                        z_list = list(np.arange(z25, zmed+zstep/2, zstep))\n",
    "                    else:\n",
    "                        z_list = list(np.arange(zmed, zmax+zstep/2, zstep))\n",
    "                    \n",
    "    #             if debug:\n",
    "    #                 print('\\n',z_ela_opt, ddfice, precfactor, tc, glac_mb_mwea_opt, mb_obs_mwea, abs_dif_mb_mwea_opt)\n",
    "\n",
    "                # ELA percentile\n",
    "                lt_ela_idx = np.where(elev_bins <= z_ela_opt)[0]\n",
    "                ela_opt_percentile = area_bins[lt_ela_idx].sum() / area_bins.sum() * 100\n",
    "    \n",
    "                # If optimized, then done\n",
    "                if (abs(dif_mb_mwea_opt) <= dif_mb_mwea_threshold and \n",
    "                    (ela_opt_percentile < ela_perc_thresholds[0] or ela_opt_percentile > ela_perc_thresholds[1])):\n",
    "                    continue_while_loop = False\n",
    "                # Otherwise, iterate through various ddfice, precfactors, tempchange\n",
    "                else:\n",
    "                    if dif_mb_mwea_opt > 0:\n",
    "                        # PyGEM initial calibration\n",
    "                        # Decrease kp, increase Tbias\n",
    "                        precfactor = precfactor - precfactor_step\n",
    "                        if precfactor < precfactor_bndlow:\n",
    "                            precfactor = precfactor_bndlow\n",
    "                            ddfice = ddfice + ddfice_step\n",
    "                            if ddfice > ddfice_bndhigh:\n",
    "                                ddfice = ddfice_bndhigh\n",
    "                                tc = tc + tc_step\n",
    "                        \n",
    "                        # Initial method\n",
    "#                         ddfice = ddfice + ddfice_step\n",
    "#                         if ddfice >= ddfice_bndhigh:\n",
    "#                             ddfice = ddfice_bndhigh\n",
    "#                             precfactor = precfactor - precfactor_step\n",
    "#                             if precfactor <= precfactor_bndlow:\n",
    "#                                 precfactor = precfactor_bndlow\n",
    "#                                 tc = tc + tc_step\n",
    "                    elif dif_mb_mwea_opt < 0:\n",
    "                        precfactor = precfactor + precfactor_step\n",
    "                        if precfactor > precfactor_bndhigh:\n",
    "                            precfactor = precfactor_bndhigh\n",
    "                            ddfice = ddfice - ddfice_step\n",
    "                            if ddfice < ddfice_bndlow:\n",
    "                                ddfice = ddfice_bndlow\n",
    "                                tc = tc - tc_step\n",
    "#                         ddfice = ddfice - ddfice_step\n",
    "#                         if ddfice <= ddfice_bndlow:\n",
    "#                             ddfice = ddfice_bndlow\n",
    "#                             precfactor = precfactor + precfactor_step\n",
    "#                             if precfactor >= precfactor_bndhigh:\n",
    "#                                 precfactor = precfactor_bndhigh\n",
    "#                                 tc = tc - tc_step\n",
    "\n",
    "                    if precfactor > precfactor_bndhigh:\n",
    "                        precfactor = precfactor_bndhigh\n",
    "                    if precfactor < precfactor_bndlow:\n",
    "                        precfactor = precfactor_bndlow\n",
    "                    if tc > tc_bndhigh:\n",
    "                        tc = tc_bndhigh\n",
    "                        print(nglac, glac_str, 'HERE - hit upper bound')\n",
    "                        continue_while_loop = False\n",
    "                    if tc < tc_bndlow:\n",
    "                        tc = tc_bndlow\n",
    "                        print(nglac, glac_str, 'HERE - hit lower bound')\n",
    "                        continue_while_loop = False\n",
    "\n",
    "                nround += 1\n",
    "\n",
    "            if debug:\n",
    "                print('\\n',z_ela_opt, ddfice_opt, pf_opt, tc_opt, glac_mb_mwea_opt)\n",
    "\n",
    "            \n",
    "            if debug:\n",
    "                print('  mb_obs (mwea):', np.round(mb_obs_mwea,2), '+/-', np.round(mb_obs_mwea_std,2))\n",
    "                print('  z_ela opt:', np.round(z_ela_opt), '(' + str(np.round(ela_opt_percentile,2)) + '%)', \n",
    "                      'z25, zmed, z75:', z25, zmed, z75)\n",
    "                print('  mb_mod (mwea):', np.round(glac_mb_mwea_opt,2), 'mb_mod (clean):', \n",
    "                      np.round(glac_mb_mwea_clean_opt,2))\n",
    "            \n",
    "            \n",
    "            if dif_mb_mwea_opt > mb_obs_mwea_std:\n",
    "                print('  ' + glac_str + ' BAD FIT')\n",
    "                error_fp = output_fp + 'errors/poor_fit/' + roi + '/'\n",
    "                if not os.path.exists(error_fp):\n",
    "                    os.makedirs(error_fp)\n",
    "                with open(error_fp + glac_str + \"-difference_gt_zempstd.txt\", \"w\") as text_file:\n",
    "                    text_file.write(glac_str + ' modeled mass balance difference off by more than zempstd')\n",
    "            if z_ela_opt == z25:\n",
    "#                 print('  ' + glac_str + ' HAS ISSUE - z25')\n",
    "                error_fp = output_fp + 'errors/z25/' + roi + '/'\n",
    "                if not os.path.exists(error_fp):\n",
    "                    os.makedirs(error_fp)\n",
    "                with open(error_fp + glac_str + \"-poor_mbgrad_model-z25.txt\", \"w\") as text_file:\n",
    "                    text_file.write(glac_str + ' bad fit for mb grad model; z_ela_opt equals z25')\n",
    "            if z_ela_opt == zmax:\n",
    "#                 print('  ' + glac_str + ' HAS ISSUE - zmax')\n",
    "                error_fp = output_fp + 'errors/zmax/' + roi + '/'\n",
    "                if not os.path.exists(error_fp):\n",
    "                    os.makedirs(error_fp)\n",
    "                with open(error_fp + glac_str + \"-poor_mbgrad_model-zmax.txt\", \"w\") as text_file:\n",
    "                    text_file.write(glac_str + ' bad fit for mb grad model; z_ela_opt equals zmax')\n",
    "\n",
    "            output_df.loc[glac_idx,:] = [glac_str, area_bins.sum(), mb_obs_mwea, glac_mb_mwea_opt, \n",
    "                                         glac_mb_mwea_clean_opt, z_ela_opt, zmed, zmin, z25, z75, zmax, \n",
    "                                         zmin_mb_mwea, zmax_mb_mwea, ela_opt_percentile, ddfice, precfactor, tc]\n",
    "        output_df.to_csv(output_fp + output_fn, index=False)\n",
    "\n",
    "    else:\n",
    "        output_df = pd.read_csv(output_fp + output_fn)\n",
    "    \n",
    "    # Ensure RGIIds are correctly formatted\n",
    "    output_df['rgiid'] = ['RGI60-' + str(x).split('.')[0].zfill(2) + '.' + \n",
    "                          str(int(np.round((np.float(x) - int(np.float(x))) * 1e5,0))).zfill(5) \n",
    "                          for x in output_df.rgiid.values]\n",
    "\n",
    "    main_glac_rgi_all = debris_prms.selectglaciersrgitable(rgi_regionsO1=[roi], rgi_regionsO2='all',\n",
    "                                                           rgi_glac_number='all')\n",
    "    \n",
    "    # Add the observations for the glaciers not modeled\n",
    "    if data_source in ['individual_glaciers']:\n",
    "        # Calculate the change in specific mass balance over the region\n",
    "        mb_shean_df['roi'] = [x.split('-')[1].split('.')[0] for x in mb_shean_df.RGIId.values]\n",
    "        mb_shean_df_roi = mb_shean_df[mb_shean_df.roi == roi]\n",
    "        mb_shean_df_roi.reset_index(inplace=True, drop=True)\n",
    "        reg_mb_obs_mwea = (mb_shean_df_roi.mb_mwea * mb_shean_df_roi.area_m2).sum() / mb_shean_df_roi.area_m2.sum()\n",
    "        reg_mb_obs_mwea_std = 0.15\n",
    "        \n",
    "        # Dictionary of glacier-wide mass balance for every glacier\n",
    "        mb_mwea_debris_dict = dict(zip(mb_shean_df.RGIId.values, mb_shean_df.mb_mwea.values))\n",
    "        mb_mwea_clean_dict = dict(zip(mb_shean_df.RGIId.values, mb_shean_df.mb_mwea.values))\n",
    "\n",
    "    elif data_source in ['regional']:\n",
    "        reg_mb_obs_mwea = roi_mbobs_dict[roi][0]\n",
    "        reg_mb_obs_mwea_std = roi_mbobs_dict[roi][1]\n",
    "        main_glac_rgi_all['mb_obs'] = reg_mb_obs_mwea\n",
    "        mb_mwea_debris_dict = dict(zip(main_glac_rgi_all.RGGIId.values, main_glac_rgi_all.mb_obs.values))\n",
    "        mb_mwea_clean_dict = dict(zip(main_glac_rgi_all.RGGIId.values, main_glac_rgi_all.mb_obs.values))\n",
    "        \n",
    "    # Update dictionaries for modeled debris-covered glaciers\n",
    "    mb_mwea_debris_dict_output = dict(zip(output_df.rgiid.values, output_df.mb_mod_mwea.values))\n",
    "    mb_mwea_clean_dict_output = dict(zip(output_df.rgiid.values, output_df.mb_mod_mwea_clean.values))\n",
    "    \n",
    "    mb_mwea_debris_dict.update(mb_mwea_debris_dict_output)\n",
    "    mb_mwea_clean_dict.update(mb_mwea_clean_dict_output)\n",
    "    \n",
    "    main_glac_rgi_all['mb_mwea'] = main_glac_rgi_all.RGIId.map(mb_mwea_debris_dict)\n",
    "    main_glac_rgi_all['mb_mwea_clean'] = main_glac_rgi_all.RGIId.map(mb_mwea_clean_dict)\n",
    "\n",
    "    reg_mb_mwea_wdebris = (main_glac_rgi_all.Area * main_glac_rgi_all.mb_mwea).sum() / main_glac_rgi_all.Area.sum()\n",
    "    reg_mb_mwea_nodebris = ((main_glac_rgi_all.Area * main_glac_rgi_all.mb_mwea_clean).sum() / \n",
    "                            main_glac_rgi_all.Area.sum())\n",
    "\n",
    "    assert np.abs(reg_mb_mwea_wdebris - reg_mb_obs_mwea) < reg_mb_obs_mwea_std, 'Reg mass balance outside uncertainty'\n",
    "\n",
    "    print('\\nreg mb obs (mwea):', np.round(reg_mb_obs_mwea,2))\n",
    "    print('reg mb mod (mwea), debris:', np.round(reg_mb_mwea_wdebris,2), 'vs clean:', np.round(reg_mb_mwea_nodebris,2),'\\n')\n",
    "    reg_output_df.loc[nroi,:] = [roi, main_glac_rgi_all.Area.sum(), reg_mb_obs_mwea, reg_mb_obs_mwea_std, \n",
    "                                 reg_mb_mwea_wdebris, reg_mb_mwea_nodebris]\n",
    "    \n",
    "# # Export regional data\n",
    "# all_area = reg_output_df.area_km2.sum()\n",
    "# all_zemp_mean = (reg_output_df.area_km2 * reg_output_df.zemp_mean).sum() / reg_output_df.area_km2.sum()\n",
    "# all_zemp_std = 0.20\n",
    "# all_mb_mwea = (reg_output_df.area_km2 * reg_output_df.mb_mwea).sum() / reg_output_df.area_km2.sum()\n",
    "# all_mb_mwea_clean = (reg_output_df.area_km2 * reg_output_df.mb_mwea_clean).sum() / reg_output_df.area_km2.sum()\n",
    "\n",
    "# all_df = pd.DataFrame(np.zeros((1,len(reg_output_cns))), columns=reg_output_cns)\n",
    "# all_df.loc[0,:] = ['all', all_area, all_zemp_mean, all_zemp_std, all_mb_mwea, all_mb_mwea_clean]\n",
    "\n",
    "# all_output_df = pd.concat([reg_output_df, all_df], axis=0)\n",
    "# all_output_df['mb_clean_dif'] = all_output_df.mb_mwea - all_output_df.mb_mwea_clean\n",
    "# all_output_df_fn = 'reg_mbgrad_impact.csv'\n",
    "# all_output_df.to_csv(output_fp + all_output_df_fn, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DONE!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\nDONE!\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(main_glac_rgi.rgino_str == '15.00058')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Glaciers optimized\n",
    "# rois = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15', '16','17','18']\n",
    "rois = ['13','14','15']\n",
    "\n",
    "for nroi, roi in enumerate(rois):\n",
    "    \n",
    "    output_fn = roi + '_mb_grad_model_opt.csv'\n",
    "    output_df = pd.read_csv(output_fp + output_fn)\n",
    "    output_df['rgiid'] = [str(x).split('.')[0].zfill(2) + '.' + str(x).split('.')[1] \n",
    "                          for x in output_df.rgiid.values]\n",
    "    \n",
    "    # ===== HISTOGRAM: ELA ======\n",
    "    ax = output_df['ela_opt_percentile'].plot.hist(bins=20, alpha=0.5)\n",
    "    fig = ax.get_figure()\n",
    "    hist_fp = output_fp + 'hist/'\n",
    "    if not os.path.exists(hist_fp):\n",
    "        os.makedirs(hist_fp)\n",
    "    fig.savefig(hist_fp + roi + '_ela_opt_percentile_hist.png')\n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debris_thickness_global]",
   "language": "python",
   "name": "conda-env-debris_thickness_global-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
