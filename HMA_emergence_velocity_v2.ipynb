{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate a 3-panel plot for input arrays\n",
    "def plot_array(dem, clim=None, titles=None, cmap='inferno', label=None, overlay=None, fn=None):\n",
    "    fig, ax = plt.subplots(1,1, sharex=True, sharey=True, figsize=(10,5))\n",
    "    alpha = 1.0\n",
    "    #Gray background\n",
    "    ax.set_facecolor('0.5')\n",
    "    #Force aspect ratio to match images\n",
    "    ax.set(aspect='equal')\n",
    "    #Turn off axes labels/ticks\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if titles is not None:\n",
    "        ax.set_title(titles[0])\n",
    "    #Plot background shaded relief map\n",
    "    if overlay is not None:\n",
    "        alpha = 0.7\n",
    "        ax.imshow(overlay, cmap='gray', clim=(1,255))\n",
    "    #Plot each array\n",
    "    im_list = [ax.imshow(dem, clim=clim, cmap=cmap, alpha=alpha)]\n",
    "    fig.tight_layout()\n",
    "    fig.colorbar(im_list[0], label=label, extend='both', shrink=0.5)\n",
    "    if fn is not None:\n",
    "        fig.savefig(fn, bbox_inches='tight', pad_inches=0, dpi=150)\n",
    "        \n",
    "def selectglaciersrgitable(glac_no=None,\n",
    "                           rgi_regionsO1=None,\n",
    "                           rgi_regionsO2=None,\n",
    "                           rgi_glac_number=None,\n",
    "#                            rgi_fp=input.rgi_fp,\n",
    "                           rgi_fp = '/Users/davidrounce/Documents/Dave_Rounce/HiMAT/RGI/rgi60/00_rgi60_attribs/',\n",
    "                           rgi_cols_drop=['GLIMSId','BgnDate','EndDate','Status','Connect','Linkages','Name'],\n",
    "                           rgi_O1Id_colname='glacno',\n",
    "                           rgi_glacno_float_colname='RGIId_float',\n",
    "                           indexname='GlacNo'):\n",
    "    \"\"\"\n",
    "    Select all glaciers to be used in the model run according to the regions and glacier numbers defined by the RGI\n",
    "    glacier inventory. This function returns the rgi table associated with all of these glaciers.\n",
    "\n",
    "    glac_no : list of strings\n",
    "        list of strings of RGI glacier numbers (e.g., ['1.00001', '13.00001'])\n",
    "    rgi_regionsO1 : list of integers\n",
    "        list of integers of RGI order 1 regions (e.g., [1, 13])\n",
    "    rgi_regionsO2 : list of integers or 'all'\n",
    "        list of integers of RGI order 2 regions or simply 'all' for all the order 2 regions\n",
    "    rgi_glac_number : list of strings\n",
    "        list of RGI glacier numbers without the region (e.g., ['00001', '00002'])\n",
    "\n",
    "    Output: Pandas DataFrame of the glacier statistics for each glacier in the model run\n",
    "    (rows = GlacNo, columns = glacier statistics)\n",
    "    \"\"\"\n",
    "    if glac_no is not None:\n",
    "        glac_no_byregion = {}\n",
    "        rgi_regionsO1 = [int(i.split('.')[0]) for i in glac_no]\n",
    "        rgi_regionsO1 = list(set(rgi_regionsO1))\n",
    "        for region in rgi_regionsO1:\n",
    "            glac_no_byregion[region] = []\n",
    "        for i in glac_no:\n",
    "            region = i.split('.')[0]\n",
    "            glac_no_only = i.split('.')[1]\n",
    "            glac_no_byregion[int(region)].append(glac_no_only)\n",
    "\n",
    "        for region in rgi_regionsO1:\n",
    "            glac_no_byregion[region] = sorted(glac_no_byregion[region])\n",
    "\n",
    "    # Create an empty dataframe\n",
    "    rgi_regionsO1 = sorted(rgi_regionsO1)\n",
    "    glacier_table = pd.DataFrame()\n",
    "    for region in rgi_regionsO1:\n",
    "\n",
    "        if glac_no is not None:\n",
    "            rgi_glac_number = glac_no_byregion[region]\n",
    "\n",
    "#        if len(rgi_glac_number) < 50:\n",
    "\n",
    "        for i in os.listdir(rgi_fp):\n",
    "            if i.startswith(str(region).zfill(2)) and i.endswith('.csv'):\n",
    "                rgi_fn = i\n",
    "        try:\n",
    "            csv_regionO1 = pd.read_csv(rgi_fp + rgi_fn)\n",
    "        except:\n",
    "            csv_regionO1 = pd.read_csv(rgi_fp + rgi_fn, encoding='latin1')\n",
    "        \n",
    "        # Populate glacer_table with the glaciers of interest\n",
    "        if rgi_regionsO2 == 'all' and rgi_glac_number == 'all':\n",
    "            print(\"All glaciers within region(s) %s are included in this model run.\" % (region))\n",
    "            if glacier_table.empty:\n",
    "                glacier_table = csv_regionO1\n",
    "            else:\n",
    "                glacier_table = pd.concat([glacier_table, csv_regionO1], axis=0)\n",
    "        elif rgi_regionsO2 != 'all' and rgi_glac_number == 'all':\n",
    "            print(\"All glaciers within subregion(s) %s in region %s are included in this model run.\" %\n",
    "                  (rgi_regionsO2, region))\n",
    "            for regionO2 in rgi_regionsO2:\n",
    "                if glacier_table.empty:\n",
    "                    glacier_table = csv_regionO1.loc[csv_regionO1['O2Region'] == regionO2]\n",
    "                else:\n",
    "                    glacier_table = (pd.concat([glacier_table, csv_regionO1.loc[csv_regionO1['O2Region'] ==\n",
    "                                                                                regionO2]], axis=0))\n",
    "        else:\n",
    "            if len(rgi_glac_number) < 20:\n",
    "                print(\"%s glaciers in region %s are included in this model run: %s\" % (len(rgi_glac_number), region,\n",
    "                                                                                       rgi_glac_number))\n",
    "            else:\n",
    "                print(\"%s glaciers in region %s are included in this model run: %s and more\" %\n",
    "                      (len(rgi_glac_number), region, rgi_glac_number[0:50]))\n",
    "                \n",
    "            rgiid_subset = ['RGI60-' + str(region).zfill(2) + '.' + x for x in rgi_glac_number] \n",
    "            rgiid_all = list(csv_regionO1.RGIId.values)\n",
    "            rgi_idx = [rgiid_all.index(x) for x in rgiid_subset]\n",
    "            if glacier_table.empty:\n",
    "                glacier_table = csv_regionO1.loc[rgi_idx]\n",
    "            else:\n",
    "                glacier_table = (pd.concat([glacier_table, csv_regionO1.loc[rgi_idx]],\n",
    "                                           axis=0))\n",
    "                    \n",
    "    glacier_table = glacier_table.copy()\n",
    "    # reset the index so that it is in sequential order (0, 1, 2, etc.)\n",
    "    glacier_table.reset_index(inplace=True)\n",
    "    # change old index to 'O1Index' to be easier to recall what it is\n",
    "    glacier_table.rename(columns={'index': 'O1Index'}, inplace=True)\n",
    "    # Record the reference date\n",
    "    glacier_table['RefDate'] = glacier_table['BgnDate']\n",
    "    # if there is an end date, then roughly average the year\n",
    "    enddate_idx = glacier_table.loc[(glacier_table['EndDate'] > 0), 'EndDate'].index.values\n",
    "    glacier_table.loc[enddate_idx,'RefDate'] = (\n",
    "            np.mean((glacier_table.loc[enddate_idx,['BgnDate', 'EndDate']].values / 10**4).astype(int),\n",
    "                    axis=1).astype(int) * 10**4 + 9999)\n",
    "    # drop columns of data that is not being used\n",
    "    glacier_table.drop(rgi_cols_drop, axis=1, inplace=True)\n",
    "    # add column with the O1 glacier numbers\n",
    "    glacier_table[rgi_O1Id_colname] = (\n",
    "            glacier_table['RGIId'].str.split('.').apply(pd.Series).loc[:,1].astype(int))\n",
    "    glacier_table['rgino_str'] = [x.split('-')[1] for x in glacier_table.RGIId.values]\n",
    "    glacier_table[rgi_glacno_float_colname] = (np.array([np.str.split(glacier_table['RGIId'][x],'-')[1]\n",
    "                                                    for x in range(glacier_table.shape[0])]).astype(float))\n",
    "    # set index name\n",
    "    glacier_table.index.name = indexname\n",
    "\n",
    "    print(\"This study is focusing on %s glaciers in region %s\" % (glacier_table.shape[0], rgi_regionsO1))\n",
    "\n",
    "    return glacier_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "Compute debris thickness through sub-debris and temperature inversion methods\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "from pygeotools.lib import malib, warplib, geolib, iolib, timelib\n",
    "# from imview.lib import pltlib\n",
    "\n",
    "import globaldebris_input as input\n",
    "\n",
    "# #INPUT\n",
    "# topdir='/Users/davidrounce/Documents/Dave_Rounce/HiMAT/DEMs/'\n",
    "# #Output directory\n",
    "# outdir = topdir + 'Shean_2019_0213/mb_combined_20190213_nmad_bins/'\n",
    "# outdir_fig = outdir + '/figures/'\n",
    "# outdir_csv = outdir + '/csv'\n",
    "\n",
    "# #RGI inventory\n",
    "# glac_str = '15.03473' # Ngozumpa\n",
    "\n",
    "# roi = 'HMA'\n",
    "\n",
    "# met_sample_fullfn = ('/Users/davidrounce/Documents/Dave_Rounce/DebrisGlaciers_WG/Melt_Intercomparison/' + \n",
    "#                      'rounce_model/hma_data/' + roi + '_ERA5-metdata_2000_2018-z.nc')\n",
    "# debris_elevstats_fullfn = ('/Users/davidrounce/Documents/Dave_Rounce/DebrisGlaciers_WG/Melt_Intercomparison/' +\n",
    "#                            'rounce_model/hma_data/' + roi + '_debris_elevstats.nc')\n",
    "\n",
    "# # glac_shp_fn_dict = {'13':topdir + '../RGI/rgi60/13_rgi60_CentralAsia/13_rgi60_CentralAsia.shp',\n",
    "# #                     '14':topdir + '../RGI/rgi60/14_rgi60_SouthAsiaWest/14_rgi60_SouthAsiaWest.shp',\n",
    "# #                     '15':topdir + '../RGI/rgi60/15_rgi60_SouthAsiaEast/15_rgi60_SouthAsiaEast.shp'}\n",
    "\n",
    "# # glac_shp_fn = glac_shp_fn_dict[region]\n",
    "# # glacfeat_fn = outdir + 'glacfeat_list.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8053\n",
      "4182 glaciers in region 13 are included in this model run: ['00062', '00093', '00130', '00135', '00137', '00140', '00147', '00175', '00181', '00183', '00203', '00210', '00277', '00358', '00382', '00386', '00391', '00394', '00400', '00401', '00403', '00439', '00440', '00441', '00465', '00561', '00585', '00594', '00604', '00606', '00611', '00628', '00643', '00693', '00713', '00750', '00751', '00757', '00761', '00763', '00777', '00788', '00809', '00830', '00834', '00838', '00880', '00884', '00885', '00891'] and more\n"
     ]
    }
   ],
   "source": [
    "rgiid_list = []\n",
    "rgiid_fn_list = []\n",
    "for i in os.listdir(input.mb_binned_fp):\n",
    "    if i.endswith('mb_bins.csv'):\n",
    "        rgiid_list.append(i[0:8])\n",
    "        rgiid_fn_list.append(i)\n",
    "        \n",
    "rgiid_list = sorted(rgiid_list)\n",
    "rgiid_fn_list = sorted(rgiid_fn_list)\n",
    "\n",
    "print(len(rgiid_list))\n",
    "\n",
    "main_glac_rgi = selectglaciersrgitable(rgiid_list)\n",
    "main_glac_rgi['bin_fn'] = rgiid_fn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
