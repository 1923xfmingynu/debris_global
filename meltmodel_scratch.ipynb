{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in libaries\n",
    "import argparse\n",
    "#import collections\n",
    "import datetime\n",
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "# External libraries\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import xarray as xr\n",
    "# Local libraries\n",
    "import globaldebris_input as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(lst, n=1, option_ordered=1):\n",
    "    \"\"\"\n",
    "    Split list into batches for the supercomputer.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lst : list\n",
    "        List that you want to split into separate batches\n",
    "    n : int\n",
    "        Number of batches to split glaciers into.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lst_batches : list\n",
    "        list of n lists that have sequential values in each list\n",
    "    \"\"\"\n",
    "    # If batches is more than list, then there will be one glacier in each batch\n",
    "    if option_ordered == 1:\n",
    "        if n > len(lst):\n",
    "            n = len(lst)\n",
    "        n_perlist_low = int(len(lst)/n)\n",
    "        n_perlist_high = int(np.ceil(len(lst)/n))\n",
    "        lst_copy = lst.copy()\n",
    "        count = 0\n",
    "        lst_batches = []\n",
    "        for x in np.arange(n):\n",
    "            count += 1\n",
    "            if count <= len(lst) % n:\n",
    "                lst_subset = lst_copy[0:n_perlist_high]\n",
    "                lst_batches.append(lst_subset)\n",
    "                [lst_copy.remove(i) for i in lst_subset]\n",
    "            else:\n",
    "                lst_subset = lst_copy[0:n_perlist_low]\n",
    "                lst_batches.append(lst_subset)\n",
    "                [lst_copy.remove(i) for i in lst_subset]\n",
    "    \n",
    "    else:\n",
    "        if n > len(lst):\n",
    "            n = len(lst)\n",
    "    \n",
    "        lst_batches = [[] for x in np.arange(n)]\n",
    "        nbatch = 0\n",
    "        for count, x in enumerate(lst):\n",
    "            if count%n == 0:\n",
    "                nbatch = 0\n",
    "    \n",
    "            lst_batches[nbatch].append(x)\n",
    "            \n",
    "            nbatch += 1\n",
    "            \n",
    "    return lst_batches    \n",
    "\n",
    "\n",
    "def getparser():\n",
    "    \"\"\"\n",
    "    Use argparse to add arguments from the command line\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batchno (optional) : int\n",
    "        batch number used to differentiate output on supercomputer\n",
    "    batches (optional) : int\n",
    "        total number of batches based on supercomputer\n",
    "    num_simultaneous_processes (optional) : int\n",
    "        number of cores to use in parallels\n",
    "    option_parallels (optional) : int\n",
    "        switch to use parallels or not\n",
    "    debug (optional) : int\n",
    "        Switch for turning debug printing on or off (default = 0 (off))\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Object containing arguments and their respective values.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"run simulations from gcm list in parallel\")\n",
    "    # add arguments\n",
    "    parser.add_argument('-batchno', action='store', type=int, default=0,\n",
    "                        help='Batch number used to differentiate output on supercomputer')\n",
    "    parser.add_argument('-batches', action='store', type=int, default=1,\n",
    "                        help='Total number of batches (nodes) for supercomputer')\n",
    "    parser.add_argument('-num_simultaneous_processes', action='store', type=int, default=4,\n",
    "                        help='number of simultaneous processes (cores) to use')\n",
    "    parser.add_argument('-option_parallels', action='store', type=int, default=1,\n",
    "                        help='Switch to use or not use parallels (1 - use parallels, 0 - do not)')\n",
    "    parser.add_argument('-debug', action='store', type=int, default=0,\n",
    "                        help='Boolean for debugging to turn it on or off (default 0 is off')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solar_calcs_NOAA(year, julian_day_of_year, time_frac, longitude_deg, latitude_deg, nsteps):\n",
    "    \"\"\" NOAA calculations to determine the position of the sun and distance to sun\n",
    "\n",
    "    Sun position based on NOAA solar calculator\n",
    "    Earth-sun distance based on Stamnes (2015)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    year : np.array\n",
    "        array of the year associated with each time step\n",
    "    julian_day_of_year : np.array\n",
    "        julian day of year associated with each time step\n",
    "    time_frac : np.array\n",
    "        time (hour + minute / 60) of each time step\n",
    "    longitude_deg : float\n",
    "        longitude in degrees\n",
    "    latitude_deg : float\n",
    "        latitude in degrees\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    SolarZenithAngleCorr_rad : np.array\n",
    "        Solar zenith angle [radians] corrected for atmospheric refraction\n",
    "    SolarAzimuthAngle_rad : np.array\n",
    "        Solar azimuth angle [radians] based on degrees clockwise from north\n",
    "    rm_r2 : np.array\n",
    "        Squared mean earth-sun distance normalized by instantaneous earth-sun distance\n",
    "    \"\"\"\n",
    "    julianday_NOAA = np.zeros((nsteps))\n",
    "    julianCentury = np.zeros((nsteps))\n",
    "    GeomMeanLongSun_deg = np.zeros((nsteps))\n",
    "    GeomMeanLongSun_rad = np.zeros((nsteps))\n",
    "    GeomMeanAnomSun_deg = np.zeros((nsteps))\n",
    "    GeomMeanAnomSun_rad = np.zeros((nsteps))\n",
    "    EccentEarthOrbit = np.zeros((nsteps))\n",
    "    SunEqofCtr = np.zeros((nsteps))\n",
    "    SunTrueLong_deg = np.zeros((nsteps))\n",
    "    SunAppLong_deg = np.zeros((nsteps))\n",
    "    SunAppLong_rad = np.zeros((nsteps))\n",
    "    MeanObliqEcliptic_deg = np.zeros((nsteps))\n",
    "    ObliqCorr_deg = np.zeros((nsteps))\n",
    "    ObliqCorr_rad = np.zeros((nsteps))\n",
    "    SunDeclin_deg = np.zeros((nsteps))\n",
    "    SunDeclin_rad = np.zeros((nsteps))\n",
    "    VarY = np.zeros((nsteps))\n",
    "    EqofTime = np.zeros((nsteps))\n",
    "    TrueSolarTime = np.zeros((nsteps))\n",
    "    HourAngle_deg = np.zeros((nsteps))\n",
    "    HourAngle_rad = np.zeros((nsteps))\n",
    "    SolarZenithAngle_deg = np.zeros((nsteps))\n",
    "    SolarZenithAngle_rad = np.zeros((nsteps))\n",
    "    SolarElevationAngle_deg = np.zeros((nsteps))\n",
    "    SolarElevationAngle_rad = np.zeros((nsteps))\n",
    "    ApproxAtmosRefrac_deg = np.zeros((nsteps))\n",
    "    SolarElevationAngleCorr_deg = np.zeros((nsteps))\n",
    "    SolarZenithAngleCorr_deg = np.zeros((nsteps))\n",
    "    SolarZenithAngleCorr_rad = np.zeros((nsteps))\n",
    "    SolarAzimuthAngle_deg = np.zeros((nsteps))\n",
    "    SolarAzimuthAngle_rad = np.zeros((nsteps))\n",
    "    rm_r2 = np.zeros((nsteps))\n",
    "\n",
    "    # Julian day\n",
    "    #  +1 accounts for the fact that day 1 is January 1, 1900\n",
    "    #  2415018.5 converts from 1900 to NOAA Julian day of year\n",
    "    julianday_NOAA = (np.floor(365.25*(year-1900)+1) + julian_day_of_year + (time_frac-input.timezone )/24 +\n",
    "                      2415018.5)\n",
    "    # Julian Century\n",
    "    julianCentury = (julianday_NOAA-2451545) / 36525\n",
    "    # Geom Mean Long Sun\n",
    "    GeomMeanLongSun_deg = (280.46646 + julianCentury * (36000.76983 + julianCentury*0.0003032)) % 360\n",
    "    GeomMeanLongSun_rad = GeomMeanLongSun_deg * np.pi/180\n",
    "    # Geom Mean Anom Sun\n",
    "    GeomMeanAnomSun_deg = 357.52911 + julianCentury * (35999.05029 - 0.0001537*julianCentury)\n",
    "    GeomMeanAnomSun_rad = GeomMeanAnomSun_deg * np.pi/180\n",
    "    # Eccent Earth Orbit\n",
    "    EccentEarthOrbit = 0.016708634 - julianCentury * (0.000042037 + 0.0000001267*julianCentury)\n",
    "    # Sun Eq of Ctr\n",
    "    SunEqofCtr = (np.sin(GeomMeanAnomSun_rad) * (1.914602 - julianCentury * (0.004817 + 0.000014*julianCentury)) +\n",
    "                  np.sin(2 * GeomMeanAnomSun_rad) * (0.019993 - 0.000101*julianCentury) +\n",
    "                  np.sin(3 * GeomMeanAnomSun_rad) * 0.000289)\n",
    "    # Sun True Long\n",
    "    SunTrueLong_deg = GeomMeanLongSun_deg + SunEqofCtr\n",
    "    # Sun True Anom\n",
    "    #SunTrueAnom_deg = GeomMeanAnomSun_deg + SunEqofCtr\n",
    "    # Sun Rad Vector [AUs]\n",
    "    #SunRadVector = ((1.000001018 * (1 - EccentEarthOrbit * EccentEarthOrbit)) /\n",
    "    #                (1 + EccentEarthOrbit * np.cos(SunTrueAnom_rad)))\n",
    "    # Sun App Long\n",
    "    SunAppLong_deg = SunTrueLong_deg - 0.00569 - 0.00478 * np.sin((125.04 - 1934.136*julianCentury) * np.pi/180)\n",
    "    SunAppLong_rad = SunAppLong_deg * np.pi/180\n",
    "    # Mean Obliq Ecliptic\n",
    "    MeanObliqEcliptic_deg = (23 + (26 + ((21.448 - julianCentury * (46.815 + julianCentury * (0.00059 -\n",
    "                             julianCentury * 0.001813)))) / 60) / 60)\n",
    "    # Obliq Corr\n",
    "    ObliqCorr_deg = MeanObliqEcliptic_deg + 0.00256 * np.cos((125.04 - 1934.136*julianCentury) * np.pi/180)\n",
    "    ObliqCorr_rad = ObliqCorr_deg * np.pi/180\n",
    "    # Sun Rt Ascen\n",
    "    #SunRtAscen_deg = (180/np.pi * np.arctan((np.cos(ObliqCorr_rad) * np.sin(SunAppLong_rad)) /\n",
    "    #                                        np.cos(SunAppLong_rad)))\n",
    "    # Sun Declin\n",
    "    SunDeclin_deg = 180/np.pi * np.arcsin(np.sin(ObliqCorr_rad) * np.sin(SunAppLong_rad))\n",
    "    SunDeclin_rad = SunDeclin_deg * np.pi/180\n",
    "    # VarY\n",
    "    VarY = np.tan(ObliqCorr_deg / 2 * np.pi/180) * np.tan(ObliqCorr_deg / 2 * np.pi/180)\n",
    "    # Eq of Time [min]\n",
    "    EqofTime = (4 * 180/np.pi * (VarY * np.sin(2 * GeomMeanLongSun_rad) - 2 * EccentEarthOrbit *\n",
    "                np.sin(GeomMeanAnomSun_rad) + 4 * EccentEarthOrbit * VarY * np.sin(GeomMeanAnomSun_rad) *\n",
    "                np.cos(2 * GeomMeanLongSun_rad) - 0.5 * VarY * VarY * np.sin(4 * GeomMeanLongSun_rad) - 1.25 *\n",
    "                EccentEarthOrbit * EccentEarthOrbit * np.sin(2 * GeomMeanAnomSun_rad)))\n",
    "    # True Solar Time [min]\n",
    "    TrueSolarTime = (time_frac*60*1440 + time_frac*60 + EqofTime + 4*longitude_deg - 60*input.timezone) % 1440\n",
    "    # Hour Angle\n",
    "    HourAngle_deg[TrueSolarTime/4 < 0] = TrueSolarTime[TrueSolarTime/4 < 0] / 4 + 180\n",
    "    HourAngle_deg[TrueSolarTime/4 >= 0] = TrueSolarTime[TrueSolarTime/4 >= 0] / 4 - 180\n",
    "    HourAngle_rad = HourAngle_deg * np.pi/180\n",
    "    # Solar Zenith Angle (deg)\n",
    "    SolarZenithAngle_deg = (180/np.pi * np.arccos(np.sin(latitude_deg * np.pi/180) * np.sin(SunDeclin_rad) +\n",
    "                            np.cos(latitude_deg * np.pi/180) * np.cos(SunDeclin_rad) * np.cos(HourAngle_rad)))\n",
    "    SolarZenithAngle_rad = SolarZenithAngle_deg * np.pi/180\n",
    "    # Solar Elevation Angle (deg)\n",
    "    SolarElevationAngle_deg = 90 - SolarZenithAngle_deg\n",
    "    SolarElevationAngle_rad = SolarElevationAngle_deg * np.pi/180\n",
    "    # Approx Atmospheric Refraction (deg)\n",
    "    ApproxAtmosRefrac_deg = -20.772 / np.tan(SolarElevationAngle_rad)\n",
    "    ApproxAtmosRefrac_deg[SolarElevationAngle_deg > 85] = 0\n",
    "    mask = [(SolarElevationAngle_deg > 5) & (SolarElevationAngle_deg <= 85)]\n",
    "    ApproxAtmosRefrac_deg[mask] = (\n",
    "            58.1 / np.tan(SolarElevationAngle_rad[mask]) - 0.07 / ((np.tan(SolarElevationAngle_rad[mask]))**3) +\n",
    "            0.000086 / ((np.tan(SolarElevationAngle_rad[mask]))**5))\n",
    "    mask = [(SolarElevationAngle_deg > -0.575) & (SolarElevationAngle_deg <= 5)]\n",
    "    ApproxAtmosRefrac_deg[mask] = (\n",
    "            1735 + SolarElevationAngle_deg[mask] * (-518.2 + SolarElevationAngle_deg[mask] *\n",
    "            (103.4 + SolarElevationAngle_deg[mask] * (-12.79 + SolarElevationAngle_deg[mask]*0.711))))\n",
    "    ApproxAtmosRefrac_deg = ApproxAtmosRefrac_deg / 3600\n",
    "    # Solar Elevation Correct for Atm Refraction\n",
    "    SolarElevationAngleCorr_deg = SolarElevationAngle_deg + ApproxAtmosRefrac_deg\n",
    "    # Solar Zenith Angle Corrected for Atm Refraction\n",
    "    SolarZenithAngleCorr_deg = 90 - SolarElevationAngleCorr_deg\n",
    "    SolarZenithAngleCorr_rad = SolarZenithAngleCorr_deg * np.pi/180\n",
    "    # Solar Azimuth Angle (deg CW from N)\n",
    "    SolarAzimuthAngle_deg[HourAngle_deg > 0] = (\n",
    "            ((180/np.pi * (np.arccos(((np.sin(latitude_deg * np.pi/180) *\n",
    "              np.cos(SolarZenithAngle_rad[HourAngle_deg > 0])) - np.sin(SunDeclin_rad[HourAngle_deg > 0])) /\n",
    "              (np.cos(latitude_deg * np.pi/180) * np.sin(SolarZenithAngle_rad[HourAngle_deg > 0])))) + 180) / 360 -\n",
    "             np.floor((180/np.pi * (np.arccos(((np.sin(latitude_deg * np.pi/180) *\n",
    "             np.cos(SolarZenithAngle_rad[HourAngle_deg > 0])) - np.sin(SunDeclin_rad[HourAngle_deg > 0])) /\n",
    "             (np.cos(latitude_deg * np.pi/180) * np.sin(SolarZenithAngle_rad[HourAngle_deg > 0])))) + 180) / 360))\n",
    "            * 360)\n",
    "    SolarAzimuthAngle_deg[HourAngle_deg <= 0] = (\n",
    "            ((540 - 180/np.pi * (np.arccos(((np.sin(latitude_deg * np.pi/180) *\n",
    "              np.cos(SolarZenithAngle_rad[HourAngle_deg <= 0])) - np.sin(SunDeclin_rad[HourAngle_deg <= 0])) /\n",
    "              (np.cos(latitude_deg * np.pi/180) * np.sin(SolarZenithAngle_rad[HourAngle_deg <= 0]))))) / 360 -\n",
    "             np.floor((540 - 180/np.pi * (np.arccos(((np.sin(latitude_deg * np.pi/180) *\n",
    "             np.cos(SolarZenithAngle_rad[HourAngle_deg <= 0])) - np.sin(SunDeclin_rad[HourAngle_deg <= 0])) /\n",
    "             (np.cos(latitude_deg * np.pi/180) * np.sin(SolarZenithAngle_rad[HourAngle_deg <= 0]))))) / 360)) * 360)\n",
    "    SolarAzimuthAngle_rad = SolarAzimuthAngle_deg * np.pi/180\n",
    "    # Distance from sun based on eccentricity of orbit (r/rm)^2 based on Stamnes (2015)\n",
    "    # Day number [radians]\n",
    "    dn_rad = julian_day_of_year * 2 * np.pi / 365\n",
    "    rm_r2 = (1 / (1.000110 + 0.034221 * np.cos(dn_rad) + 0.001280 * np.sin(dn_rad) + 0.000719 *\n",
    "                  np.cos(2 * dn_rad) + 0.000077 * np.sin(2 * dn_rad)))**2\n",
    "    return SolarZenithAngleCorr_rad, SolarAzimuthAngle_rad, rm_r2\n",
    "\n",
    "\n",
    "def CrankNicholson(Td, Tair, i, debris_thickness, N, h, C, a_Crank, b_Crank, c_Crank, d_Crank, A_Crank, S_Crank):\n",
    "    \"\"\" Run Crank-Nicholson scheme to obtain debris temperature\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Td : np.array\n",
    "        debris temperature [k] (rows = internal layers, columns = timestep)\n",
    "    Tair : np.array\n",
    "        air temperature [K]\n",
    "    i : int\n",
    "        step number\n",
    "    debris_thickness : float\n",
    "        debris thickness [m]\n",
    "    N : int\n",
    "        number of layers\n",
    "    h : float\n",
    "        height of debris layers [m]\n",
    "    C : float\n",
    "        constant defined by Reid and Brock (2010) for Crank-Nicholson Scheme\n",
    "    a_Crank,\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Td : np.array\n",
    "        updated debris temperature [k] (rows = internal layers, columns = timestep)\n",
    "    \"\"\"\n",
    "    # Calculate temperature profile in the debris\n",
    "    # For t = 0, which is i = 1, assume initial condition of linear temperature profile in the debris\n",
    "    if i == 0:\n",
    "        Td_gradient = (Td[0,0] - Td[N-1,0])/debris_thickness\n",
    "\n",
    "        # CODE IMPROVEMENT HERE: TD CALCULATION SKIPPED ONE\n",
    "        for j in np.arange(1,N-1):\n",
    "            Td[j,0] = Td[0,0] - (j*h)*Td_gradient\n",
    "\n",
    "    else:\n",
    "        # Perform Crank-Nicholson Scheme\n",
    "        for j in np.arange(1,N-1):\n",
    "            # Equations A8 in Reid and Brock (2010)\n",
    "            a_Crank[j,i] = C\n",
    "            b_Crank[j,i] = 2*C+1\n",
    "            c_Crank[j,i] = C\n",
    "\n",
    "            # Equations A9 in Reid and Brock (2010)\n",
    "            if j == 1:\n",
    "                d_Crank[j,i] = C*Td[0,i] + C*Td[0,i-1] + (1-2*C)*Td[j,i-1] + C*Td[j+1,i-1]\n",
    "            elif j < (N-2):\n",
    "                d_Crank[j,i] = C*Td[j-1,i-1] + (1-2*C)*Td[j,i-1] + C*Td[j+1,i-1]\n",
    "            elif j == (N-2):\n",
    "                d_Crank[j,i] = 2*C*Td[N-1,i] + C*Td[N-3,i-1] + (1-2*C)*Td[N-2,i-1]\n",
    "            # note notation:\n",
    "            #  \"i-1\" refers to the past\n",
    "            #  \"j-1\" refers to the cell above it\n",
    "            #  \"j+1\" refers to the cell below it\n",
    "\n",
    "\n",
    "            # Equations A10 and A11 in Reid and Brock (2010)\n",
    "            if j == 1:\n",
    "                A_Crank[j,i] = b_Crank[j,i]\n",
    "                S_Crank[j,i] = d_Crank[j,i]\n",
    "            else:\n",
    "                A_Crank[j,i] = b_Crank[j,i] - a_Crank[j,i] / A_Crank[j-1,i] * c_Crank[j-1,i]\n",
    "                S_Crank[j,i] = d_Crank[j,i] + a_Crank[j,i] / A_Crank[j-1,i] * S_Crank[j-1,i]\n",
    "\n",
    "        # Equations A12 in Reid and Brock (2010)\n",
    "        for j in np.arange(N-2,0,-1):\n",
    "            if j == (N-2):\n",
    "                Td[j,i] = S_Crank[j,i] / A_Crank[j,i]\n",
    "            else:\n",
    "                Td[j,i] = 1 / A_Crank[j,i] * (S_Crank[j,i] + c_Crank[j,i] * Td[j+1,i])\n",
    "    return Td\n",
    "\n",
    "\n",
    "def calc_surface_fluxes(Td_i, Tair_i, RH_AWS_i, u_AWS_i, Sin_i, Lin_AWS_i, Rain_AWS_i, snow_i, P, Albedo, k,\n",
    "                        a_neutral_debris, h, dsnow_t0, tsnow_t0, snow_tau_t0, ill_angle_rad_i, a_neutral_snow,\n",
    "                        debris_thickness,\n",
    "                        option_snow=0, option_snow_fromAWS=0):\n",
    "    \"\"\" Calculate surface energy fluxes for timestep i\n",
    "\n",
    "    Snow model uses a modified version of Tarboten and Luce (1996) to compute fluxes\n",
    "      - Sin calculated above, not with their local slope and illumination corrections though\n",
    "        they are likely similar\n",
    "      - Ground heat flux is computed from the debris, not using their estimates from diurnal\n",
    "        soil temperatures\n",
    "      - Do not use their temperature threshold for snowfall, but use set value\n",
    "      - For P_flux, we do not include the snow fall component because it alters the cold content of the snow pack\n",
    "        therefore we don't want to double count this energy\n",
    "      - Do not account for wind redistribution of snow, which they state is site specific\n",
    "      - Do not iterate to solve snow temperature, but do a depth average\n",
    "      - Solve for the thermal conductivity at the debris/ice interface using the depth of snow and debris height\n",
    "\n",
    "    Limitation:\n",
    "      - If allow all negative energy to warm up the snowpack and the snowpack is very thin (< 1 cm), then the\n",
    "        change in temperature can be extreme (-10 to -1000s of degrees), which is unrealistic.\n",
    "        More realistic is that the snowpack may change its temperature and the remaining energy will be\n",
    "        transferred to also cool the debris layer. Set maximum temperature change of the snow pack during any given\n",
    "        time step to 1 degC.\n",
    "\n",
    "    Note: since partitioning rain into snow, units are automatically m w.e.\n",
    "          hence, the density of snow is not important\n",
    "\n",
    "    Future work:\n",
    "      - Currently, the debris/ice interface is set to 273.15.\n",
    "        This is fine during the ablation season; however, when the debris freezes in the winter\n",
    "      - Snow melt water should theoretically percolate into the debris and transfer energy\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Td_i : np.array\n",
    "        debris temperature\n",
    "    Tair_i, RH_AWS_i, u_AWS_i, Sin_i, Lin_AWS_i, Rain_AWS_i, snow_i : floats\n",
    "        meteorological data\n",
    "    P : float\n",
    "        pressure [Pa]\n",
    "    Albedo, k, a_neutral_debris : floats\n",
    "        debris albedo, thermal conductivity, and turbulent heat flux transfer coefficient (from surface roughness)\n",
    "    h : float\n",
    "        debris layer height [m]\n",
    "    dsnow_t0, tsnow_t0, snow_tau_t0\n",
    "        snow depth, temperature and dimensionless age at start of time step before any snow or melt has occurred\n",
    "    ill_angle_rad_i : float\n",
    "        solar illumination angle used to adjust snow albedo\n",
    "    a_neutral_snow : float\n",
    "        snow turbulent heat flux transfer coefficient (based on surface roughness)\n",
    "    option_snow : int\n",
    "        switch to use snow model (1) or not (0)\n",
    "    option_snow_fromAWS : int\n",
    "        switch to use snow depth (1) instead of snow fall (0)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    F_Ts_i, Rn_i, LE_i, H_i, P_flux_i, Qc_i : floats\n",
    "        Energy fluxes [W m-2]\n",
    "    dF_Ts_i, dRn_i, dLE_i, dH_i, dP_flux_i, dQc_i : floats\n",
    "        Derivatives of energy fluxes\n",
    "    dsnow_i : float\n",
    "        Snow depth [mwe] at end of time step\n",
    "    tsnow_i : float\n",
    "        Snow temperature at end of time step\n",
    "    snow_tau_i : float\n",
    "        Non-dimensional snow age at end of time step\n",
    "    \"\"\"\n",
    "    # Snow depth [m w.e.]\n",
    "    dsnow_i = dsnow_t0 + snow_i\n",
    "    snow_tau_i = snow_tau_t0\n",
    "    tsnow_i = 0\n",
    "\n",
    "    # First option: Snow depth is based on snow fall, so need to melt snow\n",
    "    if dsnow_i > 0 and option_snow==1 and option_snow_fromAWS == 0:\n",
    "        tsnow_i = (dsnow_t0 * tsnow_t0 + snow_i * Tair_i) / dsnow_i\n",
    "\n",
    "        # Thermal conductivity at debris/snow interface assuming conductance resistance is additive\n",
    "        #  estimating the heat transfer through dsnow_eff layer of snow and h_eff layer of debris\n",
    "        # Tarboten and Luce (1996) use effective soil depth of 0.4 m for computing the ground heat transfer\n",
    "        if debris_thickness < 0.4:\n",
    "            h_eff = debris_thickness\n",
    "        else:\n",
    "            h_eff = 0.4\n",
    "        if dsnow_i < 0.4:\n",
    "            dsnow_eff = dsnow_i\n",
    "        else:\n",
    "            dsnow_eff = 0.4\n",
    "        k_snow_interface = (h_eff + dsnow_eff) / (dsnow_eff/input.k_snow + h_eff/k)\n",
    "        # Previously estimating it based on equal parts\n",
    "        #k_snow_interface = h / ((0.5 * h) / input.k_snow + (0.5*h) / k)\n",
    "\n",
    "        # Density of air (dry) based on pressure (elevation) and temperature\n",
    "        #  used in snow calculations, which has different parameterization of turbulent fluxes\n",
    "        #  compared to the debris\n",
    "        density_air = P / (287.058 * Tair_i)\n",
    "\n",
    "        # Albedo\n",
    "        # parameters representing grain growth due to vapor diffusion (r1), additional effect near\n",
    "        #  and at freezing point due to melt and refreeze (r2), and the effect of dirt and soot (r3)\n",
    "        snow_r1 = np.exp(5000 * (1 / 273.16 - 1 / tsnow_i))\n",
    "        snow_r2 = np.min([snow_r1**10, 1])\n",
    "        snow_r3 = 0.03 # change to 0.01 if in Antarctica\n",
    "        # change in non-dimensional snow surface age\n",
    "        snow_tau_i += (snow_r1 + snow_r2 + snow_r3) / input.snow_tau_0 * input.delta_t\n",
    "        # new snow affect on snow age\n",
    "        if snow_i > 0.01:\n",
    "            snow_tau_i = 0\n",
    "        elif snow_i > 0:\n",
    "            snow_tau_i = snow_tau_i * (1 - 100 * snow_i)\n",
    "        # snow age\n",
    "        snow_age = snow_tau_i / (1 + snow_tau_i)\n",
    "        # albedo as a function of snow age and band\n",
    "        albedo_vd = (1 - input.snow_c_v * snow_age) * input.albedo_vo\n",
    "        albedo_ird = (1 - input.snow_c_ir * snow_age) * input.albedo_iro\n",
    "        # increase in albedo based on illumination angle\n",
    "        #  illumination angle measured relative to the surface normal\n",
    "        if np.cos(ill_angle_rad_i) < 0.5:\n",
    "            b_ill = 2\n",
    "            f_psi = 1/b_ill * ((1 + b_ill) / (1 + 2 * b_ill * np.cos(ill_angle_rad_i)) - 1)\n",
    "        else:\n",
    "            f_psi = 0\n",
    "        albedo_v = albedo_vd + 0.4 * f_psi * (1 - albedo_vd)\n",
    "        albedo_ir = albedo_ird + 0.4 * f_psi * (1 - albedo_ird)\n",
    "        albedo_snow = np.mean([albedo_v, albedo_ir])\n",
    "        # Adjustments to albedo\n",
    "        # ensure albedo is within bounds\n",
    "        if albedo_snow > 1:\n",
    "            albedo_snow = 1\n",
    "        elif albedo_snow < 0:\n",
    "            albedo_snow = 0\n",
    "        # if snow less than 0.1 m, then underlying debris influences albedo\n",
    "        if dsnow_i < 0.1:\n",
    "            r_adj = (1 - dsnow_i/0.1)*np.exp(dsnow_i / (2*0.1))\n",
    "            albedo_snow = r_adj * Albedo + (1 - r_adj) * albedo_snow\n",
    "\n",
    "        # Snow Energy Balance\n",
    "        Rn_snow = (Sin_i * (1 - albedo_snow) + input.emissivity_snow * (Lin_AWS_i -\n",
    "                   (input.stefan_boltzmann * tsnow_i**4)))\n",
    "        H_snow = a_neutral_snow * density_air * input.cA * u_AWS_i * (Tair_i - tsnow_i)\n",
    "        # Vapor pressure above snow assumed to be saturated\n",
    "        # Vapor pressure (e, Pa) computed using Clasius-Clapeyron Equation and Relative Humidity\n",
    "        #  611 is the vapor pressure of ice and liquid water at melting temperature (273.15 K)\n",
    "        eZ_Saturated = 611 * np.exp(input.Lv / input.R_const * (1 / 273.15 - 1 / Tair_i))\n",
    "        eZ = RH_AWS_i * eZ_Saturated\n",
    "        # Vapor pressure of snow based on temperature (Colbeck, 1990)\n",
    "        e_snow = input.eS_snow * np.exp(2838 * (tsnow_i - 273.15) / (0.4619 * tsnow_i * 273.15))\n",
    "        if e_snow > input.eS_snow:\n",
    "            e_snow = input.eS_snow\n",
    "        LE_snow = 0.622 * input.Ls / (input.Rd * Tair_i) * a_neutral_snow * u_AWS_i * (eZ - e_snow)\n",
    "        Pflux_snow = (Rain_AWS_i * (input.Lf * input.density_water + input.cW * input.density_water *\n",
    "                                    (np.max([273.15, Tair_i]) - 273.15)) / input.delta_t)\n",
    "        Qc_snow_debris = k_snow_interface * (Td_i[0] - tsnow_i)/h\n",
    "\n",
    "        # Net energy available for snow depends on latent heat flux\n",
    "        # if Positive LE: Air > snow vapor pressure (condensation/resublimation)\n",
    "        #  energy released and available to melt the snow (include LE in net energy)\n",
    "        if LE_snow > 0:\n",
    "            Fnet_snow = Rn_snow + H_snow + LE_snow + Pflux_snow + Qc_snow_debris\n",
    "            snow_sublimation = 0\n",
    "        # if Negative LE: Air < snow vapor pressure (sublimation/evaporation)\n",
    "        #  energy consumed and snow sublimates (do not include LE in net energy)\n",
    "        else:\n",
    "            Fnet_snow = Rn_snow + H_snow + Pflux_snow + Qc_snow_debris\n",
    "            # Snow sublimation [m w.e.]\n",
    "            snow_sublimation = -1 * LE_snow / (input.density_water * input.Lv) * input.delta_t\n",
    "\n",
    "        # Cold content of snow [W m2]\n",
    "        Qcc_snow = input.cSnow * input.density_water * dsnow_i * (273.15 - tsnow_i) / input.delta_t\n",
    "\n",
    "        # Max energy spent cooling snowpack based on 1 degree temperature change\n",
    "        Qcc_snow_neg1 = -1 * input.cSnow * input.density_water * dsnow_i / input.delta_t\n",
    "\n",
    "        # If Fnet_snow is positive and greater than cold content, then energy is going to warm the\n",
    "        # snowpack to melting point and begin melting the snow.\n",
    "        if Fnet_snow > Qcc_snow:\n",
    "            # Snow warmed up to melting temperature\n",
    "            tsnow_i = 273.15\n",
    "            Fnet_snow -= Qcc_snow\n",
    "            Fnet_snow2debris = 0\n",
    "        elif Fnet_snow < Qcc_snow_neg1:\n",
    "            # Otherwise only changes the temperature in the snowpack and the debris\n",
    "            # limit the change in snow temperature\n",
    "            tsnow_i -= 1\n",
    "            Fnet_snow2debris = Fnet_snow - Qcc_snow_neg1\n",
    "            Fnet_snow = 0\n",
    "        else:\n",
    "            # Otherwise only changes the temperature\n",
    "            tsnow_i += Fnet_snow / (input.cSnow * input.density_water * dsnow_i) * input.delta_t\n",
    "            Fnet_snow = 0\n",
    "            Fnet_snow2debris = 0\n",
    "\n",
    "        # Snow melt [m snow] with remaining energy, if any\n",
    "        snow_melt_energy = Fnet_snow / (input.density_water * input.Lf) * input.delta_t\n",
    "\n",
    "        # Total snow melt\n",
    "        snow_melt = snow_melt_energy + snow_sublimation\n",
    "\n",
    "        # Snow depth [m w.e.]\n",
    "        dsnow_i -= snow_melt\n",
    "        if dsnow_i < 0:\n",
    "            dsnow_i = 0\n",
    "        if dsnow_i == 0:\n",
    "            snow_tau_i = 0\n",
    "\n",
    "        # Solve for temperature in debris\n",
    "        #  Rn, LE, H, and P equal 0\n",
    "        Rn_i = 0\n",
    "        LE_i = 0\n",
    "        H_i = 0\n",
    "        Qc_i = k * (Td_i[1] - Td_i[0]) / h\n",
    "        P_flux_i = 0\n",
    "        Qc_snow_i = -Qc_snow_debris\n",
    "        F_Ts_i = Rn_i + LE_i + H_i + Qc_i + P_flux_i + Qc_snow_i  + Fnet_snow2debris\n",
    "\n",
    "        dRn_i = 0\n",
    "        dLE_i = 0\n",
    "        dH_i = 0\n",
    "        dQc_i = -k/h\n",
    "        dP_flux_i = 0\n",
    "        dQc_snow_i = -k_snow_interface/h\n",
    "        dF_Ts_i = dRn_i + dLE_i + dH_i + dQc_i + dP_flux_i + dQc_snow_i\n",
    "\n",
    "    # Second option: Snow depth is prescribed from AWS, so don't need to melt snow\n",
    "    elif dsnow_i > 0 and option_snow==1 and option_snow_fromAWS == 1:\n",
    "        dsnow_i = snow_i\n",
    "        tsnow_i = Tair_i\n",
    "        if tsnow_i > 273.15:\n",
    "            tsnow_i = 273.15\n",
    "\n",
    "        # Thermal conductivity at debris/snow interface assuming conductance resistance is additive\n",
    "        #  estimating the heat transfer through dsnow_eff layer of snow and h_eff layer of debris\n",
    "        # Tarboten and Luce (1996) use effective soil depth of 0.4 m for computing the ground heat transfer\n",
    "        if debris_thickness < 0.4:\n",
    "            h_eff = debris_thickness\n",
    "        else:\n",
    "            h_eff = 0.4\n",
    "        if dsnow_i < 0.4:\n",
    "            dsnow_eff = dsnow_i\n",
    "        else:\n",
    "            dsnow_eff = 0.4\n",
    "        k_snow_interface = (h_eff + dsnow_eff) / (dsnow_eff/input.k_snow + h_eff/k)\n",
    "\n",
    "        Qc_snow_debris = k_snow_interface * (Td_i[0] - tsnow_i)/h\n",
    "\n",
    "        # Solve for temperature in debris\n",
    "        #  Rn, LE, H, and P equal 0\n",
    "        Rn_i = 0\n",
    "        LE_i = 0\n",
    "        H_i = 0\n",
    "        Qc_i = k * (Td_i[1] - Td_i[0]) / h\n",
    "        P_flux_i = 0\n",
    "        Qc_snow_i = -Qc_snow_debris\n",
    "        Fnet_snow2debris = 0\n",
    "        F_Ts_i = Rn_i + LE_i + H_i + Qc_i + P_flux_i + Qc_snow_i\n",
    "\n",
    "        dRn_i = 0\n",
    "        dLE_i = 0\n",
    "        dH_i = 0\n",
    "        dQc_i = -k/h\n",
    "        dP_flux_i = 0\n",
    "        dQc_snow_i = -k_snow_interface/h\n",
    "        dF_Ts_i = dRn_i + dLE_i + dH_i + dQc_i + dP_flux_i + dQc_snow_i\n",
    "\n",
    "    else:\n",
    "        # Debris-covered glacier Energy Balance (no snow)\n",
    "        if Rain_AWS_i > 0:\n",
    "            # Vapor pressure (e, Pa) computed using Clasius-Clapeyron Equation and Relative Humidity\n",
    "            #  611 is the vapor pressure of ice and liquid water at melting temperature (273.15 K)\n",
    "            # if raining, assume the surface is saturated\n",
    "            eS_Saturated = 611 * np.exp(-input.Lv / input.R_const * (1 / Td_i[0] - 1 / 273.15))\n",
    "            eS = eS_Saturated\n",
    "            eZ_Saturated = 611 * np.exp(-input.Lv / input.R_const * (1 / Tair_i - 1 / 273.15))\n",
    "            eZ = RH_AWS_i * eZ_Saturated\n",
    "            LE_i = (0.622 * input.density_air_0 / input.P0 * input.Lv * a_neutral_debris * u_AWS_i\n",
    "                    * (eZ -eS))\n",
    "        else:\n",
    "            LE_i = 0\n",
    "        Rn_i = Sin_i * (1 - Albedo) + input.emissivity * (Lin_AWS_i - (5.67e-8 * Td_i[0]**4))\n",
    "        H_i = (input.density_air_0 * (P / input.P0) * input.cA * a_neutral_debris * u_AWS_i *\n",
    "               (Tair_i - Td_i[0]))\n",
    "        P_flux_i = input.density_water * input.cW * Rain_AWS_i / input.delta_t * (Tair_i - Td_i[0])\n",
    "        Qc_i = k * (Td_i[1] - Td_i[0]) / h\n",
    "        F_Ts_i = Rn_i + LE_i + H_i + Qc_i + P_flux_i\n",
    "\n",
    "        # Derivatives\n",
    "        if Rain_AWS_i > 0:\n",
    "            dLE_i = (-0.622 * input.density_air_0 / input.P0 * input.Lv * a_neutral_debris *\n",
    "                     u_AWS_i * 611 * np.exp(-input.Lv / input.R_const * (1 / Td_i[0] - 1 / 273.15))\n",
    "                     * (input.Lv / input.R_const * Td_i[0]**-2))\n",
    "        else:\n",
    "            dLE_i = 0\n",
    "        dRn_i = -4 * input.emissivity * 5.67e-8 * Td_i[0]**3\n",
    "        dH_i = -1 * input.density_air_0 * P / input.P0 * input.cA * a_neutral_debris * u_AWS_i\n",
    "        dP_flux_i = -input.density_water * input.cW * Rain_AWS_i/ input.delta_t\n",
    "        dQc_i = -k / h\n",
    "        dF_Ts_i = dRn_i + dLE_i + dH_i + dQc_i + dP_flux_i\n",
    "\n",
    "    return (F_Ts_i, Rn_i, LE_i, H_i, P_flux_i, Qc_i, dF_Ts_i, dRn_i, dLE_i, dH_i, dP_flux_i, dQc_i,\n",
    "            dsnow_i, tsnow_i, snow_tau_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(list_packed_vars):\n",
    "    \"\"\"\n",
    "    Run melt model for list of latlons\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    list_packed_vars : list\n",
    "        list of packed variables that enable the use of parallels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ...\n",
    "    \"\"\"\n",
    "    # Unpack variables\n",
    "    count = list_packed_vars[0]\n",
    "    latlon_list = list_packed_vars[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REPLACE ME WITH ARG PARSER\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "# parser = getparser()\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# if args.debug == 1:\n",
    "#     debug = True\n",
    "# else:\n",
    "#     debug = False\n",
    "\n",
    "#=====\n",
    "print('\\nREPLACE ME WITH ARG PARSER\\n')\n",
    "class batman():\n",
    "    pass\n",
    "args = batman()\n",
    "args.option_ordered=1\n",
    "args.option_parallels=0\n",
    "args.num_simultaneous_processes=3\n",
    "#=====\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "# Date of start of simulation\n",
    "date_start = datetime.datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "# Number of cores for parallel processing\n",
    "if args.option_parallels != 0:\n",
    "    num_cores = int(np.min([len(input.latlon_list), args.num_simultaneous_processes]))\n",
    "else:\n",
    "    num_cores = 1\n",
    "\n",
    "# Latlon batches to pass for parallel processing\n",
    "latlon_list_batches = split_list(input.latlon_list, n=num_cores, option_ordered=args.option_ordered)\n",
    "\n",
    "# Pack variables for multiprocessing\n",
    "list_packed_vars = []\n",
    "for count, latlon_list_batch in enumerate(latlon_list_batches):\n",
    "    list_packed_vars.append([count, latlon_list_batch])\n",
    "\n",
    "# Parallel processing\n",
    "if args.option_parallels != 0:\n",
    "    print('Processing in parallel with ' + str(args.num_simultaneous_processes) + ' cores...')\n",
    "    with multiprocessing.Pool(args.num_simultaneous_processes) as p:\n",
    "        p.map(main,list_packed_vars)\n",
    "# If not in parallel, then only should be one loop\n",
    "else:\n",
    "    # Loop through the chunks and export bias adjustments\n",
    "    for n in range(len(list_packed_vars)):\n",
    "        main(list_packed_vars[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (28.0, 86.75)\n"
     ]
    }
   ],
   "source": [
    "for nlatlon, latlon in enumerate(input.latlon_list):\n",
    "    print(nlatlon, latlon)\n",
    "    \n",
    "#     print('\\n\\nSHOULD TRY TO SET THIS UP BETTER AS AN OBJECT-ORIENTED PROGRAM\\n\\n')\n",
    "    \n",
    "    # ===== Meteorological data - GET ALL DATA FROM THE CLIMATE DATA OR ASSUMPTIONS =====\n",
    "    met_data = np.genfromtxt(input.met_data_fullfn, delimiter=',', skip_header=1)\n",
    "    met_data = met_data[input.start_idx:input.end_idx,:]\n",
    "    long_deg = input.lon_AWS_deg\n",
    "    lat_deg = input.lat_AWS_deg\n",
    "    Slope_AWS_rad = input.slope_AWS_deg*(np.pi/180)\n",
    "    Aspect_AWS_rad = input.aspect_AWS_deg*(np.pi/180)\n",
    "    P_AWS = input.P0*np.exp(-0.0289644*9.81*input.Elev_AWS/(8.31447*288.15))  # Pressure at Pyramid Station\n",
    "\n",
    "    # Select data\n",
    "    year = met_data[:,0].astype(int)\n",
    "    month = met_data[:,1].astype(int)\n",
    "    day = met_data[:,2].astype(int)\n",
    "    hour = met_data[:,3].astype(int)\n",
    "    minute = met_data[:,4].astype(int)\n",
    "    Tair_AWS = met_data[:,5] + 273.15 #celsius to kelvin\n",
    "    RH_AWS = met_data[:,6] / 100 # percentage to decimal\n",
    "    u_AWS_raw = met_data[:,7]\n",
    "    Rain_AWS = met_data[:,14]/1000 # mm to meters\n",
    "    Sin_AWS = met_data[:,10]\n",
    "    Sout_AWS = met_data[:,11]\n",
    "    Lin_AWS = met_data[:,12]\n",
    "    Snow_AWS = met_data[:,15]\n",
    "\n",
    "    # Albedo from AWS\n",
    "    albedo_AWS = np.zeros(Sin_AWS.shape)\n",
    "    albedo_AWS[Sin_AWS > 0] = Sout_AWS[Sin_AWS > 0] / Sin_AWS[Sin_AWS > 0]\n",
    "    albedo_AWS[albedo_AWS > 1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
