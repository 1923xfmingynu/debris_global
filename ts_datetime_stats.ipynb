{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate a 3-panel plot for input arrays\n",
    "def plot_array(dem, clim=None, titles=None, cmap='inferno', label=None, overlay=None, fn=None, close_fig=True):\n",
    "    fig, ax = plt.subplots(1,1, sharex=True, sharey=True, figsize=(10,5))\n",
    "    alpha = 1.0\n",
    "    #Gray background\n",
    "    ax.set_facecolor('0.5')\n",
    "    #Force aspect ratio to match images\n",
    "    ax.set(aspect='equal')\n",
    "    #Turn off axes labels/ticks\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if titles is not None:\n",
    "        ax.set_title(titles[0])\n",
    "    #Plot background shaded relief map\n",
    "    if overlay is not None:\n",
    "        alpha = 0.7\n",
    "        ax.imshow(overlay, cmap='gray', clim=(1,255))\n",
    "    #Plot each array\n",
    "    im_list = [ax.imshow(dem, clim=clim, cmap=cmap, alpha=alpha)]\n",
    "    fig.tight_layout()\n",
    "    fig.colorbar(im_list[0], label=label, extend='both', shrink=0.5)\n",
    "    if fn is not None:\n",
    "        fig.savefig(fn, bbox_inches='tight', pad_inches=0, dpi=150)\n",
    "    if close_fig:\n",
    "        plt.close(fig)\n",
    "        \n",
    "def selectglaciersrgitable(glac_no=None,\n",
    "                           rgi_regionsO1=None,\n",
    "                           rgi_regionsO2=None,\n",
    "                           rgi_glac_number=None,\n",
    "#                            rgi_fp=input.rgi_fp,\n",
    "                           rgi_fp = '/Users/davidrounce/Documents/Dave_Rounce/HiMAT/RGI/rgi60/00_rgi60_attribs/',\n",
    "                           rgi_cols_drop=['GLIMSId','BgnDate','EndDate','Status','Connect','Linkages','Name'],\n",
    "                           rgi_O1Id_colname='glacno',\n",
    "                           rgi_glacno_float_colname='RGIId_float',\n",
    "                           indexname='GlacNo'):\n",
    "    \"\"\"\n",
    "    Select all glaciers to be used in the model run according to the regions and glacier numbers defined by the RGI\n",
    "    glacier inventory. This function returns the rgi table associated with all of these glaciers.\n",
    "\n",
    "    glac_no : list of strings\n",
    "        list of strings of RGI glacier numbers (e.g., ['1.00001', '13.00001'])\n",
    "    rgi_regionsO1 : list of integers\n",
    "        list of integers of RGI order 1 regions (e.g., [1, 13])\n",
    "    rgi_regionsO2 : list of integers or 'all'\n",
    "        list of integers of RGI order 2 regions or simply 'all' for all the order 2 regions\n",
    "    rgi_glac_number : list of strings\n",
    "        list of RGI glacier numbers without the region (e.g., ['00001', '00002'])\n",
    "\n",
    "    Output: Pandas DataFrame of the glacier statistics for each glacier in the model run\n",
    "    (rows = GlacNo, columns = glacier statistics)\n",
    "    \"\"\"\n",
    "    if glac_no is not None:\n",
    "        glac_no_byregion = {}\n",
    "        rgi_regionsO1 = [int(i.split('.')[0]) for i in glac_no]\n",
    "        rgi_regionsO1 = list(set(rgi_regionsO1))\n",
    "        for region in rgi_regionsO1:\n",
    "            glac_no_byregion[region] = []\n",
    "        for i in glac_no:\n",
    "            region = i.split('.')[0]\n",
    "            glac_no_only = i.split('.')[1]\n",
    "            glac_no_byregion[int(region)].append(glac_no_only)\n",
    "\n",
    "        for region in rgi_regionsO1:\n",
    "            glac_no_byregion[region] = sorted(glac_no_byregion[region])\n",
    "\n",
    "    # Create an empty dataframe\n",
    "    rgi_regionsO1 = sorted(rgi_regionsO1)\n",
    "    glacier_table = pd.DataFrame()\n",
    "    for region in rgi_regionsO1:\n",
    "\n",
    "        if glac_no is not None:\n",
    "            rgi_glac_number = glac_no_byregion[region]\n",
    "\n",
    "#        if len(rgi_glac_number) < 50:\n",
    "\n",
    "        for i in os.listdir(rgi_fp):\n",
    "            if i.startswith(str(region).zfill(2)) and i.endswith('.csv'):\n",
    "                rgi_fn = i\n",
    "        try:\n",
    "            csv_regionO1 = pd.read_csv(rgi_fp + rgi_fn)\n",
    "        except:\n",
    "            csv_regionO1 = pd.read_csv(rgi_fp + rgi_fn, encoding='latin1')\n",
    "        \n",
    "        # Populate glacer_table with the glaciers of interest\n",
    "        if rgi_regionsO2 == 'all' and rgi_glac_number == 'all':\n",
    "            print(\"All glaciers within region(s) %s are included in this model run.\" % (region))\n",
    "            if glacier_table.empty:\n",
    "                glacier_table = csv_regionO1\n",
    "            else:\n",
    "                glacier_table = pd.concat([glacier_table, csv_regionO1], axis=0)\n",
    "        elif rgi_regionsO2 != 'all' and rgi_glac_number == 'all':\n",
    "            print(\"All glaciers within subregion(s) %s in region %s are included in this model run.\" %\n",
    "                  (rgi_regionsO2, region))\n",
    "            for regionO2 in rgi_regionsO2:\n",
    "                if glacier_table.empty:\n",
    "                    glacier_table = csv_regionO1.loc[csv_regionO1['O2Region'] == regionO2]\n",
    "                else:\n",
    "                    glacier_table = (pd.concat([glacier_table, csv_regionO1.loc[csv_regionO1['O2Region'] ==\n",
    "                                                                                regionO2]], axis=0))\n",
    "        else:\n",
    "            if len(rgi_glac_number) < 20:\n",
    "                print(\"%s glaciers in region %s are included in this model run: %s\" % (len(rgi_glac_number), region,\n",
    "                                                                                       rgi_glac_number))\n",
    "            else:\n",
    "                print(\"%s glaciers in region %s are included in this model run: %s and more\" %\n",
    "                      (len(rgi_glac_number), region, rgi_glac_number[0:50]))\n",
    "                \n",
    "            rgiid_subset = ['RGI60-' + str(region).zfill(2) + '.' + x for x in rgi_glac_number] \n",
    "            rgiid_all = list(csv_regionO1.RGIId.values)\n",
    "            rgi_idx = [rgiid_all.index(x) for x in rgiid_subset]\n",
    "            if glacier_table.empty:\n",
    "                glacier_table = csv_regionO1.loc[rgi_idx]\n",
    "            else:\n",
    "                glacier_table = (pd.concat([glacier_table, csv_regionO1.loc[rgi_idx]],\n",
    "                                           axis=0))\n",
    "                    \n",
    "    glacier_table = glacier_table.copy()\n",
    "    # reset the index so that it is in sequential order (0, 1, 2, etc.)\n",
    "    glacier_table.reset_index(inplace=True)\n",
    "    # change old index to 'O1Index' to be easier to recall what it is\n",
    "    glacier_table.rename(columns={'index': 'O1Index'}, inplace=True)\n",
    "    # Record the reference date\n",
    "    glacier_table['RefDate'] = glacier_table['BgnDate']\n",
    "    # if there is an end date, then roughly average the year\n",
    "    enddate_idx = glacier_table.loc[(glacier_table['EndDate'] > 0), 'EndDate'].index.values\n",
    "    glacier_table.loc[enddate_idx,'RefDate'] = (\n",
    "            np.mean((glacier_table.loc[enddate_idx,['BgnDate', 'EndDate']].values / 10**4).astype(int),\n",
    "                    axis=1).astype(int) * 10**4 + 9999)\n",
    "    # drop columns of data that is not being used\n",
    "    glacier_table.drop(rgi_cols_drop, axis=1, inplace=True)\n",
    "    # add column with the O1 glacier numbers\n",
    "    glacier_table[rgi_O1Id_colname] = (\n",
    "            glacier_table['RGIId'].str.split('.').apply(pd.Series).loc[:,1].astype(int))\n",
    "    glacier_table['rgino_str'] = [x.split('-')[1] for x in glacier_table.RGIId.values]\n",
    "    glacier_table[rgi_glacno_float_colname] = (np.array([np.str.split(glacier_table['RGIId'][x],'-')[1]\n",
    "                                                    for x in range(glacier_table.shape[0])]).astype(float))\n",
    "    # set index name\n",
    "    glacier_table.index.name = indexname\n",
    "\n",
    "    print(\"This study is focusing on %s glaciers in region %s\" % (glacier_table.shape[0], rgi_regionsO1))\n",
    "\n",
    "    return glacier_table\n",
    "\n",
    "\n",
    "def nearest_nonzero_idx(a,x,y):\n",
    "    r,c = np.nonzero(a)\n",
    "    min_idx = ((r - x)**2 + (c - y)**2).argmin()\n",
    "    return r[min_idx], c[min_idx]\n",
    "\n",
    "\n",
    "def emergence_pixels(gf, vel_x_raw, vel_y_raw, icethickness_raw, xres, yres, \n",
    "                     vel_min=0, max_velocity=600, vel_depth_avg_factor=0.8, option_border=1,\n",
    "                     positive_is_east=True, positive_is_north=True, constant_icethickness=False, debug=True):\n",
    "    \"\"\" Compute the emergence velocity using an ice flux approach\n",
    "    \"\"\"\n",
    "    # Glacier mask\n",
    "    glac_mask = np.zeros(vel_x_raw.shape) + 1\n",
    "    glac_mask[gf.z1.mask] = 0\n",
    "    \n",
    "    # Modify vel_y by multiplying velocity by -1 such that matrix operations agree with flow direction\n",
    "    #    Specifically, a negative y velocity means the pixel is flowing south.\n",
    "    #    However, if you were to subtract that value from the rows, it would head north in the matrix.\n",
    "    #    This is due to the fact that the number of rows start at 0 at the top.\n",
    "    #    Therefore, multipylying by -1 aligns the matrix operations with the flow direction\n",
    "    if positive_is_north:\n",
    "        vel_y = -1*vel_y_raw * vel_depth_avg_factor\n",
    "    else:\n",
    "        vel_y = vel_y_raw * vel_depth_avg_factor\n",
    "    if positive_is_east:\n",
    "        vel_x = vel_x_raw * vel_depth_avg_factor\n",
    "    else:\n",
    "        vel_x = -1*vel_x_raw * vel_depth_avg_factor\n",
    "    vel_total = (vel_y**2 + vel_x**2)**0.5\n",
    "    # Ice thickness\n",
    "    icethickness = icethickness_raw.copy()\n",
    "    if constant_icethickness:\n",
    "        icethickness[:,:] = 1\n",
    "        icethickness = icethickness * glac_mask\n",
    "#     print('mean ice thickness:', np.round(icethickness.mean(),0), 'm')\n",
    "    # Compute the initial volume\n",
    "    volume_initial = icethickness * (xres * yres)\n",
    "    pix_maxres = xres\n",
    "    if yres > pix_maxres:\n",
    "        pix_maxres = yres\n",
    "    # Quality control options:\n",
    "    # Apply a border based on the max specified velocity to prevent errors associated with pixels going out of bounds\n",
    "    if option_border == 1:\n",
    "        border = int(max_velocity / pix_maxres) + 1\n",
    "        for r in range(vel_x.shape[0]):\n",
    "            for c in range(vel_x.shape[1]):\n",
    "                if (r < border) | (r >= vel_x.shape[0] - border) | (c < border) | (c >= vel_x.shape[1] - border):\n",
    "                    vel_x[r,c] = 0\n",
    "                    vel_y[r,c] = 0\n",
    "    # Minimum/maximum velocity bounds\n",
    "    vel_x[vel_total < vel_min] = 0\n",
    "    vel_y[vel_total < vel_min] = 0\n",
    "    vel_x[vel_total > max_velocity] = 0\n",
    "    vel_y[vel_total > max_velocity] = 0\n",
    "#     # Remove clusters of high velocity on stagnant portions of glaciers due to feature tracking of ice cliffs and ponds\n",
    "#     if option_stagnantbands == 1:\n",
    "#         vel_x[bands <= stagnant_band] = 0\n",
    "#         vel_y[bands <= stagnant_band] = 0        \n",
    "    # Compute displacement in units of pixels\n",
    "    vel_x_pix = vel_x / xres\n",
    "    vel_y_pix = vel_y / yres\n",
    "    # Compute the displacement and fraction of pixels moved for all columns (x-axis)\n",
    "    # col_x1 is the number of columns to the closest pixel receiving ice [ex. 2.6 returns 2, -2.6 returns -2]\n",
    "    #    int() automatically rounds towards zero\n",
    "    col_x1 = vel_x_pix.astype(int)\n",
    "    # col_x2 is the number of columns to the further pixel receiving ice [ex. 2.6 returns 3, -2.6 returns -3]\n",
    "    #    np.sign() returns a value of 1 or -1, so it's adding 1 pixel away from zero\n",
    "    col_x2 = (vel_x_pix + np.sign(vel_x_pix)).astype(int)\n",
    "    # rem_x2 is the fraction of the pixel that remains in the further pixel (col_x2) [ex. 2.6 returns 0.6, -2.6 returns 0.6]\n",
    "    #    np.sign() returns a value of 1 or -1, so multiplying by that ensures you have a positive value\n",
    "    #    then when you take the remainder using \"% 1\", you obtain the desired fraction\n",
    "    rem_x2 = np.multiply(np.sign(vel_x_pix), vel_x_pix) % 1\n",
    "    # rem_x1 is the fraction of the pixel that remains in the closer pixel (col_x1) [ex. 2.6 returns 0.4, -2.6 returns 0.4]\n",
    "    rem_x1 = 1 - rem_x2\n",
    "    # Repeat the displacement and fraction computations for all rows (y-axis)\n",
    "    row_y1 = vel_y_pix.astype(int)\n",
    "    row_y2 = (vel_y_pix + np.sign(vel_y_pix)).astype(int)\n",
    "    rem_y2 = np.multiply(np.sign(vel_y_pix), vel_y_pix) % 1\n",
    "    rem_y1 = 1 - rem_y2\n",
    "          \n",
    "    # Compute the mass flux for each pixel\n",
    "    volume_final = np.zeros(volume_initial.shape)\n",
    "    for r in range(vel_x.shape[0]):\n",
    "        for c in range(vel_x.shape[1]):\n",
    "            volume_final[r+row_y1[r,c], c+col_x1[r,c]] = (\n",
    "                volume_final[r+row_y1[r,c], c+col_x1[r,c]] + rem_y1[r,c]*rem_x1[r,c]*volume_initial[r,c]\n",
    "                )\n",
    "            volume_final[r+row_y2[r,c], c+col_x1[r,c]] = (\n",
    "                volume_final[r+row_y2[r,c], c+col_x1[r,c]] + rem_y2[r,c]*rem_x1[r,c]*volume_initial[r,c]\n",
    "                )\n",
    "            volume_final[r+row_y1[r,c], c+col_x2[r,c]] = (\n",
    "                volume_final[r+row_y1[r,c], c+col_x2[r,c]] + rem_y1[r,c]*rem_x2[r,c]*volume_initial[r,c]\n",
    "                )\n",
    "            volume_final[r+row_y2[r,c], c+col_x2[r,c]] = (\n",
    "                volume_final[r+row_y2[r,c], c+col_x2[r,c]] + rem_y2[r,c]*rem_x2[r,c]*volume_initial[r,c]\n",
    "                )\n",
    "         \n",
    "    # Redistribute off-glacier volume back onto the nearest pixel on the glacier\n",
    "    offglac_row, offglac_col = np.where((glac_mask == 0) & (volume_final > 0))\n",
    "    for nidx in range(0,len(offglac_row)):\n",
    "        nrow = offglac_row[nidx]\n",
    "        ncol = offglac_col[nidx]\n",
    "        ridx, cidx = nearest_nonzero_idx(glac_mask, nrow, ncol)\n",
    "        # Add off-glacier volume back onto nearest pixel on glacier\n",
    "        volume_final[ridx,cidx] += volume_final[nrow,ncol]\n",
    "        volume_final[nrow,ncol] = 0\n",
    "            \n",
    "    # Check that mass is conserved (threshold = 0.1 m x pixel_size**2)\n",
    "    if debug:\n",
    "        print('Mass is conserved?', np.absolute(volume_final.sum() - volume_initial.sum()) / volume_initial.sum() < 0.01)\n",
    "        print(np.round(np.absolute(volume_final.sum() - volume_initial.sum()),1), \n",
    "              np.round(np.absolute(volume_final.sum() - volume_initial.sum()) / volume_initial.sum() * 100,2), '%')\n",
    "        \n",
    "    if np.absolute(volume_final.sum() - volume_initial.sum()) / volume_initial.sum() > 0.01:\n",
    "        print('MASS NOT CONSERVED FOR EMERGENCE VELOCITY')\n",
    "    # Final ice thickness\n",
    "    icethickness_final = volume_final / (xres * yres)\n",
    "    # Emergence velocity\n",
    "    emergence_velocity = icethickness_final - icethickness\n",
    "    return emergence_velocity\n",
    "\n",
    "\n",
    "\n",
    "class GlacFeat:\n",
    "    def __init__(self, feat, glacname_fieldname, glacnum_fieldname):\n",
    "\n",
    "        self.glacname = feat.GetField(glacname_fieldname)\n",
    "        if self.glacname is None:\n",
    "            self.glacname = \"\"\n",
    "        else:\n",
    "            #RGI has some nonstandard characters\n",
    "            #self.glacname = self.glacname.decode('unicode_escape').encode('ascii','ignore')\n",
    "            #glacname = re.sub(r'[^\\x00-\\x7f]',r'', glacname)\n",
    "            self.glacname = re.sub(r'\\W+', '', self.glacname)\n",
    "            self.glacname = self.glacname.replace(\" \", \"\")\n",
    "            self.glacname = self.glacname.replace(\"_\", \"\")\n",
    "            self.glacname = self.glacname.replace(\"/\", \"\")\n",
    "\n",
    "        self.glacnum = feat.GetField(glacnum_fieldname)\n",
    "        fn = feat.GetDefnRef().GetName()\n",
    "        #RGIId (String) = RGI50-01.00004\n",
    "        self.glacnum = '%0.5f' % float(self.glacnum.split('-')[-1])\n",
    "\n",
    "        if self.glacname:\n",
    "            self.feat_fn = \"%s_%s\" % (self.glacnum, self.glacname)\n",
    "        else:\n",
    "            self.feat_fn = str(self.glacnum)\n",
    "\n",
    "        self.glac_geom_orig = geolib.geom_dup(feat.GetGeometryRef())\n",
    "        self.glac_geom = geolib.geom_dup(self.glac_geom_orig)\n",
    "        #Hack to deal with fact that this is not preserved in geom when loaded from pickle on disk\n",
    "        self.glac_geom_srs_wkt = self.glac_geom.GetSpatialReference().ExportToWkt()\n",
    "\n",
    "        #Attributes written by mb_calc\n",
    "        self.z1 = None\n",
    "        self.z1_hs = None\n",
    "        self.z1_stats = None\n",
    "        self.z1_ela = None\n",
    "        self.z2 = None\n",
    "        self.z2_hs = None\n",
    "        self.z2_stats = None\n",
    "        self.z2_ela = None\n",
    "        self.z2_aspect = None\n",
    "        self.z2_aspect_stats = None\n",
    "        self.z2_slope = None\n",
    "        self.z2_slope_stats = None\n",
    "        self.res = None\n",
    "        self.dhdt = None\n",
    "        self.mb = None\n",
    "        self.mb_mean = None\n",
    "        self.t1 = None\n",
    "        self.t2 = None\n",
    "        self.dt = None\n",
    "        self.t1_mean = None\n",
    "        self.t2_mean = None\n",
    "        self.dt_mean = None\n",
    "\n",
    "        self.H = None\n",
    "        self.H_mean = np.nan\n",
    "        self.vx = None\n",
    "        self.vy = None\n",
    "        self.vm = None\n",
    "        self.vm_mean = np.nan\n",
    "        self.divQ = None\n",
    "        self.emvel = None\n",
    "        self.debris_class = None\n",
    "        self.debris_thick = None\n",
    "        self.debris_thick_mean = np.nan\n",
    "        self.perc_clean = np.nan\n",
    "        self.perc_debris = np.nan\n",
    "        self.perc_pond = np.nan\n",
    "\n",
    "    def geom_srs_update(self, srs=None):\n",
    "        if self.glac_geom.GetSpatialReference() is None:\n",
    "            if srs is None:\n",
    "                srs = osr.SpatialReference()\n",
    "                srs.ImportFromWkt(self.glac_geom_srs_wkt)\n",
    "            self.glac_geom.AssignSpatialReference(srs)\n",
    "\n",
    "    def geom_attributes(self, srs=None):\n",
    "        self.geom_srs_update()\n",
    "        if srs is not None:\n",
    "            #Should reproject here to equal area, before geom_attributes\n",
    "            #self.glac_geom.AssignSpatialReference(glac_shp_srs)\n",
    "            #self.glac_geom_local = geolib.geom2localortho(self.glac_geom)\n",
    "            geolib.geom_transform(self.glac_geom, srs)\n",
    "\n",
    "        self.glac_geom_extent = geolib.geom_extent(self.glac_geom)\n",
    "        self.glac_area = self.glac_geom.GetArea()\n",
    "        self.glac_area_km2 = self.glac_area / 1E6\n",
    "        self.cx, self.cy = self.glac_geom.Centroid().GetPoint_2D()\n",
    "        \n",
    "        \n",
    "#RGI uses 50 m bins\n",
    "def hist_plot(gf, bin_width=50.0, dz_clim=(-2.0, 2.0), exportcsv=True, csv_ending=''):\n",
    "    #print(\"Generating histograms\")\n",
    "    #Create bins for full range of input data and specified bin width\n",
    "\n",
    "    #NOTE: these counts/areas are for valid pixels only\n",
    "    #Not necessarily a true representation of actual glacier hypsometry\n",
    "    #Need a void-filled DEM for this\n",
    "\n",
    "    z_bin_edges, z_bin_centers = malib.get_bins(gf.z1, bin_width)\n",
    "    #Need to compress here, otherwise histogram uses masked values!\n",
    "    z1_bin_counts, z1_bin_edges = np.histogram(gf.z1.compressed(), bins=z_bin_edges)\n",
    "    z1_bin_areas = z1_bin_counts * gf.res[0] * gf.res[1] / 1E6\n",
    "    #RGI standard is integer thousandths of glaciers total area\n",
    "    #Should check to make sure sum of bin areas equals total area\n",
    "    #z1_bin_areas_perc = 100. * z1_bin_areas / np.sum(z1_bin_areas)\n",
    "    z1_bin_areas_perc = 100. * (z1_bin_areas / gf.glac_area_km2)\n",
    "\n",
    "    #If we only have one elevation grid with dhdt\n",
    "    if gf.z2 is not None:\n",
    "        z2_bin_counts, z2_bin_edges = np.histogram(gf.z2.compressed(), bins=z_bin_edges)\n",
    "        z2_bin_areas = z2_bin_counts * gf.res[0] * gf.res[1] / 1E6\n",
    "        #z2_bin_areas_perc = 100. * z2_bin_areas / np.sum(z2_bin_areas)\n",
    "        z2_bin_areas_perc = 100. * (z1_bin_areas / gf.glac_area_km2)\n",
    "    else:\n",
    "        z2_bin_counts = z1_bin_counts\n",
    "        z2_bin_edges = z1_bin_edges\n",
    "        z2_bin_areas = z1_bin_areas\n",
    "        z2_bin_areas_perc = z1_bin_areas_perc\n",
    "\n",
    "    #Create arrays to store output\n",
    "    slope_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "    slope_bin_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "    aspect_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "    aspect_bin_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "    if gf.dhdt is not None:\n",
    "        mb_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "        np.ma.set_fill_value(mb_bin_med, np.nan)\n",
    "        mb_bin_mad = np.ma.masked_all_like(mb_bin_med)\n",
    "        mb_bin_mean = np.ma.masked_all_like(mb_bin_med)\n",
    "        mb_bin_std = np.ma.masked_all_like(mb_bin_med)\n",
    "        dhdt_bin_med = np.ma.masked_all_like(mb_bin_med)\n",
    "        dhdt_bin_mad = np.ma.masked_all_like(mb_bin_med)\n",
    "        dhdt_bin_mean = np.ma.masked_all_like(mb_bin_med)\n",
    "        dhdt_bin_std = np.ma.masked_all_like(mb_bin_med)\n",
    "        dhdt_bin_count = np.ma.masked_all_like(mb_bin_med)\n",
    "    if gf.vm is not None:\n",
    "        vm_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "        vm_bin_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "    if gf.H is not None:\n",
    "        H_bin_mean = np.ma.masked_all_like(z1_bin_areas)\n",
    "        H_bin_std = np.ma.masked_all_like(z1_bin_areas)\n",
    "    if gf.emvel is not None:\n",
    "        emvel_bin_mean = np.ma.masked_all_like(z1_bin_areas)\n",
    "        emvel_bin_std = np.ma.masked_all_like(z1_bin_areas)\n",
    "        emvel_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "        emvel_bin_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "    if gf.debris_class is not None:\n",
    "#         perc_clean = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         perc_debris = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         perc_pond = np.ma.masked_all_like(z1_bin_areas)\n",
    "        debris_thick_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "        debris_thick_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         dhdt_clean_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         dhdt_debris_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         dhdt_pond_bin_med = np.ma.masked_all_like(mz1_bin_areas)\n",
    "\n",
    "#         gf.dhdt_clean = np.ma.array(gf.dhdt, mask=~((gf.debris_class == 1).data))\n",
    "#         gf.dhdt_debris = np.ma.array(gf.dhdt, mask=~((gf.debris_class == 2).data))\n",
    "#         gf.dhdt_pond = np.ma.array(gf.dhdt, mask=~((gf.debris_class == 3).data))\n",
    "\n",
    "    if gf.debris_thick_ts is not None:\n",
    "        debris_thick_ts_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "        debris_thick_ts_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "    if gf.meltfactor_ts is not None:\n",
    "        meltfactor_ts_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "        meltfactor_ts_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "\n",
    "    #Bin sample count must be greater than this value\n",
    "    min_bin_samp_count = 9\n",
    "\n",
    "    #Loop through each bin and extract stats\n",
    "    idx = np.digitize(gf.z1, z_bin_edges)\n",
    "    for bin_n in range(z_bin_centers.size):\n",
    "        if gf.dhdt is not None:\n",
    "            mb_bin_samp = gf.mb_map[(idx == bin_n+1)]\n",
    "            if mb_bin_samp.count() > min_bin_samp_count:\n",
    "                mb_bin_med[bin_n] = malib.fast_median(mb_bin_samp)\n",
    "                mb_bin_mad[bin_n] = malib.mad(mb_bin_samp)\n",
    "                mb_bin_mean[bin_n] = mb_bin_samp.mean()\n",
    "                mb_bin_std[bin_n] = mb_bin_samp.std()\n",
    "            dhdt_bin_samp = gf.dhdt[(idx == bin_n+1)]\n",
    "            if dhdt_bin_samp.count() > min_bin_samp_count:\n",
    "                dhdt_bin_med[bin_n] = malib.fast_median(dhdt_bin_samp)\n",
    "                dhdt_bin_mad[bin_n] = malib.mad(dhdt_bin_samp)\n",
    "                dhdt_bin_mean[bin_n] = dhdt_bin_samp.mean()\n",
    "                dhdt_bin_std[bin_n] = dhdt_bin_samp.std()\n",
    "                dhdt_bin_count[bin_n] = dhdt_bin_samp.count()\n",
    "        if gf.debris_thick is not None:\n",
    "            debris_thick_bin_samp = gf.debris_thick[(idx == bin_n+1)]\n",
    "            if debris_thick_bin_samp.size > min_bin_samp_count:\n",
    "                debris_thick_med[bin_n] = malib.fast_median(debris_thick_bin_samp)\n",
    "                debris_thick_mad[bin_n] = malib.mad(debris_thick_bin_samp)\n",
    "        \n",
    "        if gf.debris_thick_ts is not None:\n",
    "            debris_thick_ts_bin_samp = gf.debris_thick_ts[(idx == bin_n+1)]\n",
    "            if debris_thick_ts_bin_samp.size > min_bin_samp_count:\n",
    "                debris_thick_ts_med[bin_n] = malib.fast_median(debris_thick_ts_bin_samp)\n",
    "                debris_thick_ts_mad[bin_n] = malib.mad(debris_thick_ts_bin_samp)\n",
    "        if gf.meltfactor_ts is not None:\n",
    "            meltfactor_ts_bin_samp = gf.meltfactor_ts[(idx == bin_n+1)]\n",
    "            if meltfactor_ts_bin_samp.size > min_bin_samp_count:\n",
    "                meltfactor_ts_med[bin_n] = malib.fast_median(meltfactor_ts_bin_samp)\n",
    "                meltfactor_ts_mad[bin_n] = malib.mad(meltfactor_ts_bin_samp)\n",
    "                \n",
    "        if gf.debris_class is not None:\n",
    "            debris_class_bin_samp = gf.debris_class[(idx == bin_n+1)]\n",
    "            dhdt_clean_bin_samp = gf.dhdt_clean[(idx == bin_n+1)]\n",
    "            dhdt_debris_bin_samp = gf.dhdt_debris[(idx == bin_n+1)]\n",
    "            dhdt_pond_bin_samp = gf.dhdt_pond[(idx == bin_n+1)]\n",
    "            if debris_class_bin_samp.count() > min_bin_samp_count:\n",
    "                perc_clean[bin_n] = 100. * (debris_class_bin_samp == 1).sum()/debris_class_bin_samp.count()\n",
    "                perc_debris[bin_n] = 100. * (debris_class_bin_samp == 2).sum()/debris_class_bin_samp.count()\n",
    "                perc_pond[bin_n] = 100. * (debris_class_bin_samp == 3).sum()/debris_class_bin_samp.count()\n",
    "            if dhdt_clean_bin_samp.count() > min_bin_samp_count:\n",
    "                dhdt_clean_bin_med[bin_n] = malib.fast_median(dhdt_clean_bin_samp)\n",
    "            if dhdt_debris_bin_samp.count() > min_bin_samp_count:\n",
    "                dhdt_debris_bin_med[bin_n] = malib.fast_median(dhdt_debris_bin_samp)\n",
    "            if dhdt_pond_bin_samp.count() > min_bin_samp_count:\n",
    "                dhdt_pond_bin_med[bin_n] = malib.fast_median(dhdt_pond_bin_samp)\n",
    "        if gf.vm is not None:\n",
    "            vm_bin_samp = gf.vm[(idx == bin_n+1)]\n",
    "            if vm_bin_samp.size > min_bin_samp_count:\n",
    "                vm_bin_med[bin_n] = malib.fast_median(vm_bin_samp)\n",
    "                vm_bin_mad[bin_n] = malib.mad(vm_bin_samp)\n",
    "        if gf.H is not None:\n",
    "            H_bin_samp = gf.H[(idx == bin_n+1)]\n",
    "            if H_bin_samp.size > min_bin_samp_count:\n",
    "                H_bin_mean[bin_n] = H_bin_samp.mean()\n",
    "                H_bin_std[bin_n] = H_bin_samp.std()\n",
    "        if gf.emvel is not None:\n",
    "            emvel_bin_samp = gf.emvel[(idx == bin_n+1)]\n",
    "            if emvel_bin_samp.size > min_bin_samp_count:\n",
    "                emvel_bin_mean[bin_n] = emvel_bin_samp.mean()\n",
    "                emvel_bin_std[bin_n] = emvel_bin_samp.std()\n",
    "                emvel_bin_med[bin_n] = malib.fast_median(emvel_bin_samp)\n",
    "                emvel_bin_mad[bin_n] = malib.mad(emvel_bin_samp)\n",
    "        slope_bin_samp = gf.z1_slope[(idx == bin_n+1)]\n",
    "        if slope_bin_samp.size > min_bin_samp_count:\n",
    "            slope_bin_med[bin_n] = malib.fast_median(slope_bin_samp)\n",
    "            slope_bin_mad[bin_n] = malib.mad(slope_bin_samp)\n",
    "        aspect_bin_samp = gf.z1_aspect[(idx == bin_n+1)]\n",
    "        if aspect_bin_samp.size > min_bin_samp_count:\n",
    "            aspect_bin_med[bin_n] = malib.fast_median(aspect_bin_samp)\n",
    "            aspect_bin_mad[bin_n] = malib.mad(aspect_bin_samp)\n",
    "\n",
    "    if gf.dhdt is not None:\n",
    "        dhdt_bin_areas = dhdt_bin_count * gf.res[0] * gf.res[1] / 1E6\n",
    "        #dhdt_bin_areas_perc = 100. * dhdt_bin_areas / np.sum(dhdt_bin_areas)\n",
    "        dhdt_bin_areas_perc = 100. * (dhdt_bin_areas / gf.glac_area_km2)\n",
    "\n",
    "    outbins_header = 'bin_center_elev_m, z1_bin_count_valid, z1_bin_area_valid_km2, z1_bin_area_perc, z2_bin_count_valid, z2_bin_area_valid_km2, z2_bin_area_perc, slope_bin_med, aspect_bin_med'\n",
    "    fmt = '%0.1f, %0.0f, %0.3f, %0.2f, %0.0f, %0.3f, %0.2f, %0.2f, %0.2f'\n",
    "    outbins = [z_bin_centers, z1_bin_counts, z1_bin_areas, z1_bin_areas_perc, z2_bin_counts, z2_bin_areas, z2_bin_areas_perc, slope_bin_med, aspect_bin_med]\n",
    "    if gf.dhdt is not None:\n",
    "        outbins_header += ', dhdt_bin_count, dhdt_bin_area_valid_km2, dhdt_bin_area_perc, dhdt_bin_med_ma, dhdt_bin_mad_ma, dhdt_bin_mean_ma, dhdt_bin_std_ma, mb_bin_med_mwea, mb_bin_mad_mwea, mb_bin_mean_mwea, mb_bin_std_mwea'\n",
    "        fmt += ', %0.0f, %0.3f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f'\n",
    "        outbins.extend([dhdt_bin_count, dhdt_bin_areas, dhdt_bin_areas_perc, dhdt_bin_med, dhdt_bin_mad, dhdt_bin_mean, dhdt_bin_std, \\\n",
    "                        mb_bin_med, mb_bin_mad, mb_bin_mean, mb_bin_std])\n",
    "    if gf.debris_thick is not None:\n",
    "        outbins_header += ', debris_thick_med_m, debris_thick_mad_m'\n",
    "        fmt += ', %0.2f, %0.2f'\n",
    "        debris_thick_med[debris_thick_med == -(np.inf)] = 0.00\n",
    "        debris_thick_mad[debris_thick_mad == -(np.inf)] = 0.00\n",
    "        outbins.extend([debris_thick_med, debris_thick_mad])\n",
    "    \n",
    "    if gf.debris_thick_ts is not None:\n",
    "        outbins_header += ',debris_thick_ts_med_m,debris_thick_ts_mad_m'\n",
    "        fmt += ', %0.2f, %0.2f'\n",
    "        debris_thick_ts_med[debris_thick_ts_med == -(np.inf)] = 0.00\n",
    "        debris_thick_ts_mad[debris_thick_ts_mad == -(np.inf)] = 0.00\n",
    "        outbins.extend([debris_thick_ts_med, debris_thick_ts_mad])\n",
    "    if gf.meltfactor_ts is not None:\n",
    "        outbins_header += ',meltfactor_ts_med_m,meltfactor_ts_mad_m'\n",
    "        fmt += ', %0.2f, %0.2f'\n",
    "        meltfactor_ts_med[meltfactor_ts_med == -(np.inf)] = 1\n",
    "        meltfactor_ts_med[meltfactor_ts_med > 1] = 1\n",
    "        meltfactor_ts_med[meltfactor_ts_med <= 0] = 1\n",
    "        meltfactor_ts_mad[meltfactor_ts_mad == -(np.inf)] = 0\n",
    "        meltfactor_ts_mad[meltfactor_ts_mad > 1] = 0\n",
    "        meltfactor_ts_mad[meltfactor_ts_mad <= 0] = 0\n",
    "        outbins.extend([meltfactor_ts_med, meltfactor_ts_mad])\n",
    "    \n",
    "    if gf.debris_class is not None:\n",
    "        outbins_header += ', perc_debris, perc_pond, perc_clean, dhdt_debris_med, dhdt_pond_med, dhdt_clean_med'\n",
    "        fmt += ', %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f'\n",
    "        outbins.extend([perc_debris, perc_pond, perc_clean, dhdt_debris_bin_med, dhdt_pond_bin_med, dhdt_clean_bin_med])\n",
    "    if gf.vm is not None:\n",
    "        outbins_header += ', vm_med, vm_mad'\n",
    "        fmt += ', %0.2f, %0.2f'\n",
    "        outbins.extend([vm_bin_med, vm_bin_mad])\n",
    "    if gf.H is not None:\n",
    "        outbins_header += ', H_mean, H_std'\n",
    "        fmt += ', %0.2f, %0.2f'\n",
    "        outbins.extend([H_bin_mean, H_bin_std])\n",
    "#         outbins_header += ', H_mean, H_std, emvel_mean, emvel_std'\n",
    "#         fmt += ', %0.2f, %0.2f, %0.2f, %0.2f'\n",
    "#         outbins.extend([H_bin_mean, H_bin_std, emvel_bin_mean, emvel_bin_std])\n",
    "\n",
    "    if gf.emvel is not None:\n",
    "        outbins_header += ', emvel_mean, emvel_std, emvel_med, emvel_mad'\n",
    "        fmt += ', %0.3f, %0.3f, %0.3f, %0.3f'\n",
    "        outbins.extend([emvel_bin_mean, emvel_bin_std, emvel_bin_med, emvel_bin_mad])\n",
    "\n",
    "    outbins = np.ma.array(outbins).T.astype('float32')\n",
    "    np.ma.set_fill_value(outbins, np.nan)\n",
    "    outbins = outbins.filled(np.nan)\n",
    "    if exportcsv:\n",
    "        outbins_fn = os.path.join(outdir_csv, gf.feat_fn[0:8] + csv_ending)\n",
    "        np.savetxt(outbins_fn, outbins, fmt=fmt, delimiter=',', header=outbins_header)\n",
    "\n",
    "#     #Create plots of elevation bins\n",
    "#     #print(\"Generating aed plot\")\n",
    "#     #f,axa = plt.subplots(1,2, figsize=(6, 6))\n",
    "#     nsubplots = 0\n",
    "#     if gf.dhdt is not None:\n",
    "#         nsubplots += 1\n",
    "#     if gf.debris_thick is not None:\n",
    "#         nsubplots += 1\n",
    "#     if gf.vm is not None:\n",
    "#         nsubplots += 1\n",
    "#     if gf.H is not None:\n",
    "#         nsubplots += 1\n",
    "# #     print(nsubplots)\n",
    "#     f,axa = plt.subplots(1,nsubplots, squeeze=False, figsize=(10, 7.5))\n",
    "#     f.suptitle(gf.feat_fn)\n",
    "#     fs = 9\n",
    "#     nplot = -1\n",
    "#     if gf.dhdt is not None:\n",
    "#         nplot += 1\n",
    "#         axa[0,nplot].plot(z1_bin_areas, z_bin_centers, label='%0.2f' % gf.t1_mean)\n",
    "#         axa[0,nplot].axhline(gf.z1_ela, ls=':', c='C0')\n",
    "#         if gf.z2 is not None:\n",
    "#             axa[0,nplot].plot(z2_bin_areas, z_bin_centers, label='%0.2f' % gf.t2_mean)\n",
    "#             axa[0,nplot].axhline(gf.z2_ela, ls=':', c='C1')\n",
    "#         axa[0,nplot].legend(prop={'size':8}, loc='upper right')\n",
    "#         axa[0,nplot].set_ylabel('Elevation (m WGS84)', fontsize=fs)\n",
    "#         axa[0,nplot].set_xlabel('Area $\\mathregular{km^2}$', fontsize=fs)\n",
    "#         axa[0,nplot].yaxis.set_ticks_position('both')\n",
    "#         # pltlib.minorticks_on(axa[0])\n",
    "\n",
    "#         nplot += 1\n",
    "#         axa[0,nplot].axvline(0, lw=1.0, c='k')\n",
    "#         \"\"\"\n",
    "#         #Plot flux divergence values for each bin\n",
    "#         if gf.vm is not None and gf.H is not None:\n",
    "#             divQ_bin_mean = np.gradient(H_bin_mean * vm_bin_med * v_col_f)\n",
    "#             axa[1].plot(divQ_bin_mean, z_bin_centers, color='green')\n",
    "#         \"\"\"\n",
    "#         axa[0,nplot].plot(mb_bin_med, z_bin_centers, color='k')\n",
    "#         axa[0,nplot].axvline(gf.mb_mean, lw=0.5, ls=':', c='k', label='%0.2f m w.e./yr' % gf.mb_mean)\n",
    "#         axa[0,nplot].fill_betweenx(z_bin_centers, mb_bin_med-mb_bin_mad, mb_bin_med+mb_bin_mad, color='k', alpha=0.1)\n",
    "#         axa[0,nplot].fill_betweenx(z_bin_centers, 0, mb_bin_med, where=(mb_bin_med<0), color='r', alpha=0.2)\n",
    "#         axa[0,nplot].fill_betweenx(z_bin_centers, 0, mb_bin_med, where=(mb_bin_med>0), color='b', alpha=0.2)\n",
    "#         #axa[nplot].set_xlabel('dh/dt (m/yr)')\n",
    "#         axa[0,nplot].set_xlabel('Mass balance (m w.e./yr)', fontsize=fs)\n",
    "#         axa[0,nplot].legend(prop={'size':8}, loc='upper right')\n",
    "#         axa[0,nplot].yaxis.set_ticks_position('both')\n",
    "#         # pltlib.minorticks_on(axa[1])\n",
    "#         #Hide y-axis labels\n",
    "#         axa[0,nplot].axes.yaxis.set_ticklabels([])\n",
    "#         axa[0,nplot].set_xlim(*dz_clim)\n",
    "\n",
    "#     if gf.debris_thick is not None:\n",
    "#         nplot += 1\n",
    "#         axa[0,nplot].errorbar(debris_thick_med*100., z_bin_centers, xerr=debris_thick_mad*100, color='k', fmt='o', ms=3, label='Debris Thickness', alpha=0.6)\n",
    "#     if gf.debris_class is not None:\n",
    "#         axa[0,nplot].plot(perc_debris, z_bin_centers, color='sienna', label='Debris Coverage')\n",
    "#         axa[0,nplot].plot(perc_pond, z_bin_centers, color='turquoise', label='Pond Coverage')\n",
    "#     if gf.debris_thick is not None or gf.debris_class is not None:\n",
    "#         axa[0,nplot].set_xlim(0, 100)\n",
    "#         axa[0,nplot].yaxis.set_ticks_position('both')\n",
    "#         # pltlib.minorticks_on(axa[2])\n",
    "#         axa[0,nplot].axes.yaxis.set_ticklabels([])\n",
    "#         axa[0,nplot].legend(prop={'size':8}, loc='upper right')\n",
    "#         axa[0,nplot].set_xlabel('Debris thickness (cm), coverage (%)', fontsize=fs)\n",
    "\n",
    "#     if gf.H is not None:\n",
    "#         nplot += 1\n",
    "#         axa[0,nplot].plot(H_bin_mean, z_bin_centers, color='b', label='H (%0.2f m)' % gf.H_mean)\n",
    "#         axa[0,nplot].fill_betweenx(z_bin_centers, H_bin_mean-H_bin_std, H_bin_mean+H_bin_std, color='b', alpha=0.1)\n",
    "#         axa[0,nplot].set_xlabel('Ice Thickness (m)', fontsize=fs)\n",
    "#         axa[0,nplot].legend(prop={'size':8}, loc='lower right')\n",
    "#         # pltlib.minorticks_on(axa[3])\n",
    "#         #axa[nplot].set_xlim(0, 400)\n",
    "#         axa[0,nplot].yaxis.tick_left()\n",
    "#         axa[0,nplot].yaxis.set_ticks_position('both')\n",
    "#         axa[0,nplot].yaxis.set_label_position(\"right\")\n",
    "    \n",
    "#     if gf.vm is not None:\n",
    "#         nplot += 1\n",
    "# #         ax4 = axa[0,nplot].twinx()\n",
    "#         axa[0,nplot].set_xlabel('Velocity (m/yr)', fontsize=fs)\n",
    "#         axa[0,nplot].plot(vm_bin_med, z_bin_centers, color='g', label='Vm (%0.2f m/yr)' % gf.vm_mean)\n",
    "#         axa[0,nplot].fill_betweenx(z_bin_centers, vm_bin_med-vm_bin_mad, vm_bin_med+vm_bin_mad, color='g', alpha=0.1)\n",
    "#         #ax4.set_xlim(0, 50)\n",
    "#         axa[0,nplot].xaxis.tick_bottom()\n",
    "#         axa[0,nplot].xaxis.set_label_position(\"bottom\")\n",
    "#         axa[0,nplot].legend(prop={'size':8}, loc='upper right')\n",
    "        \n",
    "#         nplot += 1\n",
    "# #         axa[0,nplot].set_xlabel('divQ (??)', fontsize=fs)\n",
    "# #         axa[0,nplot].plot(vm_bin_med, z_bin_centers, color='g', label='Vm (%0.2f m/yr)' % gf.vm_mean)\n",
    "# #         axa[0,nplot].fill_betweenx(z_bin_centers, vm_bin_med-vm_bin_mad, vm_bin_med+vm_bin_mad, color='g', alpha=0.1)\n",
    "# #         #ax4.set_xlim(0, 50)\n",
    "# #         axa[0,nplot].xaxis.tick_bottom()\n",
    "# #         axa[0,nplot].xaxis.set_label_position(\"bottom\")\n",
    "# #         axa[0,nplot].legend(prop={'size':8}, loc='upper right')\n",
    "# #         gf.divQ\n",
    "    \n",
    "# #     if gf.vm is not None:\n",
    "# #         nplot += 1\n",
    "# # #         ax4 = axa[0,nplot].twinx()\n",
    "# #         axa[0,nplot].set_xlabel('Velocity (m/yr)', fontsize=fs)\n",
    "# #         axa[0,nplot].plot(vm_bin_med, z_bin_centers, color='g', label='Vm (%0.2f m/yr)' % gf.vm_mean)\n",
    "# #         axa[0,nplot].fill_betweenx(z_bin_centers, vm_bin_med-vm_bin_mad, vm_bin_med+vm_bin_mad, color='g', alpha=0.1)\n",
    "# #         #ax4.set_xlim(0, 50)\n",
    "# #         axa[0,nplot].xaxis.tick_bottom()\n",
    "# #         axa[0,nplot].xaxis.set_label_position(\"bottom\")\n",
    "# #         axa[0,nplot].legend(prop={'size':8}, loc='upper right')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     #Make room for suptitle\n",
    "#     plt.subplots_adjust(top=0.95, wspace=0.1)\n",
    "#     #print(\"Saving aed plot\")\n",
    "#     fig_fn = os.path.join(outdir_fig, gf.feat_fn+'_mb_aed.png')\n",
    "#     #plt.savefig(fig_fn, bbox_inches='tight', dpi=300)\n",
    "#     plt.savefig(fig_fn, dpi=300)\n",
    "#     plt.close(f)\n",
    "    \n",
    "    \n",
    "    outbins_df = pd.DataFrame(outbins, columns=outbins_header.split(','))\n",
    "    return outbins_df, z_bin_edges\n",
    "#     return z_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "Compute debris thickness through sub-debris and temperature inversion methods\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "# import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "from pygeotools.lib import malib, warplib, geolib, iolib, timelib\n",
    "# from imview.lib import pltlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/Documents/Dave_Rounce/DebrisGlaciers_WG/Melt_Intercomparison/debris_global/../output/ts_tif/HMA_debris_tsinfo.nc\n"
     ]
    }
   ],
   "source": [
    "import globaldebris_input as input\n",
    "\n",
    "#INPUT\n",
    "# topdir='/Users/davidrounce/Documents/Dave_Rounce/HiMAT/DEMs/'\n",
    "# #Output directory\n",
    "# outdir = topdir + 'Shean_2019_0213/mb_combined_20190213_nmad_bins/'\n",
    "# outdir_fig = outdir + '/figures/'\n",
    "# outdir_csv = outdir + '/csv'\n",
    "\n",
    "verbose=False\n",
    "extra_layers=True\n",
    "min_glac_area_writeout=0\n",
    "min_valid_area_perc = 0\n",
    "buff_dist = 1000\n",
    "bin_width = 5\n",
    "\n",
    "ts_info_fullfn = input.ts_fp + input.roi + '_debris_tsinfo.nc'\n",
    "\n",
    "print(ts_info_fullfn)\n",
    "\n",
    "#INPUT\n",
    "glac_shp_fn_dict = {'13':input.main_directory + '/../../../HiMAT/RGI/rgi60/13_rgi60_CentralAsia/13_rgi60_CentralAsia.shp',\n",
    "                    '14':input.main_directory + '/../../../HiMAT/RGI/rgi60/14_rgi60_SouthAsiaWest/14_rgi60_SouthAsiaWest.shp',\n",
    "                    '15':input.main_directory + '/../../../HiMAT/RGI/rgi60/15_rgi60_SouthAsiaEast/15_rgi60_SouthAsiaEast.shp'}\n",
    "glac_shp_proj_fp = input.output_fp + 'glac_shp_proj/'\n",
    "if os.path.exists(glac_shp_proj_fp) == False:\n",
    "    os.makedirs(glac_shp_proj_fp)\n",
    "\n",
    "#DEM\n",
    "z1_dir_sample = ('/Users/davidrounce/Documents/Dave_Rounce/HiMAT/IceThickness_Farinotti/surface_DEMs_RGI60/' + \n",
    "          'surface_DEMs_RGI60-XXXX/')\n",
    "z1_fn_sample = 'surface_DEM_RGI60-XXXX.tif'\n",
    "# Ice thickness\n",
    "huss_dir_sample = ('/Users/davidrounce/Documents/Dave_Rounce/HiMAT/IceThickness_Farinotti/' + \n",
    "                   'composite_thickness_RGI60-all_regions/RGI60-XXXX/')\n",
    "huss_fn_sample = 'RGI60-XXXX_thickness.tif'\n",
    "\n",
    "if os.path.exists(input.ts_fp) == False:\n",
    "    os.makedirs(input.ts_fp)\n",
    "    \n",
    "outdir_csv = input.outdir_emvel_fp \n",
    "outdir_fig = input.outdir_emvel_fp  + '../figures/'\n",
    "\n",
    "if os.path.exists(glac_shp_proj_fp) == False:\n",
    "    os.makedirs(glac_shp_proj_fp)\n",
    "if os.path.exists(outdir_csv) == False:\n",
    "    os.makedirs(outdir_csv)\n",
    "if os.path.exists(outdir_fig) == False:\n",
    "    os.makedirs(outdir_fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7934\n",
      "4066 glaciers in region 13 are included in this model run: ['00093', '00130', '00135', '00137', '00140', '00147', '00175', '00181', '00183', '00203', '00210', '00277', '00358', '00382', '00386', '00391', '00394', '00400', '00401', '00403', '00439', '00440', '00441', '00465', '00561', '00585', '00594', '00604', '00606', '00611', '00628', '00643', '00693', '00713', '00750', '00751', '00757', '00761', '00763', '00777', '00788', '00809', '00830', '00834', '00838', '00880', '00884', '00885', '00891', '00905'] and more\n",
      "2465 glaciers in region 14 are included in this model run: ['00005', '00018', '00032', '00036', '00043', '00057', '00063', '00072', '00088', '00101', '00104', '00111', '00131', '00142', '00145', '00146', '00159', '00163', '00164', '00187', '00213', '00219', '00222', '00225', '00235', '00243', '00251', '00271', '00287', '00309', '00323', '00326', '00336', '00346', '00347', '00352', '00353', '00363', '00366', '00367', '00370', '00372', '00380', '00398', '00403', '00432', '00449', '00453', '00456', '00466'] and more\n",
      "1403 glaciers in region 15 are included in this model run: ['00024', '00026', '00055', '00057', '00107', '00186', '00194', '00232', '00233', '00234', '00288', '00355', '00356', '00358', '00368', '00372', '00379', '00399', '00406', '00410', '00423', '00475', '00503', '00612', '00617', '00621', '00639', '00642', '00643', '00647', '00648', '00655', '00679', '00726', '00835', '00850', '00855', '00868', '00869', '00872', '00880', '00881', '00885', '00894', '00898', '00899', '00909', '00910', '00911', '00920'] and more\n",
      "This study is focusing on 7934 glaciers in region [13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "rgiid_list = []\n",
    "rgiid_fn_list = []\n",
    "for i in os.listdir(input.mb_binned_fp_wdebris):\n",
    "    if i.endswith('mb_bins_wdebris.csv'):\n",
    "        rgiid_list.append(i[0:8])\n",
    "        rgiid_fn_list.append(i)\n",
    "        \n",
    "rgiid_list = sorted(rgiid_list)\n",
    "rgiid_fn_list = sorted(rgiid_fn_list)\n",
    "\n",
    "print(len(rgiid_list))\n",
    "\n",
    "main_glac_rgi = selectglaciersrgitable(rgiid_list)\n",
    "main_glac_rgi['bin_fn'] = rgiid_fn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group datasets by nearest lat/lon\n",
    "ds = xr.open_dataset(input.debris_elevstats_fullfn)\n",
    "#  argmin() finds the minimum distance between the glacier lat/lon and the GCM pixel\n",
    "lat_nearidx = (np.abs(main_glac_rgi['CenLat'].values[:,np.newaxis] - \n",
    "                      ds['latitude'][:].values).argmin(axis=1))\n",
    "lon_nearidx = (np.abs(main_glac_rgi['CenLon'].values[:,np.newaxis] - \n",
    "                      ds['longitude'][:].values).argmin(axis=1))\n",
    "\n",
    "latlon_nearidx = list(zip(lat_nearidx, lon_nearidx))\n",
    "latlon_nearidx_unique = sorted(list(set(latlon_nearidx)))\n",
    "\n",
    "main_glac_rgi['latlon_nearidx'] = latlon_nearidx\n",
    "latlon_unique_dict = dict(zip(latlon_nearidx_unique,np.arange(0,len(latlon_nearidx_unique))))\n",
    "latlon_unique_dict_reversed = dict(zip(np.arange(0,len(latlon_nearidx_unique)),latlon_nearidx_unique))\n",
    "main_glac_rgi['latlon_unique_no'] = main_glac_rgi['latlon_nearidx'].map(latlon_unique_dict)\n",
    "\n",
    "ds_latlon = ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 45.0 79.25\n",
      "\n",
      "\n",
      "HACK TO BYPASS VALID AREA\n",
      "\n",
      "\n",
      "\n",
      " 1 45.0 79.5\n",
      "\n",
      " 2 45.0 79.75\n",
      "\n",
      " 3 45.0 80.0\n",
      "\n",
      " 4 45.0 80.25\n",
      "\n",
      " 5 45.0 80.5\n",
      "\n",
      " 6 44.75 79.75\n",
      "\n",
      " 7 44.75 80.0\n",
      "\n",
      " 8 44.75 80.5\n",
      "\n",
      " 9 44.75 80.75\n",
      "\n",
      " 10 44.5 80.25\n",
      "\n",
      " 11 44.5 80.5\n",
      "\n",
      " 12 44.25 83.25\n",
      "\n",
      " 13 44.25 83.5\n",
      "\n",
      " 14 44.0 83.25\n",
      "\n",
      " 15 44.0 83.5\n",
      "\n",
      " 16 44.0 83.75\n",
      "\n",
      " 17 44.0 84.0\n",
      "\n",
      " 18 43.75 84.0\n",
      "\n",
      " 19 43.75 84.25\n",
      "\n",
      " 20 43.75 84.5\n",
      "\n",
      " 21 43.75 84.75\n",
      "\n",
      " 22 43.75 85.0\n",
      "\n",
      " 23 43.75 85.25\n",
      "\n",
      " 24 43.75 85.75\n",
      "\n",
      " 25 43.75 88.25\n",
      "\n",
      " 26 43.75 88.5\n",
      "\n",
      " 27 43.5 84.5\n",
      "\n",
      " 28 43.5 84.75\n",
      "\n",
      " 29 43.5 85.0\n",
      "\n",
      " 30 43.5 85.25\n",
      "\n",
      " 31 43.5 85.5\n",
      "\n",
      " 32 43.5 85.75\n",
      "\n",
      " 33 43.5 86.0\n",
      "\n",
      " 34 43.5 89.25\n",
      "\n",
      " 35 43.5 93.25\n",
      "\n",
      " 36 43.25 77.5\n",
      "\n",
      " 37 43.25 83.75\n",
      "\n",
      " 38 43.25 85.0\n",
      "\n",
      " 39 43.25 85.5\n",
      "\n",
      " 40 43.25 85.75\n",
      "\n",
      " 41 43.25 94.25\n",
      "\n",
      " 42 43.0 76.75\n",
      "\n",
      " 43 43.0 77.0\n",
      "\n",
      " 44 43.0 77.25\n",
      "\n",
      " 45 43.0 77.5\n",
      "\n",
      " 46 43.0 77.75\n",
      "\n",
      " 47 43.0 82.75\n",
      "\n",
      " 48 43.0 83.5\n",
      "\n",
      " 49 43.0 83.75\n",
      "\n",
      " 50 43.0 87.0\n",
      "\n",
      " 51 43.0 94.25\n",
      "\n",
      " 52 43.0 94.5\n",
      "\n",
      " 53 42.75 76.75\n",
      "\n",
      " 54 42.75 77.0\n",
      "\n",
      " 55 42.75 77.25\n",
      "\n",
      " 56 42.75 81.25\n",
      "\n",
      " 57 42.75 81.75\n",
      "\n",
      " 58 42.75 82.25\n",
      "\n",
      " 59 42.75 82.5\n",
      "\n",
      " 60 42.75 82.75\n",
      "\n",
      " 61 42.75 83.0\n",
      "\n",
      " 62 42.75 83.25\n",
      "\n",
      " 63 42.75 85.25\n",
      "\n",
      " 64 42.5 74.25\n",
      "\n",
      " 65 42.5 74.5\n",
      "\n",
      " 66 42.5 74.75\n",
      "\n",
      " 67 42.5 75.0\n",
      "\n",
      " 68 42.5 75.25\n",
      "\n",
      " 69 42.5 79.75\n",
      "\n",
      " 70 42.5 80.0\n",
      "\n",
      " 71 42.5 80.25\n",
      "\n",
      " 72 42.5 80.5\n",
      "\n",
      " 73 42.5 80.75\n",
      "\n",
      " 74 42.5 81.0\n",
      "\n",
      " 75 42.5 81.25\n",
      "\n",
      " 76 42.5 81.5\n",
      "\n",
      " 77 42.5 81.75\n",
      "\n",
      " 78 42.5 82.0\n",
      "\n",
      " 79 42.5 82.25\n",
      "\n",
      " 80 42.5 82.5\n",
      "\n",
      " 81 42.5 82.75\n",
      "\n",
      " 82 42.5 83.0\n",
      "\n",
      " 83 42.5 83.25\n",
      "\n",
      " 84 42.5 83.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/numpy/core/_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/numpy/core/_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/ipykernel_launcher.py:322: UserWarning: Warning: converting a masked element to nan.\n",
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/ipykernel_launcher.py:323: UserWarning: Warning: converting a masked element to nan.\n",
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/ipykernel_launcher.py:326: UserWarning: Warning: converting a masked element to nan.\n",
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/ipykernel_launcher.py:327: UserWarning: Warning: converting a masked element to nan.\n",
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/ipykernel_launcher.py:330: UserWarning: Warning: converting a masked element to nan.\n",
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/ipykernel_launcher.py:331: UserWarning: Warning: converting a masked element to nan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 85 42.5 85.25\n",
      "\n",
      " 86 42.5 85.5\n",
      "\n",
      " 87 42.25 70.75\n",
      "\n",
      " 88 42.25 71.0\n",
      "\n",
      " 89 42.25 71.25\n",
      "\n",
      " 90 42.25 74.75\n",
      "\n",
      " 91 42.25 78.25\n",
      "\n",
      " 92 42.25 78.5\n",
      "\n",
      " 93 42.25 78.75\n",
      "\n",
      " 94 42.25 79.0\n",
      "\n",
      " 95 42.25 79.25\n",
      "\n",
      " 96 42.25 79.5\n",
      "\n",
      " 97 42.25 79.75\n",
      "\n",
      " 98 42.25 80.0\n",
      "\n",
      " 99 42.25 80.25\n",
      "\n",
      " 100 42.25 80.5\n",
      "\n",
      " 101 42.25 80.75\n",
      "\n",
      " 102 42.25 81.0\n",
      "\n",
      " 103 42.25 81.25\n",
      "\n",
      " 104 42.25 81.5\n",
      "\n",
      " 105 42.25 81.75\n",
      "\n",
      " 106 42.0 70.5\n",
      "\n",
      " 107 42.0 71.0\n",
      "\n",
      " 108 42.0 72.0\n",
      "\n",
      " 109 42.0 72.25\n",
      "\n",
      " 110 42.0 76.0\n",
      "\n",
      " 111 42.0 76.5\n",
      "\n",
      " 112 42.0 76.75\n",
      "\n",
      " 113 42.0 77.0\n",
      "\n",
      " 114 42.0 77.25\n",
      "\n",
      " 115 42.0 77.5\n",
      "\n",
      " 116 42.0 77.75\n",
      "\n",
      " 117 42.0 78.0\n",
      "\n",
      " 118 42.0 78.25\n",
      "\n",
      " 119 42.0 78.5\n",
      "\n",
      " 120 42.0 78.75\n",
      "\n",
      " 121 42.0 79.0\n",
      "\n",
      " 122 42.0 79.25\n",
      "\n",
      " 123 42.0 79.5\n",
      "\n",
      " 124 42.0 79.75\n",
      "\n",
      " 125 42.0 80.0\n",
      "\n",
      " 126 42.0 80.25\n",
      "\n",
      " 127 42.0 80.5\n",
      "\n",
      " 128 42.0 80.75\n",
      "\n",
      " 129 42.0 81.0\n",
      "\n",
      " 130 41.75 76.25\n",
      "\n",
      " 131 41.75 77.25\n",
      "\n",
      " 132 41.75 77.5\n",
      "\n",
      " 133 41.75 77.75\n",
      "\n",
      " 134 41.75 78.0\n",
      "\n",
      " 135 41.75 78.25\n",
      "\n",
      " 136 41.75 78.5\n",
      "\n",
      " 137 41.75 78.75\n",
      "\n",
      " 138 41.75 79.0\n",
      "\n",
      " 139 41.75 80.0\n",
      "\n",
      " 140 41.75 80.25\n",
      "\n",
      " 141 41.75 80.5\n",
      "\n",
      " 142 41.5 77.25\n",
      "\n",
      " 143 41.5 77.5\n",
      "\n",
      " 144 41.5 77.75\n",
      "\n",
      " 145 41.5 78.75\n",
      "\n",
      " 146 41.25 77.25\n",
      "\n",
      " 147 41.25 77.5\n",
      "\n",
      " 148 41.25 77.75\n",
      "\n",
      " 149 41.25 78.25\n",
      "\n",
      " 150 41.25 78.5\n",
      "\n",
      " 151 41.0 75.5\n",
      "\n",
      " 152 41.0 75.75\n",
      "\n",
      " 153 41.0 76.0\n",
      "\n",
      " 154 41.0 77.25\n",
      "\n",
      " 155 41.0 77.5\n",
      "\n",
      " 156 41.0 77.75\n",
      "\n",
      " 157 41.0 78.0\n",
      "\n",
      " 158 41.0 78.25\n",
      "\n",
      " 159 40.75 74.25\n",
      "\n",
      " 160 40.75 74.5\n",
      "\n",
      " 161 40.75 76.75\n",
      "\n",
      " 162 40.5 74.5\n",
      "\n",
      " 163 40.5 74.75\n",
      "\n",
      " 164 40.5 75.0\n",
      "\n",
      " 165 40.0 72.5\n",
      "\n",
      " 166 39.75 70.5\n",
      "\n",
      " 167 39.75 70.75\n",
      "\n",
      " 168 39.75 71.25\n",
      "\n",
      " 169 39.75 71.5\n",
      "\n",
      " 170 39.75 71.75\n",
      "\n",
      " 171 39.75 72.0\n",
      "\n",
      " 172 39.75 72.5\n",
      "\n",
      " 173 39.75 72.75\n",
      "\n",
      " 174 39.5 69.75\n",
      "\n",
      " 175 39.5 70.0\n",
      "\n",
      " 176 39.5 70.25\n",
      "\n",
      " 177 39.5 70.5\n",
      "\n",
      " 178 39.5 70.75\n",
      "\n",
      " 179 39.5 71.0\n",
      "\n",
      " 180 39.5 71.25\n",
      "\n",
      " 181 39.5 71.5\n",
      "\n",
      " 182 39.5 72.0\n",
      "\n",
      " 183 39.5 72.5\n",
      "\n",
      " 184 39.5 72.75\n",
      "\n",
      " 185 39.5 73.0\n",
      "\n",
      " 186 39.5 73.25\n",
      "\n",
      " 187 39.5 73.5\n",
      "\n",
      " 188 39.5 73.75\n",
      "\n",
      " 189 39.5 74.0\n",
      "\n",
      " 190 39.5 96.25\n",
      "\n",
      " 191 39.5 96.5\n",
      "\n",
      " 192 39.5 96.75\n",
      "\n",
      " 193 39.5 98.25\n",
      "\n",
      " 194 39.25 69.5\n",
      "\n",
      " 195 39.25 69.75\n",
      "\n",
      " 196 39.25 70.0\n",
      "\n",
      " 197 39.25 70.25\n",
      "\n",
      " 198 39.25 70.5\n",
      "\n",
      " 199 39.25 71.0\n",
      "\n",
      " 200 39.25 71.75\n",
      "\n",
      " 201 39.25 72.0\n",
      "\n",
      " 202 39.25 72.25\n",
      "\n",
      " 203 39.25 72.5\n",
      "\n",
      " 204 39.25 72.75\n",
      "\n",
      " 205 39.25 73.0\n",
      "\n",
      " 206 39.25 73.25\n",
      "\n",
      " 207 39.25 73.5\n",
      "\n",
      " 208 39.25 73.75\n",
      "\n",
      " 209 39.25 74.25\n",
      "\n",
      " 210 39.25 74.5\n",
      "\n",
      " 211 39.25 74.75\n",
      "\n",
      " 212 39.25 75.0\n",
      "\n",
      " 213 39.25 93.5\n",
      "\n",
      " 214 39.25 93.75\n",
      "\n",
      " 215 39.25 95.25\n",
      "\n",
      " 216 39.25 95.5\n",
      "\n",
      " 217 39.25 96.75\n",
      "\n",
      " 218 39.25 97.75\n",
      "\n",
      " 219 39.25 98.25\n",
      "\n",
      " 220 39.25 98.5\n",
      "\n",
      " 221 39.0 68.0\n",
      "\n",
      " 222 39.0 68.5\n",
      "\n",
      " 223 39.0 69.0\n",
      "\n",
      " 224 39.0 69.25\n",
      "\n",
      " 225 39.0 69.5\n",
      "\n",
      " 226 39.0 69.75\n",
      "\n",
      " 227 39.0 70.75\n",
      "\n",
      " 228 39.0 71.0\n",
      "\n",
      " 229 39.0 71.25\n",
      "\n",
      " 230 39.0 71.5\n",
      "\n",
      " 231 39.0 71.75\n",
      "\n",
      " 232 39.0 72.0\n",
      "\n",
      " 233 39.0 72.25\n",
      "\n",
      " 234 39.0 72.5\n",
      "\n",
      " 235 39.0 72.75\n",
      "\n",
      " 236 39.0 73.0\n",
      "\n",
      " 237 39.0 73.25\n",
      "\n",
      " 238 39.0 73.75\n",
      "\n",
      " 239 39.0 74.0\n",
      "\n",
      " 240 39.0 74.75\n",
      "\n",
      " 241 39.0 75.0\n",
      "\n",
      " 242 39.0 95.5\n",
      "\n",
      " 243 39.0 99.0\n",
      "\n",
      " 244 38.75 71.0\n",
      "\n",
      " 245 38.75 71.25\n",
      "\n",
      " 246 38.75 71.5\n",
      "\n",
      " 247 38.75 71.75\n",
      "\n",
      " 248 38.75 72.0\n",
      "\n",
      " 249 38.75 72.25\n",
      "\n",
      " 250 38.75 72.5\n",
      "\n",
      " 251 38.75 72.75\n",
      "\n",
      " 252 38.75 73.0\n",
      "\n",
      " 253 38.75 73.25\n",
      "\n",
      " 254 38.75 73.5\n",
      "\n",
      " 255 38.75 73.75\n",
      "\n",
      " 256 38.75 75.0\n",
      "\n",
      " 257 38.75 75.25\n",
      "\n",
      " 258 38.75 75.5\n",
      "\n",
      " 259 38.75 96.0\n",
      "\n",
      " 260 38.75 96.25\n",
      "\n",
      " 261 38.75 97.0\n",
      "\n",
      " 262 38.75 97.25\n",
      "\n",
      " 263 38.75 97.75\n",
      "\n",
      " 264 38.75 98.25\n",
      "\n",
      " 265 38.5 71.0\n",
      "\n",
      " 266 38.5 71.25\n",
      "\n",
      " 267 38.5 71.5\n",
      "\n",
      " 268 38.5 71.75\n",
      "\n",
      " 269 38.5 72.0\n",
      "\n",
      " 270 38.5 72.25\n",
      "\n",
      " 271 38.5 72.5\n",
      "\n",
      " 272 38.5 72.75\n",
      "\n",
      " 273 38.5 73.25\n",
      "\n",
      " 274 38.5 73.5\n",
      "\n",
      " 275 38.5 75.25\n",
      "\n",
      " 276 38.5 75.5\n",
      "\n",
      " 277 38.5 75.75\n",
      "\n",
      " 278 38.5 95.75\n",
      "\n",
      " 279 38.5 96.5\n",
      "\n",
      " 280 38.5 97.5\n",
      "\n",
      " 281 38.5 97.75\n",
      "\n",
      " 282 38.5 98.0\n",
      "\n",
      " 283 38.5 98.25\n",
      "\n",
      " 284 38.25 71.0\n",
      "\n",
      " 285 38.25 71.25\n",
      "\n",
      " 286 38.25 71.75\n",
      "\n",
      " 287 38.25 72.0\n",
      "\n",
      " 288 38.25 72.25\n",
      "\n",
      " 289 38.25 72.5\n",
      "\n",
      " 290 38.25 72.75\n",
      "\n",
      " 291 38.25 73.0\n",
      "\n",
      " 292 38.25 73.25\n",
      "\n",
      " 293 38.25 75.0\n",
      "\n",
      " 294 38.25 75.25\n",
      "\n",
      " 295 38.25 75.5\n",
      "\n",
      " 296 38.25 88.75\n",
      "\n",
      " 297 38.25 89.0\n",
      "\n",
      " 298 38.25 89.25\n",
      "\n",
      " 299 38.25 89.5\n",
      "\n",
      " 300 38.25 95.75\n",
      "\n",
      " 301 38.25 96.0\n",
      "\n",
      " 302 38.25 96.25\n",
      "\n",
      " 303 38.25 96.5\n",
      "\n",
      " 304 38.25 98.0\n",
      "\n",
      " 305 38.25 98.75\n",
      "\n",
      " 306 38.0 70.75\n",
      "\n",
      " 307 38.0 71.0\n",
      "\n",
      " 308 38.0 71.5\n",
      "\n",
      " 309 38.0 71.75\n",
      "\n",
      " 310 38.0 72.0\n",
      "\n",
      " 311 38.0 72.25\n",
      "\n",
      " 312 38.0 72.5\n",
      "\n",
      " 313 38.0 72.75\n",
      "\n",
      " 314 38.0 73.0\n",
      "\n",
      " 315 38.0 73.25\n",
      "\n",
      " 316 38.0 73.5\n",
      "\n",
      " 317 38.0 87.25\n",
      "\n",
      " 318 38.0 87.5\n",
      "\n",
      " 319 38.0 95.25\n",
      "\n",
      " 320 38.0 95.75\n",
      "\n",
      " 321 38.0 96.5\n",
      "\n",
      " 322 37.75 71.0\n",
      "\n",
      " 323 37.75 71.25\n",
      "\n",
      " 324 37.75 71.75\n",
      "\n",
      " 325 37.75 72.0\n",
      "\n",
      " 326 37.75 72.25\n",
      "\n",
      " 327 37.75 72.5\n",
      "\n",
      " 328 37.75 72.75\n",
      "\n",
      " 329 37.75 88.25\n",
      "\n",
      " 330 37.75 90.5\n",
      "\n",
      " 331 37.75 90.75\n",
      "\n",
      " 332 37.75 101.5\n",
      "\n",
      " 333 37.5 71.25\n",
      "\n",
      " 334 37.5 72.0\n",
      "\n",
      " 335 37.5 72.25\n",
      "\n",
      " 336 37.5 72.75\n",
      "\n",
      " 337 37.5 75.0\n",
      "\n",
      " 338 37.5 75.25\n",
      "\n",
      " 339 37.5 87.5\n",
      "\n",
      " 340 37.5 87.75\n",
      "\n",
      " 341 37.5 88.0\n",
      "\n",
      " 342 37.5 88.25\n",
      "\n",
      " 343 37.5 90.5\n",
      "\n",
      " 344 37.5 101.75\n",
      "\n",
      " 345 37.25 71.75\n",
      "\n",
      " 346 37.25 72.0\n",
      "\n",
      " 347 37.25 72.5\n",
      "\n",
      " 348 37.25 72.75\n",
      "\n",
      " 349 37.25 73.0\n",
      "\n",
      " 350 37.25 73.25\n",
      "\n",
      " 351 37.25 73.5\n",
      "\n",
      " 352 37.25 73.75\n",
      "\n",
      " 353 37.25 74.25\n",
      "\n",
      " 354 37.25 74.5\n",
      "\n",
      " 355 37.25 74.75\n",
      "\n",
      " 356 37.25 75.0\n",
      "\n",
      " 357 37.25 75.25\n",
      "\n",
      " 358 37.25 75.75\n",
      "\n",
      " 359 37.25 85.75\n",
      "\n",
      " 360 37.25 86.0\n",
      "\n",
      " 361 37.25 87.75\n",
      "\n",
      " 362 37.25 90.75\n",
      "\n",
      " 363 37.0 71.25\n",
      "\n",
      " 364 37.0 71.75\n",
      "\n",
      " 365 37.0 72.0\n",
      "\n",
      " 366 37.0 72.25\n",
      "\n",
      " 367 37.0 72.5\n",
      "\n",
      " 368 37.0 72.75\n",
      "\n",
      " 369 37.0 73.0\n",
      "\n",
      " 370 37.0 73.25\n",
      "\n",
      " 371 37.0 73.5\n",
      "\n",
      " 372 37.0 73.75\n",
      "\n",
      " 373 37.0 74.0\n",
      "\n",
      " 374 37.0 74.25\n",
      "\n",
      " 375 37.0 74.5\n",
      "\n",
      " 376 37.0 74.75\n",
      "\n",
      " 377 37.0 75.0\n",
      "\n",
      " 378 37.0 75.25\n",
      "\n",
      " 379 37.0 75.5\n",
      "\n",
      " 380 37.0 75.75\n",
      "\n",
      " 381 37.0 76.25\n",
      "\n",
      " 382 36.75 71.75\n",
      "\n",
      " 383 36.75 72.0\n",
      "\n",
      " 384 36.75 72.25\n",
      "\n",
      " 385 36.75 72.5\n",
      "\n",
      " 386 36.75 72.75\n",
      "\n",
      " 387 36.75 73.0\n",
      "\n",
      " 388 36.75 73.25\n",
      "\n",
      " 389 36.75 73.5\n",
      "\n",
      " 390 36.75 73.75\n",
      "\n",
      " 391 36.75 74.0\n",
      "\n",
      " 392 36.75 74.25\n",
      "\n",
      " 393 36.75 74.5\n",
      "\n",
      " 394 36.75 74.75\n",
      "\n",
      " 395 36.75 75.0\n",
      "\n",
      " 396 36.75 75.25\n",
      "\n",
      " 397 36.75 75.5\n",
      "\n",
      " 398 36.75 75.75\n",
      "\n",
      " 399 36.75 76.0\n",
      "\n",
      " 400 36.75 76.25\n",
      "\n",
      " 401 36.75 76.5\n",
      "\n",
      " 402 36.75 76.75\n",
      "\n",
      " 403 36.75 77.0\n",
      "\n",
      " 404 36.75 77.25\n",
      "\n",
      " 405 36.75 77.5\n",
      "\n",
      " 406 36.75 77.75\n",
      "\n",
      " 407 36.75 78.0\n",
      "\n",
      " 408 36.75 78.25\n",
      "\n",
      " 409 36.75 78.5\n",
      "\n",
      " 410 36.75 84.25\n",
      "\n",
      " 411 36.75 84.5\n",
      "\n",
      " 412 36.75 84.75\n",
      "\n",
      " 413 36.75 85.0\n",
      "\n",
      " 414 36.75 85.25\n",
      "\n",
      " 415 36.75 90.75\n",
      "\n",
      " 416 36.75 91.0\n",
      "\n",
      " 417 36.75 91.25\n",
      "\n",
      " 418 36.5 70.5\n",
      "\n",
      " 419 36.5 71.5\n",
      "\n",
      " 420 36.5 71.75\n",
      "\n",
      " 421 36.5 72.0\n",
      "\n",
      " 422 36.5 72.25\n",
      "\n",
      " 423 36.5 72.75\n",
      "\n",
      " 424 36.5 73.0\n",
      "\n",
      " 425 36.5 73.25\n",
      "\n",
      " 426 36.5 73.5\n",
      "\n",
      " 427 36.5 73.75\n",
      "\n",
      " 428 36.5 74.0\n",
      "\n",
      " 429 36.5 74.25\n",
      "\n",
      " 430 36.5 74.5\n",
      "\n",
      " 431 36.5 74.75\n",
      "\n",
      " 432 36.5 75.0\n",
      "\n",
      " 433 36.5 75.25\n",
      "\n",
      " 434 36.5 75.5\n",
      "\n",
      " 435 36.5 75.75\n",
      "\n",
      " 436 36.5 76.0\n",
      "\n",
      " 437 36.5 76.25\n",
      "\n",
      " 438 36.5 76.5\n",
      "\n",
      " 439 36.5 76.75\n",
      "\n",
      " 440 36.5 77.0\n",
      "\n",
      " 441 36.5 77.25\n",
      "\n",
      " 442 36.5 77.5\n",
      "\n",
      " 443 36.5 77.75\n",
      "\n",
      " 444 36.5 78.0\n",
      "\n",
      " 445 36.5 78.25\n",
      "\n",
      " 446 36.5 78.75\n",
      "\n",
      " 447 36.5 79.0\n",
      "\n",
      " 448 36.5 87.25\n",
      "\n",
      " 449 36.5 87.5\n",
      "\n",
      " 450 36.5 91.0\n",
      "\n",
      " 451 36.5 91.25\n",
      "\n",
      " 452 36.25 69.75\n",
      "\n",
      " 453 36.25 70.25\n",
      "\n",
      " 454 36.25 70.5\n",
      "\n",
      " 455 36.25 71.0\n",
      "\n",
      " 456 36.25 71.25\n",
      "\n",
      " 457 36.25 71.75\n",
      "\n",
      " 458 36.25 72.0\n",
      "\n",
      " 459 36.25 72.25\n",
      "\n",
      " 460 36.25 72.5\n",
      "\n",
      " 461 36.25 72.75\n",
      "\n",
      " 462 36.25 73.0\n",
      "\n",
      " 463 36.25 74.0\n",
      "\n",
      " 464 36.25 74.25\n",
      "\n",
      " 465 36.25 74.5\n",
      "\n",
      " 466 36.25 74.75\n",
      "\n",
      " 467 36.25 75.0\n",
      "\n",
      " 468 36.25 75.25\n",
      "\n",
      " 469 36.25 75.5\n",
      "\n",
      " 470 36.25 75.75\n",
      "\n",
      " 471 36.25 76.0\n",
      "\n",
      " 472 36.25 76.25\n",
      "\n",
      " 473 36.25 76.5\n",
      "\n",
      " 474 36.25 76.75\n",
      "\n",
      " 475 36.25 77.0\n",
      "\n",
      " 476 36.25 77.25\n",
      "\n",
      " 477 36.25 78.5\n",
      "\n",
      " 478 36.25 78.75\n",
      "\n",
      " 479 36.25 79.0\n",
      "\n",
      " 480 36.25 79.25\n",
      "\n",
      " 481 36.25 79.5\n",
      "\n",
      " 482 36.25 82.0\n",
      "\n",
      " 483 36.25 82.25\n",
      "\n",
      " 484 36.25 82.5\n",
      "\n",
      " 485 36.25 82.75\n",
      "\n",
      " 486 36.25 83.0\n",
      "\n",
      " 487 36.25 90.0\n",
      "\n",
      " 488 36.25 90.25\n",
      "\n",
      " 489 36.25 91.75\n",
      "\n",
      " 490 36.25 92.0\n",
      "\n",
      " 491 36.0 70.5\n",
      "\n",
      " 492 36.0 70.75\n",
      "\n",
      " 493 36.0 71.0\n",
      "\n",
      " 494 36.0 71.25\n",
      "\n",
      " 495 36.0 72.25\n",
      "\n",
      " 496 36.0 72.5\n",
      "\n",
      " 497 36.0 72.75\n",
      "\n",
      " 498 36.0 73.0\n",
      "\n",
      " 499 36.0 74.5\n",
      "\n",
      " 500 36.0 74.75\n",
      "\n",
      " 501 36.0 75.0\n",
      "\n",
      " 502 36.0 75.25\n",
      "\n",
      " 503 36.0 75.5\n",
      "\n",
      " 504 36.0 75.75\n",
      "\n",
      " 505 36.0 76.0\n",
      "\n",
      " 506 36.0 76.25\n",
      "\n",
      " 507 36.0 76.5\n",
      "\n",
      " 508 36.0 76.75\n",
      "\n",
      " 509 36.0 77.0\n",
      "\n",
      " 510 36.0 79.25\n",
      "\n",
      " 511 36.0 79.5\n",
      "\n",
      " 512 36.0 79.75\n",
      "\n",
      " 513 36.0 80.0\n",
      "\n",
      " 514 36.0 80.25\n",
      "\n",
      " 515 36.0 80.5\n",
      "\n",
      " 516 36.0 80.75\n",
      "\n",
      " 517 36.0 81.0\n",
      "\n",
      " 518 36.0 81.25\n",
      "\n",
      " 519 36.0 81.5\n",
      "\n",
      " 520 36.0 81.75\n",
      "\n",
      " 521 36.0 90.0\n",
      "\n",
      " 522 36.0 90.75\n",
      "\n",
      " 523 36.0 91.0\n",
      "\n",
      " 524 36.0 91.25\n",
      "\n",
      " 525 36.0 91.5\n",
      "\n",
      " 526 35.75 70.5\n",
      "\n",
      " 527 35.75 70.75\n",
      "\n",
      " 528 35.75 71.0\n",
      "\n",
      " 529 35.75 71.25\n",
      "\n",
      " 530 35.75 72.25\n",
      "\n",
      " 531 35.75 72.5\n",
      "\n",
      " 532 35.75 72.75\n",
      "\n",
      " 533 35.75 73.0\n",
      "\n",
      " 534 35.75 73.25\n",
      "\n",
      " 535 35.75 74.75\n",
      "\n",
      " 536 35.75 75.0\n",
      "\n",
      " 537 35.75 75.25\n",
      "\n",
      " 538 35.75 75.5\n",
      "\n",
      " 539 35.75 75.75\n",
      "\n",
      " 540 35.75 76.0\n",
      "\n",
      " 541 35.75 76.25\n",
      "\n",
      " 542 35.75 76.5\n",
      "\n",
      " 543 35.75 76.75\n",
      "\n",
      " 544 35.75 77.0\n",
      "\n",
      " 545 35.75 77.25\n",
      "\n",
      " 546 35.75 77.5\n",
      "\n",
      " 547 35.75 77.75\n",
      "\n",
      " 548 35.75 78.5\n",
      "\n",
      " 549 35.75 78.75\n",
      "\n",
      " 550 35.75 79.0\n",
      "\n",
      " 551 35.75 79.5\n",
      "\n",
      " 552 35.75 79.75\n",
      "\n",
      " 553 35.75 80.0\n",
      "\n",
      " 554 35.75 80.25\n",
      "\n",
      " 555 35.75 80.5\n",
      "\n",
      " 556 35.75 80.75\n",
      "\n",
      " 557 35.75 81.25\n",
      "\n",
      " 558 35.75 82.25\n",
      "\n",
      " 559 35.75 82.5\n",
      "\n",
      " 560 35.75 89.75\n",
      "\n",
      " 561 35.75 90.5\n",
      "\n",
      " 562 35.75 90.75\n",
      "\n",
      " 563 35.75 91.25\n",
      "\n",
      " 564 35.75 91.5\n",
      "\n",
      " 565 35.75 92.0\n",
      "\n",
      " 566 35.75 93.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 567 35.75 93.25\n",
      "\n",
      " 568 35.75 93.5\n",
      "\n",
      " 569 35.75 93.75\n",
      "\n",
      " 570 35.75 94.25\n",
      "\n",
      " 571 35.5 70.75\n",
      "\n",
      " 572 35.5 72.5\n",
      "\n",
      " 573 35.5 72.75\n",
      "\n",
      " 574 35.5 73.0\n",
      "\n",
      " 575 35.5 74.75\n",
      "\n",
      " 576 35.5 75.0\n",
      "\n",
      " 577 35.5 75.25\n",
      "\n",
      " 578 35.5 75.5\n",
      "\n",
      " 579 35.5 75.75\n",
      "\n",
      " 580 35.5 76.0\n",
      "\n",
      " 581 35.5 76.25\n",
      "\n",
      " 582 35.5 76.5\n",
      "\n",
      " 583 35.5 76.75\n",
      "\n",
      " 584 35.5 77.0\n",
      "\n",
      " 585 35.5 77.25\n",
      "\n",
      " 586 35.5 77.5\n",
      "\n",
      " 587 35.5 77.75\n",
      "\n",
      " 588 35.5 78.0\n",
      "\n",
      " 589 35.5 78.5\n",
      "\n",
      " 590 35.5 78.75\n",
      "\n",
      " 591 35.5 80.0\n",
      "\n",
      " 592 35.5 80.5\n",
      "\n",
      " 593 35.5 80.75\n",
      "\n",
      " 594 35.5 81.0\n",
      "\n",
      " 595 35.5 81.25\n",
      "\n",
      " 596 35.5 81.5\n",
      "\n",
      " 597 35.5 81.75\n",
      "\n",
      " 598 35.5 82.25\n",
      "\n",
      " 599 35.5 89.5\n",
      "\n",
      " 600 35.5 89.75\n",
      "\n",
      " 601 35.5 94.5\n",
      "\n",
      " 602 35.25 72.75\n",
      "\n",
      " 603 35.25 73.0\n",
      "\n",
      " 604 35.25 73.5\n",
      "\n",
      " 605 35.25 74.5\n",
      "\n",
      " 606 35.25 74.75\n",
      "\n",
      " 607 35.25 75.0\n",
      "\n",
      " 608 35.25 75.25\n",
      "\n",
      " 609 35.25 76.25\n",
      "\n",
      " 610 35.25 76.5\n",
      "\n",
      " 611 35.25 76.75\n",
      "\n",
      " 612 35.25 77.0\n",
      "\n",
      " 613 35.25 77.25\n",
      "\n",
      " 614 35.25 77.5\n",
      "\n",
      " 615 35.25 77.75\n",
      "\n",
      " 616 35.25 78.0\n",
      "\n",
      " 617 35.25 78.25\n",
      "\n",
      " 618 35.25 78.5\n",
      "\n",
      " 619 35.25 78.75\n",
      "\n",
      " 620 35.25 79.0\n",
      "\n",
      " 621 35.25 80.5\n",
      "\n",
      " 622 35.25 80.75\n",
      "\n",
      " 623 35.25 81.0\n",
      "\n",
      " 624 35.25 81.25\n",
      "\n",
      " 625 35.25 81.5\n",
      "\n",
      " 626 35.25 81.75\n",
      "\n",
      " 627 35.25 82.0\n",
      "\n",
      " 628 35.25 88.5\n",
      "\n",
      " 629 35.0 73.25\n",
      "\n",
      " 630 35.0 73.5\n",
      "\n",
      " 631 35.0 74.25\n",
      "\n",
      " 632 35.0 74.5\n",
      "\n",
      " 633 35.0 74.75\n",
      "\n",
      " 634 35.0 76.25\n",
      "\n",
      " 635 35.0 76.75\n",
      "\n",
      " 636 35.0 77.0\n",
      "\n",
      " 637 35.0 77.25\n",
      "\n",
      " 638 35.0 77.5\n",
      "\n",
      " 639 35.0 77.75\n",
      "\n",
      " 640 35.0 78.0\n",
      "\n",
      " 641 35.0 78.25\n",
      "\n",
      " 642 35.0 78.5\n",
      "\n",
      " 643 35.0 79.0\n",
      "\n",
      " 644 35.0 81.0\n",
      "\n",
      " 645 35.0 89.5\n",
      "\n",
      " 646 35.0 89.75\n",
      "\n",
      " 647 34.75 73.75\n",
      "\n",
      " 648 34.75 74.0\n",
      "\n",
      " 649 34.75 76.75\n",
      "\n",
      " 650 34.75 77.0\n",
      "\n",
      " 651 34.75 77.25\n",
      "\n",
      " 652 34.75 77.5\n",
      "\n",
      " 653 34.75 77.75\n",
      "\n",
      " 654 34.75 78.0\n",
      "\n",
      " 655 34.75 78.25\n",
      "\n",
      " 656 34.75 78.5\n",
      "\n",
      " 657 34.75 78.75\n",
      "\n",
      " 658 34.75 80.25\n",
      "\n",
      " 659 34.75 82.25\n",
      "\n",
      " 660 34.75 82.5\n",
      "\n",
      " 661 34.75 89.75\n",
      "\n",
      " 662 34.75 99.5\n",
      "\n",
      " 663 34.5 73.75\n",
      "\n",
      " 664 34.5 75.0\n",
      "\n",
      " 665 34.5 75.25\n",
      "\n",
      " 666 34.5 75.5\n",
      "\n",
      " 667 34.5 76.75\n",
      "\n",
      " 668 34.5 77.0\n",
      "\n",
      " 669 34.5 77.25\n",
      "\n",
      " 670 34.5 77.5\n",
      "\n",
      " 671 34.5 77.75\n",
      "\n",
      " 672 34.5 78.0\n",
      "\n",
      " 673 34.5 78.25\n",
      "\n",
      " 674 34.5 78.5\n",
      "\n",
      " 675 34.5 78.75\n",
      "\n",
      " 676 34.5 79.0\n",
      "\n",
      " 677 34.5 79.5\n",
      "\n",
      " 678 34.5 79.75\n",
      "\n",
      " 679 34.5 80.0\n",
      "\n",
      " 680 34.5 80.75\n",
      "\n",
      " 681 34.5 81.0\n",
      "\n",
      " 682 34.5 81.25\n",
      "\n",
      " 683 34.5 81.75\n",
      "\n",
      " 684 34.5 85.5\n",
      "\n",
      " 685 34.5 85.75\n",
      "\n",
      " 686 34.5 86.0\n",
      "\n",
      " 687 34.25 75.25\n",
      "\n",
      " 688 34.25 75.5\n",
      "\n",
      " 689 34.25 75.75\n",
      "\n",
      " 690 34.25 76.0\n",
      "\n",
      " 691 34.25 77.5\n",
      "\n",
      " 692 34.25 78.0\n",
      "\n",
      " 693 34.25 78.25\n",
      "\n",
      " 694 34.25 78.5\n",
      "\n",
      " 695 34.25 78.75\n",
      "\n",
      " 696 34.25 79.0\n",
      "\n",
      " 697 34.25 79.5\n",
      "\n",
      " 698 34.25 79.75\n",
      "\n",
      " 699 34.25 80.0\n",
      "\n",
      " 700 34.25 80.25\n",
      "\n",
      " 701 34.25 80.75\n",
      "\n",
      " 702 34.25 81.0\n",
      "\n",
      " 703 34.25 81.25\n",
      "\n",
      " 704 34.25 81.75\n",
      "\n",
      " 705 34.25 82.0\n",
      "\n",
      " 706 34.25 82.25\n",
      "\n",
      " 707 34.25 85.75\n",
      "\n",
      " 708 34.25 86.0\n",
      "\n",
      " 709 34.25 86.75\n",
      "\n",
      " 710 34.0 75.5\n",
      "\n",
      " 711 34.0 75.75\n",
      "\n",
      " 712 34.0 76.0\n",
      "\n",
      " 713 34.0 76.25\n",
      "\n",
      " 714 34.0 76.5\n",
      "\n",
      " 715 34.0 76.75\n",
      "\n",
      " 716 34.0 78.25\n",
      "\n",
      " 717 34.0 78.75\n",
      "\n",
      " 718 34.0 79.5\n",
      "\n",
      " 719 34.0 80.0\n",
      "\n",
      " 720 34.0 82.25\n",
      "\n",
      " 721 34.0 89.0\n",
      "\n",
      " 722 34.0 89.25\n",
      "\n",
      " 723 34.0 89.5\n",
      "\n",
      " 724 34.0 90.5\n",
      "\n",
      " 725 34.0 90.75\n",
      "\n",
      " 726 33.75 75.75\n",
      "\n",
      " 727 33.75 76.0\n",
      "\n",
      " 728 33.75 76.25\n",
      "\n",
      " 729 33.75 76.5\n",
      "\n",
      " 730 33.75 77.25\n",
      "\n",
      " 731 33.75 77.5\n",
      "\n",
      " 732 33.75 78.25\n",
      "\n",
      " 733 33.75 78.5\n",
      "\n",
      " 734 33.75 78.75\n",
      "\n",
      " 735 33.75 82.25\n",
      "\n",
      " 736 33.75 88.0\n",
      "\n",
      " 737 33.75 89.0\n",
      "\n",
      " 738 33.75 89.25\n",
      "\n",
      " 739 33.75 89.5\n",
      "\n",
      " 740 33.75 94.75\n",
      "\n",
      " 741 33.5 76.0\n",
      "\n",
      " 742 33.5 76.25\n",
      "\n",
      " 743 33.5 76.5\n",
      "\n",
      " 744 33.5 76.75\n",
      "\n",
      " 745 33.5 78.5\n",
      "\n",
      " 746 33.5 82.0\n",
      "\n",
      " 747 33.5 82.25\n",
      "\n",
      " 748 33.5 83.25\n",
      "\n",
      " 749 33.5 85.5\n",
      "\n",
      " 750 33.5 86.75\n",
      "\n",
      " 751 33.5 90.75\n",
      "\n",
      " 752 33.5 91.0\n",
      "\n",
      " 753 33.5 91.25\n",
      "\n",
      " 754 33.5 91.5\n",
      "\n",
      " 755 33.5 92.25\n",
      "\n",
      " 756 33.5 94.75\n",
      "\n",
      " 757 33.5 95.0\n",
      "\n",
      " 758 33.25 76.0\n",
      "\n",
      " 759 33.25 76.25\n",
      "\n",
      " 760 33.25 76.5\n",
      "\n",
      " 761 33.25 76.75\n",
      "\n",
      " 762 33.25 77.0\n",
      "\n",
      " 763 33.25 78.25\n",
      "\n",
      " 764 33.25 78.5\n",
      "\n",
      " 765 33.25 78.75\n",
      "\n",
      " 766 33.25 85.25\n",
      "\n",
      " 767 33.25 88.75\n",
      "\n",
      " 768 33.25 91.0\n",
      "\n",
      " 769 33.25 91.25\n",
      "\n",
      " 770 33.25 91.5\n",
      "\n",
      " 771 33.25 92.0\n",
      "\n",
      " 772 33.0 76.25\n",
      "\n",
      " 773 33.0 76.5\n",
      "\n",
      " 774 33.0 76.75\n",
      "\n",
      " 775 33.0 77.0\n",
      "\n",
      " 776 33.0 77.25\n",
      "\n",
      " 777 33.0 78.0\n",
      "\n",
      " 778 33.0 78.25\n",
      "\n",
      " 779 33.0 78.5\n",
      "\n",
      " 780 33.0 88.5\n",
      "\n",
      " 781 33.0 91.25\n",
      "\n",
      " 782 33.0 91.75\n",
      "\n",
      " 783 33.0 92.0\n",
      "\n",
      " 784 33.0 92.25\n",
      "\n",
      " 785 32.75 76.25\n",
      "\n",
      " 786 32.75 76.5\n",
      "\n",
      " 787 32.75 76.75\n",
      "\n",
      " 788 32.75 77.0\n",
      "\n",
      " 789 32.75 77.25\n",
      "\n",
      " 790 32.75 77.5\n",
      "\n",
      " 791 32.75 77.75\n",
      "\n",
      " 792 32.75 81.0\n",
      "\n",
      " 793 32.75 92.0\n",
      "\n",
      " 794 32.75 92.25\n",
      "\n",
      " 795 32.75 92.5\n",
      "\n",
      " 796 32.75 92.75\n",
      "\n",
      " 797 32.75 93.25\n",
      "\n",
      " 798 32.5 76.5\n",
      "\n",
      " 799 32.5 76.75\n",
      "\n",
      " 800 32.5 77.0\n",
      "\n",
      " 801 32.5 77.25\n",
      "\n",
      " 802 32.5 77.5\n",
      "\n",
      " 803 32.5 77.75\n",
      "\n",
      " 804 32.5 78.0\n",
      "\n",
      " 805 32.5 78.25\n",
      "\n",
      " 806 32.5 78.5\n",
      "\n",
      " 807 32.5 78.75\n",
      "\n",
      " 808 32.5 79.0\n",
      "\n",
      " 809 32.5 87.5\n",
      "\n",
      " 810 32.5 93.0\n",
      "\n",
      " 811 32.25 76.75\n",
      "\n",
      " 812 32.25 77.0\n",
      "\n",
      " 813 32.25 77.25\n",
      "\n",
      " 814 32.25 77.5\n",
      "\n",
      " 815 32.25 77.75\n",
      "\n",
      " 816 32.25 78.25\n",
      "\n",
      " 817 32.25 78.5\n",
      "\n",
      " 818 32.25 79.75\n",
      "\n",
      " 819 32.25 87.25\n",
      "\n",
      " 820 32.25 87.5\n",
      "\n",
      " 821 32.0 77.5\n",
      "\n",
      " 822 32.0 77.75\n",
      "\n",
      " 823 32.0 78.0\n",
      "\n",
      " 824 32.0 78.5\n",
      "\n",
      " 825 32.0 78.75\n",
      "\n",
      " 826 32.0 79.75\n",
      "\n",
      " 827 32.0 80.0\n",
      "\n",
      " 828 32.0 95.5\n",
      "\n",
      " 829 31.75 77.5\n",
      "\n",
      " 830 31.75 77.75\n",
      "\n",
      " 831 31.75 78.0\n",
      "\n",
      " 832 31.75 78.25\n",
      "\n",
      " 833 31.75 78.75\n",
      "\n",
      " 834 31.75 83.5\n",
      "\n",
      " 835 31.75 85.0\n",
      "\n",
      " 836 31.75 94.75\n",
      "\n",
      " 837 31.75 95.5\n",
      "\n",
      " 838 31.75 95.75\n",
      "\n",
      " 839 31.75 99.0\n",
      "\n",
      " 840 31.5 78.25\n",
      "\n",
      " 841 31.5 78.5\n",
      "\n",
      " 842 31.5 83.5\n",
      "\n",
      " 843 31.5 85.0\n",
      "\n",
      " 844 31.5 86.75\n",
      "\n",
      " 845 31.5 93.5\n",
      "\n",
      " 846 31.5 100.25\n",
      "\n",
      " 847 31.25 78.25\n",
      "\n",
      " 848 31.25 78.5\n",
      "\n",
      " 849 31.25 78.75\n",
      "\n",
      " 850 31.25 79.0\n",
      "\n",
      " 851 31.25 79.25\n",
      "\n",
      " 852 31.25 82.25\n",
      "\n",
      " 853 31.25 86.75\n",
      "\n",
      " 854 31.25 94.75\n",
      "\n",
      " 855 31.25 103.0\n",
      "\n",
      " 856 31.0 78.5\n",
      "\n",
      " 857 31.0 78.75\n",
      "\n",
      " 858 31.0 79.0\n",
      "\n",
      " 859 31.0 79.25\n",
      "\n",
      " 860 31.0 79.5\n",
      "\n",
      " 861 31.0 79.75\n",
      "\n",
      " 862 31.0 81.25\n",
      "\n",
      " 863 31.0 82.25\n",
      "\n",
      " 864 31.0 82.5\n",
      "\n",
      " 865 31.0 82.75\n",
      "\n",
      " 866 31.0 83.0\n",
      "\n",
      " 867 31.0 83.5\n",
      "\n",
      " 868 31.0 91.5\n",
      "\n",
      " 869 31.0 93.75\n",
      "\n",
      " 870 31.0 94.0\n",
      "\n",
      " 871 30.75 78.75\n",
      "\n",
      " 872 30.75 79.0\n",
      "\n",
      " 873 30.75 79.25\n",
      "\n",
      " 874 30.75 79.5\n",
      "\n",
      " 875 30.75 79.75\n",
      "\n",
      " 876 30.75 80.0\n",
      "\n",
      " 877 30.75 82.75\n",
      "\n",
      " 878 30.75 83.0\n",
      "\n",
      " 879 30.75 83.25\n",
      "\n",
      " 880 30.75 83.5\n",
      "\n",
      " 881 30.75 86.5\n",
      "\n",
      " 882 30.75 88.5\n",
      "\n",
      " 883 30.75 88.75\n",
      "\n",
      " 884 30.75 91.5\n",
      "\n",
      " 885 30.75 93.5\n",
      "\n",
      " 886 30.75 93.75\n",
      "\n",
      " 887 30.75 94.0\n",
      "\n",
      " 888 30.75 94.25\n",
      "\n",
      " 889 30.75 94.5\n",
      "\n",
      " 890 30.75 94.75\n",
      "\n",
      " 891 30.75 95.0\n",
      "\n",
      " 892 30.75 95.25\n",
      "\n",
      " 893 30.75 99.5\n",
      "\n",
      " 894 30.5 79.75\n",
      "\n",
      " 895 30.5 80.0\n",
      "\n",
      " 896 30.5 80.25\n",
      "\n",
      " 897 30.5 80.5\n",
      "\n",
      " 898 30.5 80.75\n",
      "\n",
      " 899 30.5 81.25\n",
      "\n",
      " 900 30.5 83.25\n",
      "\n",
      " 901 30.5 84.0\n",
      "\n",
      " 902 30.5 84.25\n",
      "\n",
      " 903 30.5 84.5\n",
      "\n",
      " 904 30.5 86.5\n",
      "\n",
      " 905 30.5 90.5\n",
      "\n",
      " 906 30.5 90.75\n",
      "\n",
      " 907 30.5 93.25\n",
      "\n",
      " 908 30.5 93.5\n",
      "\n",
      " 909 30.5 93.75\n",
      "\n",
      " 910 30.5 94.0\n",
      "\n",
      " 911 30.5 94.25\n",
      "\n",
      " 912 30.5 94.5\n",
      "\n",
      " 913 30.5 94.75\n",
      "\n",
      " 914 30.5 95.0\n",
      "\n",
      " 915 30.5 95.25\n",
      "\n",
      " 916 30.5 99.5\n",
      "\n",
      " 917 30.25 79.75\n",
      "\n",
      " 918 30.25 80.0\n",
      "\n",
      " 919 30.25 80.25\n",
      "\n",
      " 920 30.25 80.5\n",
      "\n",
      " 921 30.25 80.75\n",
      "\n",
      " 922 30.25 81.5\n",
      "\n",
      " 923 30.25 81.75\n",
      "\n",
      " 924 30.25 82.0\n",
      "\n",
      " 925 30.25 82.25\n",
      "\n",
      " 926 30.25 84.5\n",
      "\n",
      " 927 30.25 85.0\n",
      "\n",
      " 928 30.25 86.25\n",
      "\n",
      " 929 30.25 88.25\n",
      "\n",
      " 930 30.25 90.25\n",
      "\n",
      " 931 30.25 90.5\n",
      "\n",
      " 932 30.25 90.75\n",
      "\n",
      " 933 30.25 93.25\n",
      "\n",
      " 934 30.25 93.5\n",
      "\n",
      " 935 30.25 93.75\n",
      "\n",
      " 936 30.25 94.0\n",
      "\n",
      " 937 30.25 94.25\n",
      "\n",
      " 938 30.25 94.5\n",
      "\n",
      " 939 30.25 94.75\n",
      "\n",
      " 940 30.25 95.0\n",
      "\n",
      " 941 30.25 95.25\n",
      "\n",
      " 942 30.25 95.5\n",
      "\n",
      " 943 30.25 95.75\n",
      "\n",
      " 944 30.25 96.0\n",
      "\n",
      " 945 30.25 102.0\n",
      "\n",
      " 946 30.0 80.5\n",
      "\n",
      " 947 30.0 81.0\n",
      "\n",
      " 948 30.0 81.25\n",
      "\n",
      " 949 30.0 81.5\n",
      "\n",
      " 950 30.0 82.0\n",
      "\n",
      " 951 30.0 82.25\n",
      "\n",
      " 952 30.0 82.5\n",
      "\n",
      " 953 30.0 82.75\n",
      "\n",
      " 954 30.0 84.5\n",
      "\n",
      " 955 30.0 85.0\n",
      "\n",
      " 956 30.0 86.25\n",
      "\n",
      " 957 30.0 90.0\n",
      "\n",
      " 958 30.0 90.25\n",
      "\n",
      " 959 30.0 90.5\n",
      "\n",
      " 960 30.0 93.0\n",
      "\n",
      " 961 30.0 93.25\n",
      "\n",
      " 962 30.0 94.25\n",
      "\n",
      " 963 30.0 94.5\n",
      "\n",
      " 964 30.0 94.75\n",
      "\n",
      " 965 30.0 95.0\n",
      "\n",
      " 966 30.0 95.25\n",
      "\n",
      " 967 30.0 95.5\n",
      "\n",
      " 968 30.0 95.75\n",
      "\n",
      " 969 30.0 96.0\n",
      "\n",
      " 970 30.0 96.25\n",
      "\n",
      " 971 29.75 81.0\n",
      "\n",
      " 972 29.75 81.5\n",
      "\n",
      " 973 29.75 82.25\n",
      "\n",
      " 974 29.75 82.5\n",
      "\n",
      " 975 29.75 82.75\n",
      "\n",
      " 976 29.75 83.0\n",
      "\n",
      " 977 29.75 84.5\n",
      "\n",
      " 978 29.75 84.75\n",
      "\n",
      " 979 29.75 85.25\n",
      "\n",
      " 980 29.75 86.75\n",
      "\n",
      " 981 29.75 88.25\n",
      "\n",
      " 982 29.75 93.5\n",
      "\n",
      " 983 29.75 94.75\n",
      "\n",
      " 984 29.75 95.0\n",
      "\n",
      " 985 29.75 95.75\n",
      "\n",
      " 986 29.75 96.0\n",
      "\n",
      " 987 29.75 96.25\n",
      "\n",
      " 988 29.75 96.5\n",
      "\n",
      " 989 29.75 96.75\n",
      "\n",
      " 990 29.75 97.0\n",
      "\n",
      " 991 29.75 97.25\n",
      "\n",
      " 992 29.75 99.5\n",
      "\n",
      " 993 29.75 101.75\n",
      "\n",
      " 994 29.75 102.0\n",
      "\n",
      " 995 29.5 82.5\n",
      "\n",
      " 996 29.5 82.75\n",
      "\n",
      " 997 29.5 85.5\n",
      "\n",
      " 998 29.5 95.0\n",
      "\n",
      " 999 29.5 95.25\n",
      "\n",
      " 1000 29.5 95.75\n",
      "\n",
      " 1001 29.5 96.0\n",
      "\n",
      " 1002 29.5 96.25\n",
      "\n",
      " 1003 29.5 96.5\n",
      "\n",
      " 1004 29.5 96.75\n",
      "\n",
      " 1005 29.5 97.0\n",
      "\n",
      " 1006 29.5 97.25\n",
      "\n",
      " 1007 29.5 97.5\n",
      "\n",
      " 1008 29.5 101.75\n",
      "\n",
      " 1009 29.5 102.0\n",
      "\n",
      " 1010 29.25 82.5\n",
      "\n",
      " 1011 29.25 82.75\n",
      "\n",
      " 1012 29.25 83.75\n",
      "\n",
      " 1013 29.25 95.0\n",
      "\n",
      " 1014 29.25 96.0\n",
      "\n",
      " 1015 29.25 96.25\n",
      "\n",
      " 1016 29.25 96.5\n",
      "\n",
      " 1017 29.25 96.75\n",
      "\n",
      " 1018 29.25 97.0\n",
      "\n",
      " 1019 29.25 97.25\n",
      "\n",
      " 1020 29.0 82.75\n",
      "\n",
      " 1021 29.0 83.5\n",
      "\n",
      " 1022 29.0 83.75\n",
      "\n",
      " 1023 29.0 84.0\n",
      "\n",
      " 1024 29.0 84.25\n",
      "\n",
      " 1025 29.0 84.5\n",
      "\n",
      " 1026 29.0 90.25\n",
      "\n",
      " 1027 29.0 94.0\n",
      "\n",
      " 1028 29.0 96.25\n",
      "\n",
      " 1029 29.0 96.5\n",
      "\n",
      " 1030 29.0 96.75\n",
      "\n",
      " 1031 29.0 97.0\n",
      "\n",
      " 1032 29.0 97.25\n",
      "\n",
      " 1033 29.0 97.5\n",
      "\n",
      " 1034 29.0 97.75\n",
      "\n",
      " 1035 28.75 83.0\n",
      "\n",
      " 1036 28.75 83.25\n",
      "\n",
      " 1037 28.75 83.5\n",
      "\n",
      " 1038 28.75 83.75\n",
      "\n",
      " 1039 28.75 84.0\n",
      "\n",
      " 1040 28.75 84.25\n",
      "\n",
      " 1041 28.75 84.5\n",
      "\n",
      " 1042 28.75 84.75\n",
      "\n",
      " 1043 28.75 85.0\n",
      "\n",
      " 1044 28.75 85.25\n",
      "\n",
      " 1045 28.75 85.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1046 28.75 90.25\n",
      "\n",
      " 1047 28.75 93.25\n",
      "\n",
      " 1048 28.75 93.5\n",
      "\n",
      " 1049 28.75 96.5\n",
      "\n",
      " 1050 28.75 97.75\n",
      "\n",
      " 1051 28.75 98.25\n",
      "\n",
      " 1052 28.5 83.75\n",
      "\n",
      " 1053 28.5 84.0\n",
      "\n",
      " 1054 28.5 84.25\n",
      "\n",
      " 1055 28.5 84.5\n",
      "\n",
      " 1056 28.5 84.75\n",
      "\n",
      " 1057 28.5 85.0\n",
      "\n",
      " 1058 28.5 85.25\n",
      "\n",
      " 1059 28.5 85.5\n",
      "\n",
      " 1060 28.5 85.75\n",
      "\n",
      " 1061 28.5 91.0\n",
      "\n",
      " 1062 28.5 91.25\n",
      "\n",
      " 1063 28.5 96.5\n",
      "\n",
      " 1064 28.5 97.5\n",
      "\n",
      " 1065 28.5 98.25\n",
      "\n",
      " 1066 28.5 98.5\n",
      "\n",
      " 1067 28.5 98.75\n",
      "\n",
      " 1068 28.25 85.0\n",
      "\n",
      " 1069 28.25 85.25\n",
      "\n",
      " 1070 28.25 85.5\n",
      "\n",
      " 1071 28.25 85.75\n",
      "\n",
      " 1072 28.25 86.0\n",
      "\n",
      " 1073 28.25 86.25\n",
      "\n",
      " 1074 28.25 86.5\n",
      "\n",
      " 1075 28.25 86.75\n",
      "\n",
      " 1076 28.25 87.0\n",
      "\n",
      " 1077 28.25 87.5\n",
      "\n",
      " 1078 28.25 89.5\n",
      "\n",
      " 1079 28.25 89.75\n",
      "\n",
      " 1080 28.25 90.0\n",
      "\n",
      " 1081 28.25 90.25\n",
      "\n",
      " 1082 28.25 90.5\n",
      "\n",
      " 1083 28.25 90.75\n",
      "\n",
      " 1084 28.25 91.0\n",
      "\n",
      " 1085 28.25 91.25\n",
      "\n",
      " 1086 28.25 91.5\n",
      "\n",
      " 1087 28.25 91.75\n",
      "\n",
      " 1088 28.25 92.75\n",
      "\n",
      " 1089 28.25 97.0\n",
      "\n",
      " 1090 28.25 97.5\n",
      "\n",
      " 1091 28.25 98.75\n",
      "\n",
      " 1092 28.0 86.0\n",
      "\n",
      " 1093 28.0 86.25\n",
      "\n",
      " 1094 28.0 86.5\n",
      "\n",
      " 1095 28.0 86.75\n",
      "\n",
      " 1096 28.0 87.0\n",
      "\n",
      " 1097 28.0 87.25\n",
      "\n",
      " 1098 28.0 87.5\n",
      "\n",
      " 1099 28.0 87.75\n",
      "\n",
      " 1100 28.0 88.0\n",
      "\n",
      " 1101 28.0 88.25\n",
      "\n",
      " 1102 28.0 88.5\n",
      "\n",
      " 1103 28.0 88.75\n",
      "\n",
      " 1104 28.0 89.0\n",
      "\n",
      " 1105 28.0 89.5\n",
      "\n",
      " 1106 28.0 89.75\n",
      "\n",
      " 1107 28.0 90.0\n",
      "\n",
      " 1108 28.0 90.25\n",
      "\n",
      " 1109 28.0 90.5\n",
      "\n",
      " 1110 28.0 90.75\n",
      "\n",
      " 1111 28.0 91.0\n",
      "\n",
      " 1112 28.0 91.25\n",
      "\n",
      " 1113 28.0 91.5\n",
      "\n",
      " 1114 28.0 91.75\n",
      "\n",
      " 1115 28.0 92.5\n",
      "\n",
      " 1116 28.0 92.75\n",
      "\n",
      " 1117 27.75 86.5\n",
      "\n",
      " 1118 27.75 86.75\n",
      "\n",
      " 1119 27.75 87.0\n",
      "\n",
      " 1120 27.75 87.25\n",
      "\n",
      " 1121 27.75 87.5\n",
      "\n",
      " 1122 27.75 87.75\n",
      "\n",
      " 1123 27.75 88.0\n",
      "\n",
      " 1124 27.75 88.25\n",
      "\n",
      " 1125 27.75 88.75\n",
      "\n",
      " 1126 27.75 89.0\n",
      "\n",
      " 1127 27.75 89.25\n",
      "\n",
      " 1128 27.75 92.0\n",
      "\n",
      " 1129 27.75 92.25\n",
      "\n",
      " 1130 27.75 92.5\n",
      "\n",
      " 1131 27.5 88.0\n",
      "\n",
      " 1132 27.5 88.25\n"
     ]
    }
   ],
   "source": [
    "# Process each group and derive elevation statistics for the debris cover\n",
    "year_mean = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "year_std = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "year_med = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "year_mad = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "doy_mean = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "doy_std = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "doy_med = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "doy_mad = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "dayfrac_mean = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "dayfrac_std = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "dayfrac_med = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "dayfrac_mad = np.zeros((len(ds.latitude.values), len(ds.longitude.values)))\n",
    "\n",
    "# for nlatlon, latlon_idx in enumerate([1095]):\n",
    "for nlatlon, latlon_idx in enumerate(list(np.arange(0,len(latlon_nearidx_unique)))):\n",
    "        \n",
    "    main_glac_rgi_subset = main_glac_rgi[main_glac_rgi['latlon_unique_no'] == latlon_idx]\n",
    "    \n",
    "    lat_idx, lon_idx = latlon_unique_dict_reversed[latlon_idx]\n",
    "    \n",
    "    print('\\n', latlon_idx, ds_latlon['latitude'][lat_idx].values, ds_latlon['longitude'][lon_idx].values)\n",
    "\n",
    "    df_all = None\n",
    "    \n",
    "    doy_list = []\n",
    "    year_list = []\n",
    "    dayfrac_list = []\n",
    "        \n",
    "        # =====\n",
    "    for nglac, glac_idx in enumerate(main_glac_rgi_subset.index.values):\n",
    "#     for nglac, glac_idx in enumerate([main_glac_rgi_subset.index.values[1]]):\n",
    "        glac_str = main_glac_rgi_subset.loc[glac_idx,'rgino_str']\n",
    "        rgiid = main_glac_rgi_subset.loc[glac_idx,'RGIId']\n",
    "        region = glac_str.split('.')[0]\n",
    "\n",
    "        if verbose:\n",
    "            print(nglac, glac_idx, rgiid,'\\n')\n",
    "        \n",
    "        df = pd.read_csv(input.mb_binned_fp_wdebris + main_glac_rgi_subset.loc[glac_idx,'bin_fn'])\n",
    "\n",
    "\n",
    "        # Process only glaciers with debris\n",
    "        debris_switch=False\n",
    "        if ' perc_debris' in df.columns:\n",
    "            # Process dataframe\n",
    "            output_cns = ['# bin_center_elev_m', ' z1_bin_area_valid_km2', ' perc_debris']\n",
    "            df = df[output_cns]\n",
    "            df['# bin_center_elev_m'] = df['# bin_center_elev_m'].astype(np.float) \n",
    "            df[' z1_bin_area_valid_km2'] = df[' z1_bin_area_valid_km2'].astype(np.float)\n",
    "            \n",
    "            # Remove nan values\n",
    "            df[' perc_debris'] = df[' perc_debris'].astype(np.float)\n",
    "            df.fillna(0, inplace=True)\n",
    "            \n",
    "            if verbose:\n",
    "                print(glac_str, df[' perc_debris'].max())\n",
    "            \n",
    "            df['area_debris_km2'] = df[' z1_bin_area_valid_km2'] * df[' perc_debris'] / 100\n",
    "            \n",
    "            if df[' perc_debris'].max() > 10:\n",
    "                debris_switch = True\n",
    "                debris_idx = np.where(df[' perc_debris'] > 50)[0]\n",
    "                \n",
    "        if debris_switch:\n",
    "            if verbose:\n",
    "                print('processing', glac_str)\n",
    "\n",
    "            # ===== Project shapefile =====\n",
    "            huss_dir = huss_dir_sample.replace('XXXX',str(region.zfill(2)))\n",
    "            huss_fn = huss_fn_sample.replace('XXXX',glac_str)\n",
    "\n",
    "            proj_fn = os.path.join(huss_dir, huss_fn) # THIS PROJECTION IS KEY!\n",
    "            ds = gdal.Open(proj_fn)\n",
    "            prj = ds.GetProjection()\n",
    "            srs = osr.SpatialReference(wkt=prj)\n",
    "            aea_srs = srs\n",
    "\n",
    "            # If projected shapefile already exists, then skip projection\n",
    "            glac_shp_proj_fn = glac_shp_proj_fp + glac_str + '_crs' + str(aea_srs.GetAttrValue(\"AUTHORITY\", 1)) + '.shp'\n",
    "\n",
    "            if os.path.exists(glac_shp_proj_fn) == False:\n",
    "                glac_shp_proj = glac_shp_single.to_crs({'init': 'epsg:' + str(aea_srs.GetAttrValue(\"AUTHORITY\", 1))})\n",
    "                glac_shp_proj.to_file(glac_shp_proj_fn)\n",
    "\n",
    "                # Shape layer processing\n",
    "                glac_shp_init = gpd.read_file(glac_shp_fn_dict[region])\n",
    "                if verbose:\n",
    "                    print('Shp init crs:', glac_shp_init.crs)\n",
    "\n",
    "                glac_shp_single = glac_shp_init[glac_shp_init['RGIId'] == rgiid]\n",
    "                glac_shp_single = glac_shp_single.reset_index()\n",
    "\n",
    "\n",
    "            glac_shp_ds = ogr.Open(glac_shp_proj_fn, 0)\n",
    "            glac_shp_lyr = glac_shp_ds.GetLayer()\n",
    "            #This should be contained in features\n",
    "            glac_shp_srs = glac_shp_lyr.GetSpatialRef()\n",
    "            feat_count = glac_shp_lyr.GetFeatureCount()\n",
    "            if verbose:\n",
    "                print(\"Input glacier polygon count: %i\" % feat_count)\n",
    "\n",
    "            # Load DEM\n",
    "            z1_dir = z1_dir_sample.replace('XXXX',str(region.zfill(2)))\n",
    "            z1_fn = z1_fn_sample.replace('XXXX',glac_str)\n",
    "            z1_ds = gdal.Open(z1_dir + z1_fn)\n",
    "            z1_int_geom = geolib.ds_geom_intersection([z1_ds, z1_ds], t_srs=glac_shp_srs)\n",
    "\n",
    "            glacfeat_list = []\n",
    "            glacname_fieldname = \"Name\"\n",
    "            glacnum_fieldname = \"RGIId\"\n",
    "            glacnum_fmt = '%08.5f'\n",
    "\n",
    "            for n, feat in enumerate(glac_shp_lyr):\n",
    "                gf = GlacFeat(feat, glacname_fieldname, glacnum_fieldname)\n",
    "                if verbose:\n",
    "                    print(\"%i of %i: %s\" % (n+1, feat_count, gf.feat_fn))\n",
    "                #NOTE: Input must be in projected coordinate system, ideally equal area\n",
    "                #Should check this and reproject\n",
    "                gf.geom_attributes(srs=aea_srs)\n",
    "                glacfeat_list.append(gf)\n",
    "\n",
    "            if verbose:\n",
    "                print(gf.feat_fn)\n",
    "\n",
    "            fn_dict = OrderedDict()\n",
    "            #We at least want to warp the two input DEMs\n",
    "            fn_dict['z1'] = os.path.join(z1_dir, z1_fn)\n",
    "\n",
    "            if extra_layers and (gf.glac_area_km2 > min_glac_area_writeout):\n",
    "                if verbose:\n",
    "                    print(gf.glacnum)\n",
    "\n",
    "                # Ice thickness data\n",
    "                ice_thick_fn = os.path.join(huss_dir, huss_fn)\n",
    "                if os.path.exists(ice_thick_fn):\n",
    "                    fn_dict['ice_thick'] = ice_thick_fn\n",
    "\n",
    "\n",
    "                if os.path.exists(input.ts_fp + input.ts_fn_dict[input.roi]):\n",
    "                    fn_dict['ts'] = input.ts_fp + input.ts_fn_dict[input.roi]\n",
    "                    \n",
    "                if os.path.exists(input.ts_fp + input.ts_dayfrac_fn_dict[input.roi]):\n",
    "                    fn_dict['ts_dayfrac'] = input.ts_fp + input.ts_dayfrac_fn_dict[input.roi]\n",
    "                if os.path.exists(input.ts_fp + input.ts_year_fn_dict[input.roi]):\n",
    "                    fn_dict['ts_year'] = input.ts_fp + input.ts_year_fn_dict[input.roi]\n",
    "                if os.path.exists(input.ts_fp + input.ts_doy_fn_dict[input.roi]):\n",
    "                    fn_dict['ts_doy'] = input.ts_fp + input.ts_doy_fn_dict[input.roi]\n",
    "\n",
    "\n",
    "            #Expand extent to include buffered region around glacier polygon\n",
    "            warp_extent = geolib.pad_extent(gf.glac_geom_extent, width=buff_dist)\n",
    "            if verbose:\n",
    "                print(\"Expanding extent\")\n",
    "                print(gf.glac_geom_extent)\n",
    "                print(warp_extent)\n",
    "                print(aea_srs)\n",
    "\n",
    "            #Warp everything to common res/extent/proj\n",
    "            ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=input.ts_stats_res, \\\n",
    "                    extent=warp_extent, t_srs=aea_srs, verbose=verbose, \\\n",
    "                    r='cubic')\n",
    "\n",
    "            ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "\n",
    "            if verbose:\n",
    "                print(ds_list)\n",
    "                print(fn_dict.keys())\n",
    "\n",
    "            #Prepare mask for all glaciers within buffered area, not just the current glacier polygon\n",
    "            glac_shp_ds = ogr.Open(glac_shp_proj_fn, 0)\n",
    "            glac_shp_lyr = glac_shp_ds.GetLayer()\n",
    "\n",
    "            #Get global glacier mask\n",
    "            #Want this to be True over ALL glacier surfaces, not just the current polygon\n",
    "            glac_shp_lyr_mask = geolib.lyr2mask(glac_shp_lyr, ds_dict['ice_thick'])\n",
    "\n",
    "            #Create buffer around glacier polygon\n",
    "            glac_geom_buff = gf.glac_geom.Buffer(buff_dist)\n",
    "            #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "            glac_geom_buff_mask = geolib.geom2mask(glac_geom_buff, ds_dict['ice_thick'])\n",
    "\n",
    "            # ds masks\n",
    "            ds_list_masked = [iolib.ds_getma(i) for i in ds_list]\n",
    "            dem1 = np.ma.masked_less_equal(ds_list_masked[0], 0)\n",
    "            dems_mask = dem1.mask\n",
    "            if verbose:\n",
    "                print('list of datasets:', len(ds_list_masked), fn_dict.values())\n",
    "\n",
    "            #Combine to identify ~1 km buffer around glacier polygon over static rock\n",
    "            static_buffer_mask = np.ma.mask_or(~glac_shp_lyr_mask, glac_geom_buff_mask)\n",
    "            static_shp_lyr_mask = np.ma.mask_or(static_buffer_mask, dems_mask)\n",
    "\n",
    "            if 'z1' in ds_dict:\n",
    "                #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "                glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1'])\n",
    "                gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']))\n",
    "\n",
    "                #Now apply glacier mask AND mask NaN values\n",
    "                glac_geom_mask = np.ma.mask_or(glac_geom_mask, dems_mask)\n",
    "                gf.z1 = np.ma.array(gf.z1, mask=glac_geom_mask)\n",
    "\n",
    "                if verbose:\n",
    "                    print('\\n\\n# z1 pixels:', gf.z1.count(), '\\n')\n",
    "                if gf.z1.count() == 0:\n",
    "                    if verbose:\n",
    "                        print(\"No z1 pixels\")\n",
    "            else:\n",
    "                print(\"Unable to load z1 ds\")\n",
    "\n",
    "            # ===== ADD VARIOUS LAYERS TO gf =====\n",
    "            if nlatlon + nglac == 0:\n",
    "                print('\\n\\nHACK TO BYPASS VALID AREA\\n\\n')\n",
    "            gf.valid_area_perc = 100\n",
    "\n",
    "            if gf.valid_area_perc < (100. * min_valid_area_perc):\n",
    "                if verbose:\n",
    "                    print(\"Not enough valid pixels. %0.1f%% percent of glacier polygon area\" % (gf.valid_area_perc))\n",
    "            #     return None\n",
    "\n",
    "            else:\n",
    "                #Filter dz - throw out abs differences >150 m\n",
    "\n",
    "                #Compute dz, volume change, mass balance and stats\n",
    "                gf.z1_stats = malib.get_stats(gf.z1)\n",
    "                z1_elev_med = gf.z1_stats[5]\n",
    "                z1_elev_min, z1_elev_max = malib.calcperc(gf.z1, (0.1, 99.9))\n",
    "\n",
    "                #Caluclate stats for aspect and slope using z2\n",
    "                #Requires GDAL 2.1+\n",
    "                gf.z1_aspect = np.ma.array(geolib.gdaldem_mem_ds(ds_dict['z1'], processing='aspect', returnma=True), mask=glac_geom_mask)\n",
    "                gf.z1_aspect_stats = malib.get_stats(gf.z1_aspect)\n",
    "                z1_aspect_med = gf.z1_aspect_stats[5]\n",
    "                gf.z1_slope = np.ma.array(geolib.gdaldem_mem_ds(ds_dict['z1'], processing='slope', returnma=True), mask=glac_geom_mask)\n",
    "                gf.z1_slope_stats = malib.get_stats(gf.z1_slope)\n",
    "                z1_slope_med = gf.z1_slope_stats[5]\n",
    "\n",
    "                #Can estimate ELA values computed from hypsometry and typical AAR\n",
    "                #For now, assume ELA is mean\n",
    "                gf.z1_ela = None\n",
    "                gf.z1_ela = gf.z1_stats[3]\n",
    "                #Note: in theory, the ELA should get higher with mass loss\n",
    "                #In practice, using mean and same polygon, ELA gets lower as glacier surface thins\n",
    "\n",
    "\n",
    "                if extra_layers and (gf.glac_area_km2 > min_glac_area_writeout):\n",
    "                    if 'ice_thick' in ds_dict:\n",
    "                        #Load ice thickness\n",
    "                        gf.H = np.ma.array(iolib.ds_getma(ds_dict['ice_thick']), mask=glac_geom_mask)\n",
    "                        gf.H_mean = gf.H.mean()\n",
    "                        if verbose:\n",
    "                            print('mean ice thickness [m]:', gf.H_mean)\n",
    "\n",
    "                    if 'ts' in ds_dict:\n",
    "                        #Load surface temperature maps\n",
    "                        gf.ts = np.ma.array(iolib.ds_getma(ds_dict['ts']), mask=glac_geom_mask)\n",
    "                        gf.ts.mask = np.ma.mask_or(glac_geom_mask, np.ma.getmask(np.ma.masked_array(gf.ts.data, np.isnan(gf.ts.data))))\n",
    "                    else:\n",
    "                        gf.ts = None\n",
    "                        \n",
    "                    if 'ts_dayfrac' in ds_dict:\n",
    "                        #Load surface temperature maps\n",
    "                        gf.ts_dayfrac = np.ma.array(iolib.ds_getma(ds_dict['ts_dayfrac']), mask=glac_geom_mask)\n",
    "                        gf.ts_dayfrac.mask = np.ma.mask_or(glac_geom_mask, \n",
    "                                                           np.ma.getmask(np.ma.masked_array(gf.ts_dayfrac.data, np.isnan(gf.ts_dayfrac.data))))\n",
    "                    else:\n",
    "                        gf.ts_dayfrac = None\n",
    "                        \n",
    "                    if 'ts_year' in ds_dict:\n",
    "                        #Load surface temperature maps\n",
    "                        gf.ts_year = np.ma.array(iolib.ds_getma(ds_dict['ts_year']), mask=glac_geom_mask)\n",
    "                        gf.ts_year.mask = np.ma.mask_or(glac_geom_mask, \n",
    "                                                        np.ma.getmask(np.ma.masked_array(gf.ts_year.data, np.isnan(gf.ts_year.data))))\n",
    "                    else:\n",
    "                        gf.ts_year = None\n",
    "                        \n",
    "                    if 'ts_doy' in ds_dict:\n",
    "                        #Load surface temperature maps\n",
    "                        gf.ts_doy = np.ma.array(iolib.ds_getma(ds_dict['ts_doy']), mask=glac_geom_mask)\n",
    "                        gf.ts_doy.mask = np.ma.mask_or(glac_geom_mask, \n",
    "                                                       np.ma.getmask(np.ma.masked_array(gf.ts_doy.data, np.isnan(gf.ts_doy.data))))\n",
    "                    else:\n",
    "                        gf.ts_doy = None\n",
    "\n",
    "                gf.res = geolib.get_res(ds_dict['z1'])\n",
    "\n",
    "                if verbose:\n",
    "                    print('Area [km2]:', gf.glac_area / 1e6)\n",
    "                    print('-------------------------------')\n",
    "                    \n",
    "                # Isolate values with positive surface temperatures below mean elevation\n",
    "                zmean_mask = np.ma.mask_or(glac_geom_mask,  \n",
    "                                           np.ma.getmask(np.ma.masked_greater(gf.z1, gf.z1.compressed().mean())))\n",
    "                ts_zmean_mask = np.ma.mask_or(zmean_mask,\n",
    "                                              np.ma.getmask(np.ma.masked_less(gf.ts, 0)))\n",
    "\n",
    "                gf.ts_doy.mask = zmean_mask\n",
    "                gf.ts_year.mask = zmean_mask\n",
    "                gf.ts_dayfrac.mask = zmean_mask\n",
    "                doy_list.extend(list(gf.ts_doy.compressed()))\n",
    "                year_list.extend(list(gf.ts_year.compressed()))\n",
    "                dayfrac_list.extend(list(gf.ts_dayfrac.compressed()))\n",
    "                \n",
    "    \n",
    "    # Compute statistics\n",
    "    year_mean_latlon = np.mean(year_list)\n",
    "    year_std_latlon = np.std(year_list)\n",
    "    year_med_latlon = malib.fast_median(year_list)\n",
    "    year_mad_latlon = malib.mad(year_list)\n",
    "    doy_mean_latlon = np.mean(doy_list)\n",
    "    doy_std_latlon = np.std(doy_list)\n",
    "    doy_med_latlon = malib.fast_median(doy_list)\n",
    "    doy_mad_latlon = malib.mad(doy_list)\n",
    "    dayfrac_mean_latlon = np.mean(dayfrac_list)\n",
    "    dayfrac_std_latlon = np.std(dayfrac_list)\n",
    "    dayfrac_med_latlon = malib.fast_median(dayfrac_list)\n",
    "    dayfrac_mad_latlon = malib.mad(dayfrac_list)\n",
    "    \n",
    "    # Update array\n",
    "    year_mean[lat_idx,lon_idx] = year_mean_latlon\n",
    "    year_std[lat_idx,lon_idx] = year_std_latlon\n",
    "    year_med[lat_idx,lon_idx] = year_med_latlon\n",
    "    year_mad[lat_idx,lon_idx] = year_mad_latlon\n",
    "    doy_mean[lat_idx,lon_idx] = doy_mean_latlon\n",
    "    doy_std[lat_idx,lon_idx] = doy_std_latlon\n",
    "    doy_med[lat_idx,lon_idx] = doy_med_latlon\n",
    "    doy_mad[lat_idx,lon_idx] = doy_mad_latlon\n",
    "    dayfrac_mean[lat_idx,lon_idx] = dayfrac_mean_latlon\n",
    "    dayfrac_std[lat_idx,lon_idx] = dayfrac_std_latlon\n",
    "    dayfrac_med[lat_idx,lon_idx] = dayfrac_med_latlon\n",
    "    dayfrac_mad[lat_idx,lon_idx] = dayfrac_mad_latlon\n",
    "    \n",
    "#     print('  year mean +/- std:', np.round(year_mean_latlon,1), np.round(year_std_latlon,1)) \n",
    "#     print('  doy mean +/- std:', np.round(doy_mean_latlon,1), np.round(doy_std_latlon,1)) \n",
    "#     print('    doy median +/- mad:', np.round(doy_med_latlon,1), np.round(doy_mad_latlon,1)) \n",
    "#     print('  dayfrac mean +/- std:', np.round(dayfrac_mean_latlon,3), np.round(dayfrac_std_latlon,3))   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:       (latitude: 81, longitude: 161)\n",
      "Coordinates:\n",
      "  * latitude      (latitude) float32 45.0 44.75 44.5 44.25 ... 25.5 25.25 25.0\n",
      "  * longitude     (longitude) float32 65.0 65.25 65.5 ... 104.5 104.75 105.0\n",
      "Data variables:\n",
      "    year_mean     (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "    year_std      (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "    year_med      (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "    year_mad      (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "    doy_mean      (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "    doy_std       (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "    doy_med       (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "    doy_mad       (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "    dayfrac_mean  (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "    dayfrac_std   (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "    dayfrac_med   (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
      "    dayfrac_mad   (latitude, longitude) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# Export to dataset\n",
    "ds_ts_stats = xr.Dataset({'year_mean': (['latitude', 'longitude'], year_mean),\n",
    "                          'year_std': (['latitude', 'longitude'], year_std),\n",
    "                          'year_med': (['latitude', 'longitude'], year_med),\n",
    "                          'year_mad': (['latitude', 'longitude'], year_mad),\n",
    "                          'doy_mean': (['latitude', 'longitude'], doy_mean),\n",
    "                          'doy_std': (['latitude', 'longitude'], doy_std),\n",
    "                          'doy_med': (['latitude', 'longitude'], doy_med),\n",
    "                          'doy_mad': (['latitude', 'longitude'], doy_mad),\n",
    "                          'dayfrac_mean': (['latitude', 'longitude'], dayfrac_mean),\n",
    "                          'dayfrac_std': (['latitude', 'longitude'], dayfrac_std),\n",
    "                          'dayfrac_med': (['latitude', 'longitude'], dayfrac_med),\n",
    "                          'dayfrac_mad': (['latitude', 'longitude'], dayfrac_mad),},\n",
    "                          coords={'latitude': ds_latlon.latitude.values,\n",
    "                                  'longitude': ds_latlon.longitude.values})\n",
    "\n",
    "attrs_dict={\n",
    "     'year_mean':{'units':'-',\n",
    "         'long_name':'mean year',\n",
    "         'comment': 'mean year when mosaicked surface temperature satellite image was acquired'},\n",
    "     'year_std':{'units':'-',\n",
    "         'long_name':'year standard deviation',\n",
    "         'comment': 'standard deviation of year when mosaicked surface temperature satellite image was acquired'},\n",
    "     'year_med':{'units':'-',\n",
    "         'long_name':'median year',\n",
    "         'comment': 'median year when mosaicked surface temperature satellite image was acquired'},\n",
    "     'year_mad':{'units':'-',\n",
    "         'long_name':'median absolute deviation year',\n",
    "         'comment': 'median absolute deviation of year of when mosaicked surface temperature satellite image was acquired'},\n",
    "     'doy_mean':{'units':'days since January 1',\n",
    "         'long_name':'mean day of year',\n",
    "         'comment': 'mean day of year when mosaicked surface temperature satellite image was acquired'},\n",
    "     'doy_std':{'units':'days since January 1',\n",
    "         'long_name':'day of year standard deviation',\n",
    "         'comment': 'standard deviation of day of year when mosaicked surface temperature satellite image was acquired'},\n",
    "     'doy_med':{'units':'days since January 1',\n",
    "         'long_name':'median day of year',\n",
    "         'comment': 'median day of year when mosaicked surface temperature satellite image was acquired'},\n",
    "     'doy_mad':{'units':'days since January 1',\n",
    "         'long_name':'median absolute deviation day of year',\n",
    "         'comment': 'day of year of year of when mosaicked surface temperature satellite image was acquired'},\n",
    "     'dayfrac_mean':{'units':'-',\n",
    "         'long_name':'mean hour',\n",
    "         'comment': 'mean hour of when mosaicked surface temperature satellite image was acquired'},\n",
    "     'dayfrac_std':{'units':'-',\n",
    "         'long_name':'year standard deviation',\n",
    "         'comment': 'standard deviation of hour when mosaicked surface temperature satellite image was acquired'},\n",
    "     'dayfrac_med':{'units':'-',\n",
    "         'long_name':'median hour',\n",
    "         'comment': 'median hour when mosaicked surface temperature satellite image was acquired'},\n",
    "     'dayfrac_mad':{'units':'-',\n",
    "         'long_name':'median absolute deviation hour',\n",
    "         'comment': 'median absolute deviation of hour of when mosaicked surface temperature satellite image was acquired'},}\n",
    "\n",
    "for vn in ['year_mean', 'year_std', 'year_med', 'year_mad',\n",
    "           'doy_mean', 'doy_std', 'doy_med', 'doy_mad',\n",
    "           'dayfrac_mean', 'dayfrac_std', 'dayfrac_med', 'dayfrac_mad',]:\n",
    "    ds_ts_stats[vn].attrs = attrs_dict[vn]\n",
    "    \n",
    "ds_ts_stats.to_netcdf(ts_info_fullfn)\n",
    "                \n",
    "print(ds_ts_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.0 87.0 \n",
      " 2015.0001220703125 0.0016057980246841908 229.2476348876953 51.61998748779297\n"
     ]
    }
   ],
   "source": [
    "lat_idx = 68\n",
    "lon_idx = 88\n",
    "# lat_idx = 37\n",
    "# lon_idx = 46\n",
    "print(ds_latlon['latitude'][lat_idx].values, ds_latlon['longitude'][lon_idx].values,\n",
    "      '\\n', ds_ts_stats['year_mean'][lat_idx,lon_idx].values, ds_ts_stats['year_std'][lat_idx,lon_idx].values, \n",
    "      ds_ts_stats['doy_mean'][lat_idx,lon_idx].values, ds_ts_stats['doy_std'][lat_idx,lon_idx].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/davidrounce/Documents/Dave_Rounce/DebrisGlaciers_WG/Melt_Intercomparison/debris_global/../output/ts_tif/HMA_debris_tsinfo.nc'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_info_fullfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
