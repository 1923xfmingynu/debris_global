{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "Compute elevation statistics for the debris-covered areas in each latitude and longitude\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from scipy import ndimage\n",
    "import xarray as xr\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "from pygeotools.lib import malib, warplib, geolib, iolib, timelib\n",
    "\n",
    "import debrisglobal.globaldebris_input as debris_prms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All DC glaciers: 6834 All DC Area (km2): 6959.884397\n",
      "Subset DC glaciers: 1109 Subset DC Area (km2): 6352.559502\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGIId</th>\n",
       "      <th>GLIMSId</th>\n",
       "      <th>BgnDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>...</th>\n",
       "      <th>Name</th>\n",
       "      <th>DC_Area</th>\n",
       "      <th>DC_BgnDate</th>\n",
       "      <th>DC_EndDate</th>\n",
       "      <th>DC_CTSmean</th>\n",
       "      <th>DC_Area_%</th>\n",
       "      <th>area_singl</th>\n",
       "      <th>DC_Area_v2</th>\n",
       "      <th>DC_Area__1</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RGI60-01.00006</td>\n",
       "      <td>G213756E63571N</td>\n",
       "      <td>20090703</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>-146.269039</td>\n",
       "      <td>63.565440</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.470</td>\n",
       "      <td>1201</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1268100</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>50.395919</td>\n",
       "      <td>12.11</td>\n",
       "      <td>50438</td>\n",
       "      <td>1194194</td>\n",
       "      <td>11.41</td>\n",
       "      <td>MULTIPOLYGON (((-146.21212 63.58992, -146.2115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RGI60-01.00013</td>\n",
       "      <td>G213316E63499N</td>\n",
       "      <td>20090703</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>-146.783771</td>\n",
       "      <td>63.548672</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>209.630</td>\n",
       "      <td>823</td>\n",
       "      <td>...</td>\n",
       "      <td>Susitna Glacier</td>\n",
       "      <td>37403100</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>52.933578</td>\n",
       "      <td>17.84</td>\n",
       "      <td>32298677</td>\n",
       "      <td>38937084</td>\n",
       "      <td>18.57</td>\n",
       "      <td>MULTIPOLYGON (((-146.69834 63.51530, -146.6965...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RGI60-01.00027</td>\n",
       "      <td>G213737E63535N</td>\n",
       "      <td>20090703</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>-146.235312</td>\n",
       "      <td>63.539164</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13.290</td>\n",
       "      <td>1073</td>\n",
       "      <td>...</td>\n",
       "      <td>McGinnis Glacier</td>\n",
       "      <td>1243800</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>52.228899</td>\n",
       "      <td>9.36</td>\n",
       "      <td>129699</td>\n",
       "      <td>1116507</td>\n",
       "      <td>8.40</td>\n",
       "      <td>MULTIPOLYGON (((-146.20847 63.54709, -146.2078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RGI60-01.00033</td>\n",
       "      <td>G213128E63680N</td>\n",
       "      <td>20090703</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>-146.870135</td>\n",
       "      <td>63.680161</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.604</td>\n",
       "      <td>1109</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>940500</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>63.881376</td>\n",
       "      <td>20.43</td>\n",
       "      <td>27022</td>\n",
       "      <td>897454</td>\n",
       "      <td>19.49</td>\n",
       "      <td>MULTIPOLYGON (((-146.87661 63.69865, -146.8766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RGI60-01.00035</td>\n",
       "      <td>G212558E63648N</td>\n",
       "      <td>20090703</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>-147.438831</td>\n",
       "      <td>63.649559</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36.349</td>\n",
       "      <td>1274</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1401300</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>42.695614</td>\n",
       "      <td>3.86</td>\n",
       "      <td>27021</td>\n",
       "      <td>1237798</td>\n",
       "      <td>3.41</td>\n",
       "      <td>MULTIPOLYGON (((-147.55037 63.61418, -147.5503...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>RGI60-01.26861</td>\n",
       "      <td>G225268E59454N</td>\n",
       "      <td>20050811</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>-134.734662</td>\n",
       "      <td>59.455168</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.545</td>\n",
       "      <td>1404</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>430200</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>28.079949</td>\n",
       "      <td>12.14</td>\n",
       "      <td>23419</td>\n",
       "      <td>369293</td>\n",
       "      <td>10.42</td>\n",
       "      <td>MULTIPOLYGON (((-134.72630 59.44781, -134.7252...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>RGI60-01.27101</td>\n",
       "      <td>G216527E60710N</td>\n",
       "      <td>20100919</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>-143.419543</td>\n",
       "      <td>60.736680</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>80.219</td>\n",
       "      <td>492</td>\n",
       "      <td>...</td>\n",
       "      <td>North Fork Lobe Bremner Glacier</td>\n",
       "      <td>15471900</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>44.530354</td>\n",
       "      <td>19.29</td>\n",
       "      <td>245801</td>\n",
       "      <td>15504591</td>\n",
       "      <td>19.33</td>\n",
       "      <td>MULTIPOLYGON (((-143.32822 60.84214, -143.3265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>RGI60-01.27103</td>\n",
       "      <td>G225914E58943N</td>\n",
       "      <td>20050811</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>-134.072577</td>\n",
       "      <td>58.948370</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>86.656</td>\n",
       "      <td>873</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1487700</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>27.500816</td>\n",
       "      <td>1.72</td>\n",
       "      <td>56741</td>\n",
       "      <td>1312248</td>\n",
       "      <td>1.51</td>\n",
       "      <td>MULTIPOLYGON (((-134.05165 58.99606, -134.0511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>RGI60-01.27105</td>\n",
       "      <td>G227608E57164N</td>\n",
       "      <td>20040810</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>-132.400219</td>\n",
       "      <td>57.153059</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>131.574</td>\n",
       "      <td>507</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>21989700</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>21.858476</td>\n",
       "      <td>16.71</td>\n",
       "      <td>50409</td>\n",
       "      <td>21268145</td>\n",
       "      <td>16.16</td>\n",
       "      <td>MULTIPOLYGON (((-132.29926 57.14057, -132.2992...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>RGI60-01.27108</td>\n",
       "      <td>G216273E60232N</td>\n",
       "      <td>20100910</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>-143.058578</td>\n",
       "      <td>60.501252</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>534.228</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>326464200</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>32.223563</td>\n",
       "      <td>61.11</td>\n",
       "      <td>43221</td>\n",
       "      <td>330559910</td>\n",
       "      <td>61.88</td>\n",
       "      <td>MULTIPOLYGON (((-143.68609 60.18918, -143.6855...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1109 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               RGIId         GLIMSId   BgnDate   EndDate      CenLon  \\\n",
       "0     RGI60-01.00006  G213756E63571N  20090703  -9999999 -146.269039   \n",
       "1     RGI60-01.00013  G213316E63499N  20090703  -9999999 -146.783771   \n",
       "2     RGI60-01.00027  G213737E63535N  20090703  -9999999 -146.235312   \n",
       "3     RGI60-01.00033  G213128E63680N  20090703  -9999999 -146.870135   \n",
       "4     RGI60-01.00035  G212558E63648N  20090703  -9999999 -147.438831   \n",
       "...              ...             ...       ...       ...         ...   \n",
       "1104  RGI60-01.26861  G225268E59454N  20050811  -9999999 -134.734662   \n",
       "1105  RGI60-01.27101  G216527E60710N  20100919  -9999999 -143.419543   \n",
       "1106  RGI60-01.27103  G225914E58943N  20050811  -9999999 -134.072577   \n",
       "1107  RGI60-01.27105  G227608E57164N  20040810  -9999999 -132.400219   \n",
       "1108  RGI60-01.27108  G216273E60232N  20100910  -9999999 -143.058578   \n",
       "\n",
       "         CenLat O1Region O2Region     Area  Zmin  ...  \\\n",
       "0     63.565440        1        2   10.470  1201  ...   \n",
       "1     63.548672        1        2  209.630   823  ...   \n",
       "2     63.539164        1        2   13.290  1073  ...   \n",
       "3     63.680161        1        2    4.604  1109  ...   \n",
       "4     63.649559        1        2   36.349  1274  ...   \n",
       "...         ...      ...      ...      ...   ...  ...   \n",
       "1104  59.455168        1        6    3.545  1404  ...   \n",
       "1105  60.736680        1        5   80.219   492  ...   \n",
       "1106  58.948370        1        6   86.656   873  ...   \n",
       "1107  57.153059        1        6  131.574   507  ...   \n",
       "1108  60.501252        1        5  534.228     3  ...   \n",
       "\n",
       "                                 Name    DC_Area  DC_BgnDate  DC_EndDate  \\\n",
       "0                                None    1268100        2013        2017   \n",
       "1                     Susitna Glacier   37403100        2013        2017   \n",
       "2                    McGinnis Glacier    1243800        2013        2017   \n",
       "3                                None     940500        2013        2017   \n",
       "4                                None    1401300        2013        2017   \n",
       "...                               ...        ...         ...         ...   \n",
       "1104                             None     430200        2013        2017   \n",
       "1105  North Fork Lobe Bremner Glacier   15471900        2013        2017   \n",
       "1106                             None    1487700        2013        2017   \n",
       "1107                             None   21989700        2013        2017   \n",
       "1108                             None  326464200        2013        2017   \n",
       "\n",
       "      DC_CTSmean  DC_Area_%  area_singl  DC_Area_v2  DC_Area__1  \\\n",
       "0      50.395919      12.11       50438     1194194       11.41   \n",
       "1      52.933578      17.84    32298677    38937084       18.57   \n",
       "2      52.228899       9.36      129699     1116507        8.40   \n",
       "3      63.881376      20.43       27022      897454       19.49   \n",
       "4      42.695614       3.86       27021     1237798        3.41   \n",
       "...          ...        ...         ...         ...         ...   \n",
       "1104   28.079949      12.14       23419      369293       10.42   \n",
       "1105   44.530354      19.29      245801    15504591       19.33   \n",
       "1106   27.500816       1.72       56741     1312248        1.51   \n",
       "1107   21.858476      16.71       50409    21268145       16.16   \n",
       "1108   32.223563      61.11       43221   330559910       61.88   \n",
       "\n",
       "                                               geometry  \n",
       "0     MULTIPOLYGON (((-146.21212 63.58992, -146.2115...  \n",
       "1     MULTIPOLYGON (((-146.69834 63.51530, -146.6965...  \n",
       "2     MULTIPOLYGON (((-146.20847 63.54709, -146.2078...  \n",
       "3     MULTIPOLYGON (((-146.87661 63.69865, -146.8766...  \n",
       "4     MULTIPOLYGON (((-147.55037 63.61418, -147.5503...  \n",
       "...                                                 ...  \n",
       "1104  MULTIPOLYGON (((-134.72630 59.44781, -134.7252...  \n",
       "1105  MULTIPOLYGON (((-143.32822 60.84214, -143.3265...  \n",
       "1106  MULTIPOLYGON (((-134.05165 58.99606, -134.0511...  \n",
       "1107  MULTIPOLYGON (((-132.29926 57.14057, -132.2992...  \n",
       "1108  MULTIPOLYGON (((-143.68609 60.18918, -143.6855...  \n",
       "\n",
       "[1109 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debris cover extent shapefile with statistics\n",
    "dc_shp = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[debris_prms.roi])\n",
    "dc_shp = dc_shp.sort_values(by=['RGIId'])\n",
    "\n",
    "print('All DC glaciers:', dc_shp.shape[0], 'All DC Area (km2):', dc_shp.DC_Area_v2.sum() / 1e6)\n",
    "\n",
    "# Subset by percent debris-covered or debris-covered area\n",
    "dc_shp_subset = dc_shp[((dc_shp['DC_Area__1'] > debris_prms.dc_percarea_threshold) | \n",
    "                        (dc_shp['DC_Area_v2'] / 1e6 > debris_prms.dc_area_threshold))\n",
    "                        & (dc_shp['Area'] > debris_prms.min_glac_area)].copy()\n",
    "dc_shp_subset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "rgino_str_list_subset = [x.split('-')[1] for x in dc_shp_subset.RGIId.values]\n",
    "\n",
    "print('Subset DC glaciers:', dc_shp_subset.shape[0], 'Subset DC Area (km2):', dc_shp_subset.DC_Area_v2.sum() / 1e6)\n",
    "\n",
    "dc_shp_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109 glaciers in region 1 are included in this model run: ['00006', '00013', '00027', '00033', '00035', '00037', '00038', '00040', '00041', '00042', '00044', '00045', '00046', '00140', '00148', '00187', '00242', '00312', '00336', '00348', '00351', '00399', '00409', '00426', '00434', '00436', '00537', '00544', '00556', '00557', '00558', '00560', '00561', '00565', '00566', '00569', '00570', '00571', '00572', '00574', '00576', '00578', '00579', '00581', '00582', '00584', '00600', '00660', '00670', '00675'] and more\n",
      "This study is focusing on 1109 glaciers in region [1]\n",
      "unique lat/lons: 457 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select glaciers using RGI and find unique latlons\n",
    "#  (Scherler DC shapefiles do not have same CenLat and CenLon for some reason)\n",
    "main_glac_rgi_subset = debris_prms.selectglaciersrgitable(rgino_str_list_subset)\n",
    "main_glac_rgi_subset['CenLon_360'] = main_glac_rgi_subset['CenLon']\n",
    "main_glac_rgi_subset.loc[main_glac_rgi_subset['CenLon_360'] < 0, 'CenLon_360'] = (\n",
    "    360 + main_glac_rgi_subset.loc[main_glac_rgi_subset['CenLon_360'] < 0, 'CenLon_360'])\n",
    "\n",
    "# Load met data and find nearest latlon indices\n",
    "ds = xr.open_dataset(debris_prms.metdata_fp + '../' + debris_prms.metdata_elev_fn)\n",
    "#  argmin() finds the minimum distance between the glacier lat/lon and the GCM pixel\n",
    "lat_nearidx = (np.abs(main_glac_rgi_subset['CenLat'].values[:,np.newaxis] - \n",
    "                      ds['latitude'][:].values).argmin(axis=1))\n",
    "lon_nearidx = (np.abs(main_glac_rgi_subset['CenLon_360'].values[:,np.newaxis] - \n",
    "                      ds['longitude'][:].values).argmin(axis=1))\n",
    "latlon_nearidx = list(zip(lat_nearidx, lon_nearidx))\n",
    "latlon_nearidx_unique = sorted(list(set(latlon_nearidx)))\n",
    "main_glac_rgi_subset['latlon_nearidx'] = latlon_nearidx\n",
    "latlon_unique_dict = dict(zip(latlon_nearidx_unique,np.arange(0,len(latlon_nearidx_unique))))\n",
    "latlon_unique_dict_reversed = dict(zip(np.arange(0,len(latlon_nearidx_unique)),latlon_nearidx_unique))\n",
    "main_glac_rgi_subset['latlon_unique_no'] = main_glac_rgi_subset['latlon_nearidx'].map(latlon_unique_dict)\n",
    "\n",
    "print('unique lat/lons:', len(np.unique(main_glac_rgi_subset['latlon_unique_no'])), '\\n\\n')\n",
    "\n",
    "# Delete me\n",
    "latlon_nearidx_unique_v1 = latlon_nearidx_unique.copy()\n",
    "\n",
    "lat_list = np.array([ds.latitude[x[0]].values for x in latlon_nearidx_unique])\n",
    "lon_list = np.array([ds.longitude[x[1]].values for x in latlon_nearidx_unique])\n",
    "latlon_list = list(tuple(zip(list(lat_list), list(lon_list))))\n",
    "\n",
    "# Pickle unique lat/lons that will be used for melt model\n",
    "with open(debris_prms.latlon_unique_fp + debris_prms.latlon_unique_dict[debris_prms.roi], 'wb') as f:\n",
    "    pickle.dump(latlon_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debris-covered glaciers: 1109 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== LOAD GLACIERS WITH DATA =====\n",
    "main_glac_rgi_subset['mb_fullfn'] = np.nan\n",
    "mb_binned_fp = debris_prms.mb_binned_fp\n",
    "\n",
    "regions_str = [str(x).zfill(2) for x in debris_prms.roi_rgidict[debris_prms.roi]]\n",
    "\n",
    "mb_fns = []\n",
    "mb_rgiids = []\n",
    "for i in os.listdir(mb_binned_fp):\n",
    "    if i.endswith('_mb_bins.csv') and i.split('_')[0].split('.')[0].zfill(2) in regions_str:\n",
    "        mb_fns.append(mb_binned_fp + i)\n",
    "        rgiid_raw = i.split('_')[0]\n",
    "        rgiid = 'RGI60-' + rgiid_raw.split('.')[0].zfill(2) + '.' + rgiid_raw.split('.')[1]\n",
    "        mb_rgiids.append(rgiid)\n",
    "mb_rgiids = sorted(mb_rgiids)\n",
    "mb_fn_df = pd.DataFrame(np.zeros((len(mb_fns),2)), columns=['RGIId', 'mb_fn'])\n",
    "mb_fn_df['RGIId'] = mb_rgiids\n",
    "mb_fn_df['mb_fullfn'] = mb_fns\n",
    "\n",
    "# Find glaciers that are debris-covered\n",
    "mb_dc_rgiid = [value for value in list(mb_fn_df.RGIId.values) if value in list(main_glac_rgi_subset.RGIId.values)]\n",
    "mb_fn_df_dc = mb_fn_df[mb_fn_df['RGIId'].isin(mb_dc_rgiid)]\n",
    "mb_fn_df_dc = mb_fn_df_dc.sort_values('RGIId')\n",
    "\n",
    "print('Debris-covered glaciers:', mb_fn_df_dc.shape[0], '\\n\\n')\n",
    "\n",
    "mb_fn_dict = dict(zip(mb_fn_df_dc['RGIId'].values, mb_fn_df_dc['mb_fullfn'].values))\n",
    "\n",
    "main_glac_rgi_subset['mb_fullfn'] = main_glac_rgi_subset.RGIId.map(mb_fn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique lat/lons: 457 \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O1Index</th>\n",
       "      <th>RGIId</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>Zmax</th>\n",
       "      <th>Zmed</th>\n",
       "      <th>...</th>\n",
       "      <th>TermType</th>\n",
       "      <th>Surging</th>\n",
       "      <th>RefDate</th>\n",
       "      <th>glacno</th>\n",
       "      <th>rgino_str</th>\n",
       "      <th>RGIId_float</th>\n",
       "      <th>CenLon_360</th>\n",
       "      <th>latlon_nearidx</th>\n",
       "      <th>latlon_unique_no</th>\n",
       "      <th>mb_fullfn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>RGI60-01.00006</td>\n",
       "      <td>-146.244000</td>\n",
       "      <td>63.571000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.470</td>\n",
       "      <td>1201</td>\n",
       "      <td>3547</td>\n",
       "      <td>1740</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20090703</td>\n",
       "      <td>6</td>\n",
       "      <td>01.00006</td>\n",
       "      <td>1.00006</td>\n",
       "      <td>213.756000</td>\n",
       "      <td>(106, 855)</td>\n",
       "      <td>11</td>\n",
       "      <td>/Users/davidrounce/Documents/Dave_Rounce/Debri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>RGI60-01.00013</td>\n",
       "      <td>-146.684082</td>\n",
       "      <td>63.499329</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>209.630</td>\n",
       "      <td>823</td>\n",
       "      <td>4003</td>\n",
       "      <td>1848</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20090703</td>\n",
       "      <td>13</td>\n",
       "      <td>01.00013</td>\n",
       "      <td>1.00013</td>\n",
       "      <td>213.315918</td>\n",
       "      <td>(106, 853)</td>\n",
       "      <td>9</td>\n",
       "      <td>/Users/davidrounce/Documents/Dave_Rounce/Debri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>RGI60-01.00027</td>\n",
       "      <td>-146.262817</td>\n",
       "      <td>63.535065</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13.290</td>\n",
       "      <td>1073</td>\n",
       "      <td>2985</td>\n",
       "      <td>1742</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20090703</td>\n",
       "      <td>27</td>\n",
       "      <td>01.00027</td>\n",
       "      <td>1.00027</td>\n",
       "      <td>213.737183</td>\n",
       "      <td>(106, 855)</td>\n",
       "      <td>11</td>\n",
       "      <td>/Users/davidrounce/Documents/Dave_Rounce/Debri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>RGI60-01.00033</td>\n",
       "      <td>-146.872000</td>\n",
       "      <td>63.680000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.604</td>\n",
       "      <td>1109</td>\n",
       "      <td>3160</td>\n",
       "      <td>1718</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20090703</td>\n",
       "      <td>33</td>\n",
       "      <td>01.00033</td>\n",
       "      <td>1.00033</td>\n",
       "      <td>213.128000</td>\n",
       "      <td>(105, 853)</td>\n",
       "      <td>4</td>\n",
       "      <td>/Users/davidrounce/Documents/Dave_Rounce/Debri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>RGI60-01.00035</td>\n",
       "      <td>-147.442000</td>\n",
       "      <td>63.648000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36.349</td>\n",
       "      <td>1274</td>\n",
       "      <td>2928</td>\n",
       "      <td>1913</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20090703</td>\n",
       "      <td>35</td>\n",
       "      <td>01.00035</td>\n",
       "      <td>1.00035</td>\n",
       "      <td>212.558000</td>\n",
       "      <td>(105, 850)</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/davidrounce/Documents/Dave_Rounce/Debri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>26856</td>\n",
       "      <td>RGI60-01.26861</td>\n",
       "      <td>-134.732000</td>\n",
       "      <td>59.454000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.545</td>\n",
       "      <td>1404</td>\n",
       "      <td>1879</td>\n",
       "      <td>1506</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20050811</td>\n",
       "      <td>26861</td>\n",
       "      <td>01.26861</td>\n",
       "      <td>1.26861</td>\n",
       "      <td>225.268000</td>\n",
       "      <td>(122, 901)</td>\n",
       "      <td>293</td>\n",
       "      <td>/Users/davidrounce/Documents/Dave_Rounce/Debri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>27096</td>\n",
       "      <td>RGI60-01.27101</td>\n",
       "      <td>-143.473236</td>\n",
       "      <td>60.709583</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>80.219</td>\n",
       "      <td>492</td>\n",
       "      <td>3182</td>\n",
       "      <td>1403</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20100919</td>\n",
       "      <td>27101</td>\n",
       "      <td>01.27101</td>\n",
       "      <td>1.27101</td>\n",
       "      <td>216.526764</td>\n",
       "      <td>(117, 866)</td>\n",
       "      <td>182</td>\n",
       "      <td>/Users/davidrounce/Documents/Dave_Rounce/Debri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>27098</td>\n",
       "      <td>RGI60-01.27103</td>\n",
       "      <td>-134.086000</td>\n",
       "      <td>58.943000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>86.656</td>\n",
       "      <td>873</td>\n",
       "      <td>2236</td>\n",
       "      <td>1768</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20050811</td>\n",
       "      <td>27103</td>\n",
       "      <td>01.27103</td>\n",
       "      <td>1.27103</td>\n",
       "      <td>225.914000</td>\n",
       "      <td>(124, 904)</td>\n",
       "      <td>326</td>\n",
       "      <td>/Users/davidrounce/Documents/Dave_Rounce/Debri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>27100</td>\n",
       "      <td>RGI60-01.27105</td>\n",
       "      <td>-132.392000</td>\n",
       "      <td>57.164000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>131.574</td>\n",
       "      <td>507</td>\n",
       "      <td>2837</td>\n",
       "      <td>1219</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20040810</td>\n",
       "      <td>27105</td>\n",
       "      <td>01.27105</td>\n",
       "      <td>1.27105</td>\n",
       "      <td>227.608000</td>\n",
       "      <td>(131, 910)</td>\n",
       "      <td>397</td>\n",
       "      <td>/Users/davidrounce/Documents/Dave_Rounce/Debri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>27103</td>\n",
       "      <td>RGI60-01.27108</td>\n",
       "      <td>-143.726807</td>\n",
       "      <td>60.231728</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>534.228</td>\n",
       "      <td>3</td>\n",
       "      <td>3238</td>\n",
       "      <td>403</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20100910</td>\n",
       "      <td>27108</td>\n",
       "      <td>01.27108</td>\n",
       "      <td>1.27108</td>\n",
       "      <td>216.273193</td>\n",
       "      <td>(119, 865)</td>\n",
       "      <td>222</td>\n",
       "      <td>/Users/davidrounce/Documents/Dave_Rounce/Debri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1109 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      O1Index           RGIId      CenLon     CenLat  O1Region  O2Region  \\\n",
       "0           5  RGI60-01.00006 -146.244000  63.571000         1         2   \n",
       "1          12  RGI60-01.00013 -146.684082  63.499329         1         2   \n",
       "2          26  RGI60-01.00027 -146.262817  63.535065         1         2   \n",
       "3          32  RGI60-01.00033 -146.872000  63.680000         1         2   \n",
       "4          34  RGI60-01.00035 -147.442000  63.648000         1         2   \n",
       "...       ...             ...         ...        ...       ...       ...   \n",
       "1104    26856  RGI60-01.26861 -134.732000  59.454000         1         6   \n",
       "1105    27096  RGI60-01.27101 -143.473236  60.709583         1         5   \n",
       "1106    27098  RGI60-01.27103 -134.086000  58.943000         1         6   \n",
       "1107    27100  RGI60-01.27105 -132.392000  57.164000         1         6   \n",
       "1108    27103  RGI60-01.27108 -143.726807  60.231728         1         5   \n",
       "\n",
       "         Area  Zmin  Zmax  Zmed  ...  TermType  Surging   RefDate  glacno  \\\n",
       "0      10.470  1201  3547  1740  ...         0        9  20090703       6   \n",
       "1     209.630   823  4003  1848  ...         0        3  20090703      13   \n",
       "2      13.290  1073  2985  1742  ...         0        3  20090703      27   \n",
       "3       4.604  1109  3160  1718  ...         0        9  20090703      33   \n",
       "4      36.349  1274  2928  1913  ...         0        9  20090703      35   \n",
       "...       ...   ...   ...   ...  ...       ...      ...       ...     ...   \n",
       "1104    3.545  1404  1879  1506  ...         0        9  20050811   26861   \n",
       "1105   80.219   492  3182  1403  ...         0        9  20100919   27101   \n",
       "1106   86.656   873  2236  1768  ...         0        9  20050811   27103   \n",
       "1107  131.574   507  2837  1219  ...         0        9  20040810   27105   \n",
       "1108  534.228     3  3238   403  ...         0        9  20100910   27108   \n",
       "\n",
       "      rgino_str  RGIId_float  CenLon_360  latlon_nearidx latlon_unique_no  \\\n",
       "0      01.00006      1.00006  213.756000      (106, 855)               11   \n",
       "1      01.00013      1.00013  213.315918      (106, 853)                9   \n",
       "2      01.00027      1.00027  213.737183      (106, 855)               11   \n",
       "3      01.00033      1.00033  213.128000      (105, 853)                4   \n",
       "4      01.00035      1.00035  212.558000      (105, 850)                1   \n",
       "...         ...          ...         ...             ...              ...   \n",
       "1104   01.26861      1.26861  225.268000      (122, 901)              293   \n",
       "1105   01.27101      1.27101  216.526764      (117, 866)              182   \n",
       "1106   01.27103      1.27103  225.914000      (124, 904)              326   \n",
       "1107   01.27105      1.27105  227.608000      (131, 910)              397   \n",
       "1108   01.27108      1.27108  216.273193      (119, 865)              222   \n",
       "\n",
       "                                              mb_fullfn  \n",
       "0     /Users/davidrounce/Documents/Dave_Rounce/Debri...  \n",
       "1     /Users/davidrounce/Documents/Dave_Rounce/Debri...  \n",
       "2     /Users/davidrounce/Documents/Dave_Rounce/Debri...  \n",
       "3     /Users/davidrounce/Documents/Dave_Rounce/Debri...  \n",
       "4     /Users/davidrounce/Documents/Dave_Rounce/Debri...  \n",
       "...                                                 ...  \n",
       "1104  /Users/davidrounce/Documents/Dave_Rounce/Debri...  \n",
       "1105  /Users/davidrounce/Documents/Dave_Rounce/Debri...  \n",
       "1106  /Users/davidrounce/Documents/Dave_Rounce/Debri...  \n",
       "1107  /Users/davidrounce/Documents/Dave_Rounce/Debri...  \n",
       "1108  /Users/davidrounce/Documents/Dave_Rounce/Debri...  \n",
       "\n",
       "[1109 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== SELECT GLACIERS WITH DATA ====\n",
    "main_glac_rgi_wobs = main_glac_rgi_subset.dropna(subset=['mb_fullfn']).copy()\n",
    "# print('subset wdata length:', main_glac_rgi_wobs.shape)\n",
    "main_glac_rgi_wobs.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Update the latlon unique pickle files\n",
    "latlon_nearidx_unique = sorted(list(set(main_glac_rgi_wobs['latlon_nearidx'].values)))\n",
    "latlon_unique_dict = dict(zip(latlon_nearidx_unique,np.arange(0,len(latlon_nearidx_unique))))\n",
    "latlon_unique_dict_reversed = dict(zip(np.arange(0,len(latlon_nearidx_unique)),latlon_nearidx_unique))\n",
    "main_glac_rgi_wobs['latlon_unique_no'] = main_glac_rgi_wobs['latlon_nearidx'].map(latlon_unique_dict)\n",
    "\n",
    "print('unique lat/lons:', len(np.unique(main_glac_rgi_wobs['latlon_unique_no'])), '\\n\\n')\n",
    "\n",
    "lat_list = np.array([ds.latitude[x[0]].values for x in latlon_nearidx_unique])\n",
    "lon_list = np.array([ds.longitude[x[1]].values for x in latlon_nearidx_unique])\n",
    "latlon_list = list(tuple(zip(list(lat_list), list(lon_list))))\n",
    "\n",
    "# Pickle unique lat/lons that will be used for melt model\n",
    "with open(debris_prms.latlon_unique_fp + debris_prms.latlon_unique_dict[debris_prms.roi], 'wb') as f:\n",
    "    pickle.dump(latlon_list, f)\n",
    "    \n",
    "main_glac_rgi_wobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique lat/lons updated: 396\n"
     ]
    }
   ],
   "source": [
    "# ===== DEBRIS ELEVATION STATS ====================================================================================\n",
    "# CALCULATE DEBRIS ELEVATION STATS FOR GLACIERS WITH DATA FOR EACH UNIQUE LAT/LON\n",
    "elev_stats_latlon_dict = {}\n",
    "latlon_list_updated = []\n",
    "rgiid_4cal = []\n",
    "for nlatlon, latlon_unique in enumerate(np.unique(main_glac_rgi_wobs.latlon_unique_no)):\n",
    "# for nlatlon, latlon_unique in enumerate([np.unique(main_glac_rgi_wobs.latlon_unique_no)[0]]):\n",
    "\n",
    "    main_glac_rgi_subset = main_glac_rgi_wobs[main_glac_rgi_wobs['latlon_unique_no'] == latlon_unique]\n",
    "\n",
    "    # Debris elevation stats should be done by lat/lon\n",
    "    df_all = None\n",
    "    elev_list_all = []\n",
    "    df_idx_count = 0\n",
    "    count_width_passes = 0\n",
    "    for nglac, glac_fullfn in enumerate(main_glac_rgi_subset.mb_fullfn.values):\n",
    "#     for nglac, glac_fn in enumerate([main_glac_rgi_subset.mb_fullfn.values[0]]):\n",
    "\n",
    "        glac_str_noleadzero = glac_fullfn.split('/')[-1].split('_')[0]\n",
    "        rgiid = 'RGI60-' + glac_str_noleadzero.split('.')[0].zfill(2) + '.' + glac_str_noleadzero.split('.')[1]\n",
    "\n",
    "        df_raw = pd.read_csv(glac_fullfn)\n",
    "        df = df_raw.dropna(subset=['mb_bin_mean_mwea'])\n",
    "        df_debris = df[(df['vm_med'] < debris_prms.vel_threshold) & \n",
    "                       (df['dc_bin_area_perc'] > debris_prms.debrisperc_threshold)\n",
    "                       & (df['dc_bin_count_valid'] > 0)]\n",
    "\n",
    "        df_idx = df_debris.index.values\n",
    "        df_idx_count += len(df_idx)\n",
    "        \n",
    "        # Widths\n",
    "        widths_fp = debris_prms.oggm_fp + 'widths/' + 'RGI60-' + rgiid.split('-')[1].split('.')[0] + '/'\n",
    "        widths_fn = rgiid + '_widths_m.csv'\n",
    "        try:\n",
    "            widths_df = pd.read_csv(widths_fp + widths_fn)\n",
    "            h = widths_df['elev'].values\n",
    "            widths_m = widths_df['width_m'].values\n",
    "        except:\n",
    "            widths_df = None\n",
    "\n",
    "        if len(df_idx) > 0 and widths_df is not None:\n",
    "            # only work with terminus\n",
    "            df_idx_dif = list(df_idx[1:] - df_idx[:-1])\n",
    "            if np.sum(df_idx_dif) == len(df_idx)-1:\n",
    "                df_idx_nojump = df_idx\n",
    "            else:\n",
    "                idx_jumpinbins = df_idx_dif.index(next(filter(lambda x: x>1, df_idx_dif)))\n",
    "                df_idx_nojump = df_idx[0:idx_jumpinbins+1]\n",
    "\n",
    "            df_debris_nojump = df_debris.loc[df_idx_nojump,:]\n",
    "            df_debris_nojump.reset_index(inplace=True, drop=True)\n",
    "            \n",
    "            # Median width to ensure terminus velocities can be estimated\n",
    "            width_median = np.median(widths_m[np.where(h < df_debris_nojump['bin_center_elev_m'].max())[0]])\n",
    "            \n",
    "            if width_median > debris_prms.width_min_dict[debris_prms.roi]:\n",
    "                for nelev, elev in enumerate(list(df_debris_nojump['bin_center_elev_m'].values)):\n",
    "                    elev_list_single = list(np.repeat(elev, df_debris_nojump.loc[nelev,'dc_bin_count_valid']))\n",
    "                    elev_list_all.extend(elev_list_single)\n",
    "                count_width_passes += 1\n",
    "                \n",
    "            rgiid_4cal.append(rgiid.split('-')[1])\n",
    "        \n",
    "    if df_idx_count > 0 and count_width_passes > 0:\n",
    "        dc_zmean = np.mean(elev_list_all)\n",
    "        dc_zstd = np.std(elev_list_all)\n",
    "        dc_zmed = malib.fast_median(elev_list_all)\n",
    "        dc_zmad = malib.mad(elev_list_all)\n",
    "\n",
    "        lat_deg = float(ds.latitude[latlon_unique_dict_reversed[latlon_unique][0]].values)\n",
    "        lon_deg = float(ds.longitude[latlon_unique_dict_reversed[latlon_unique][1]].values)\n",
    "        elev_stats_latlon_dict[lat_deg,lon_deg] = [dc_zmean, dc_zstd, dc_zmed, dc_zmad]\n",
    "        latlon_list_updated.append((lat_deg, lon_deg))\n",
    "        \n",
    "print('unique lat/lons updated:', len(latlon_list_updated))\n",
    "# Update pickle of unique lat/lons that will be used for melt model\n",
    "with open(debris_prms.latlon_unique_fp + debris_prms.latlon_unique_dict[debris_prms.roi], 'wb') as f:\n",
    "    pickle.dump(latlon_list_updated, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010 glaciers in region 1 are included in this model run: ['00006', '00013', '00027', '00033', '00037', '00038', '00040', '00041', '00042', '00044', '00045', '00046', '00140', '00148', '00187', '00242', '00312', '00348', '00351', '00399', '00409', '00426', '00434', '00436', '00537', '00544', '00556', '00557', '00558', '00560', '00561', '00565', '00566', '00569', '00570', '00571', '00572', '00574', '00576', '00578', '00579', '00581', '00582', '00584', '00600', '00660', '00670', '00675', '00732', '00739'] and more\n",
      "This study is focusing on 1010 glaciers in region [1]\n",
      "\n",
      "DC glaciers (used for cal): 1010 DC Area (used for cal, km2): 5757.058539\n"
     ]
    }
   ],
   "source": [
    "# Statistics of data coverage\n",
    "rgiid_4cal = sorted(rgiid_4cal)\n",
    "main_glac_rgi_4cal = debris_prms.selectglaciersrgitable(rgiid_4cal)\n",
    "dc_area_dict = dict(zip(dc_shp.RGIId.values, dc_shp.DC_Area_v2.values))\n",
    "main_glac_rgi_4cal['DC_Area_v2'] = main_glac_rgi_4cal.RGIId.map(dc_area_dict)\n",
    "print('\\nDC glaciers (used for cal):', main_glac_rgi_4cal.shape[0], \n",
    "      'DC Area (used for cal, km2):', main_glac_rgi_4cal.DC_Area_v2.sum() / 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ADD DEBRIS ELEVATION STATS TO MET DATA ======\n",
    "overwrite_dc_stats = True\n",
    "for nlatlon, latlon in enumerate(latlon_list_updated):\n",
    "# for nlatlon, latlon in enumerate([latlon_list_updated[0]]):\n",
    "    \n",
    "    lat_deg = latlon[0]\n",
    "    lon_deg = latlon[1]\n",
    "    \n",
    "    print(nlatlon, lat_deg, lon_deg)\n",
    "    \n",
    "    if lat_deg < 0:\n",
    "        lat_str = 'S-'\n",
    "    else:\n",
    "        lat_str = 'N-' \n",
    "\n",
    "    # ===== Meteorological data =====\n",
    "    metdata_fn = debris_prms.metdata_fn_sample.replace(\n",
    "        'XXXX', str(int(np.abs(lat_deg)*100)) + lat_str + str(int(lon_deg*100)) + 'E-')\n",
    "    \n",
    "    ds = xr.open_dataset(debris_prms.metdata_fp + metdata_fn)    \n",
    "#     print('  ', ds.dc_zmean.values, elev_stats_latlon_dict[latlon][0])\n",
    "    if 'dc_zmean' not in list(ds.keys()) or overwrite_dc_stats:\n",
    "        # Add stats\n",
    "        ds['dc_zmean'] = elev_stats_latlon_dict[latlon][0]\n",
    "        ds['dc_zmean'].attrs = {'units':'m a.s.l.', 'long_name':'Mean debris cover elevation', \n",
    "                                'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "        ds['dc_zstd'] = elev_stats_latlon_dict[latlon][1]\n",
    "        ds['dc_zstd'].attrs = {'units':'m a.s.l.', 'long_name':'Standard deviation of debris cover elevation', \n",
    "                               'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "        ds['dc_zmed'] = elev_stats_latlon_dict[latlon][2]\n",
    "        ds['dc_zmed'].attrs = {'units':'m a.s.l.', 'long_name':'Median debris cover elevation', \n",
    "                               'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "        ds['dc_zmad'] = elev_stats_latlon_dict[latlon][3]\n",
    "        ds['dc_zmad'].attrs = {'units':'m a.s.l.', 'long_name':'Median absolute deviation of debris cover elevation', \n",
    "                               'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "\n",
    "        try:\n",
    "            ds.close()\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        # Export updated dataset\n",
    "        ds.to_netcdf(debris_prms.metdata_fp + metdata_fn, mode='a')\n",
    "    else:\n",
    "        print(lat_deg, lon_deg, 'exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset wdata length: (1109, 35)\n",
      "1109\n",
      "1109\n",
      "unique lat/lons: 448 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # ===== SELECT GLACIERS WITH DATA ====\n",
    "# dc_shp_subset_wdata = dc_shp_subset.dropna(subset=['mb_fullfn']).copy()\n",
    "# print('subset wdata length:', dc_shp_subset_wdata.shape)\n",
    "# dc_shp_subset_wdata.reset_index(inplace=True, drop=True)\n",
    "# ds = xr.open_dataset(debris_prms.metdata_fp + '../' + debris_prms.metdata_elev_fn)\n",
    "# # #  argmin() finds the minimum distance between the glacier lat/lon and the GCM pixel\n",
    "# # lat_nearidx = (np.abs(dc_shp_subset_wdata['CenLat'].values[:,np.newaxis] - \n",
    "# #                       ds['latitude'][:].values).argmin(axis=1))\n",
    "# # lon_nearidx = (np.abs(dc_shp_subset_wdata['CenLon_360'].values[:,np.newaxis] - \n",
    "# #                       ds['longitude'][:].values).argmin(axis=1))\n",
    "\n",
    "\n",
    "# # ===== CORRECT FOR THE CENTER LONGITUDE BEING 360\n",
    "# dc_shp_subset_wdata['CenLon_360'] = dc_shp_subset_wdata['CenLon']\n",
    "# dc_shp_subset_wdata.loc[dc_shp_subset_wdata['CenLon_360'] < 0, 'CenLon_360'] = (\n",
    "#     360 + dc_shp_subset_wdata.loc[dc_shp_subset_wdata['CenLon_360'] < 0, 'CenLon_360'])\n",
    "# lat_nearidx = (np.abs(dc_shp_subset_wdata['CenLat'].values[:,np.newaxis] - \n",
    "#                       ds['latitude'][:].values).argmin(axis=1))\n",
    "# lon_nearidx = (np.abs(dc_shp_subset_wdata['CenLon_360'].values[:,np.newaxis] - \n",
    "#                       ds['longitude'][:].values).argmin(axis=1))\n",
    "# # =====\n",
    "\n",
    "# lat_nearidx_v3 = lat_nearidx.copy()\n",
    "\n",
    "\n",
    "# latlon_nearidx = list(zip(lat_nearidx, lon_nearidx))\n",
    "# latlon_nearidx_unique = sorted(list(set(latlon_nearidx)))\n",
    "# dc_shp_subset_wdata['latlon_nearidx'] = latlon_nearidx\n",
    "# latlon_unique_dict = dict(zip(latlon_nearidx_unique,np.arange(0,len(latlon_nearidx_unique))))\n",
    "# latlon_unique_dict_reversed = dict(zip(np.arange(0,len(latlon_nearidx_unique)),latlon_nearidx_unique))\n",
    "# dc_shp_subset_wdata['latlon_unique_no'] = dc_shp_subset_wdata['latlon_nearidx'].map(latlon_unique_dict)\n",
    "\n",
    "# latlon_nearidx_v3 = latlon_nearidx.copy()\n",
    "\n",
    "# rgiid_dc_v3 = list(dc_shp_subset_wdata.RGIId.values)\n",
    "# print(len(rgiid_dc_v3))\n",
    "\n",
    "# latlon_unique_v3 = list(dc_shp_subset_wdata['latlon_unique_no'].values)\n",
    "# print(len(latlon_unique_v3))\n",
    "\n",
    "# print('unique lat/lons:', len(np.unique(dc_shp_subset_wdata['latlon_unique_no'])), '\\n\\n')\n",
    "# # print(dc_shp_subset_wdata.loc[0:5,['RGIId', 'CenLat', 'CenLon', 'larsen_fn', 'braun_fn', 'latlon_unique_no']])\n",
    "\n",
    "# lat_list = np.array([ds.latitude[x[0]].values for x in latlon_nearidx_unique])\n",
    "# lon_list = np.array([ds.longitude[x[1]].values for x in latlon_nearidx_unique])\n",
    "# latlon_list = list(tuple(zip(list(lat_list), list(lon_list))))\n",
    "\n",
    "# # Pickle unique lat/lons that will be used for melt model\n",
    "# with open(debris_prms.latlon_unique_fp + debris_prms.latlon_unique_dict[debris_prms.roi], 'wb') as f:\n",
    "#     pickle.dump(latlon_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109 glaciers in region 1 are included in this model run: ['00006', '00013', '00027', '00033', '00035', '00037', '00038', '00040', '00041', '00042', '00044', '00045', '00046', '00140', '00148', '00187', '00242', '00312', '00336', '00348', '00351', '00399', '00409', '00426', '00434', '00436', '00537', '00544', '00556', '00557', '00558', '00560', '00561', '00565', '00566', '00569', '00570', '00571', '00572', '00574', '00576', '00578', '00579', '00581', '00582', '00584', '00600', '00660', '00670', '00675'] and more\n",
      "This study is focusing on 1109 glaciers in region [1]\n"
     ]
    }
   ],
   "source": [
    "# # ===== Load Glaciers =====\n",
    "# rgiid_wobs = [x.split('-')[1] for x in dc_shp_subset_wdata['RGIId'].values]\n",
    "# main_glac_rgi_wobs = debris_prms.selectglaciersrgitable(rgiid_wobs)\n",
    "# # add filenames\n",
    "# main_glac_rgi_wobs['mb_fn'] = np.nan\n",
    "# main_glac_rgi_wobs['mb_fn'] = main_glac_rgi_wobs.RGIId.map(mb_fn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109\n",
      "1109\n",
      "unique lat/lons: 457 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== DEBRIS ELEVATION STATS ====================================================================================\n",
    "# # Glaciers with data\n",
    "# glac_wobs_fns = []\n",
    "# rgiid_wobs = []\n",
    "# for i in os.listdir(debris_prms.mb_binned_fp):\n",
    "# #     if i.endswith('_mb_bins_wdc_emvel_offset.csv'):\n",
    "#     if i.endswith('_mb_bins.csv'):\n",
    "#         rgiid_reg = int(i.split('.')[0])\n",
    "#         if int(rgiid_reg) in debris_prms.roi_rgidict[debris_prms.roi]:\n",
    "#             glac_wobs_fns.append(i)\n",
    "#             if rgiid_reg < 10:\n",
    "#                 rgiid_wobs.append(i[0:7])\n",
    "#             else:\n",
    "#                 rgiid_wobs.append(i[0:8])\n",
    "        \n",
    "# glac_wobs_fns = sorted(glac_wobs_fns)\n",
    "# rgiid_wobs = sorted(rgiid_wobs)\n",
    "\n",
    "# print(len(rgiid_wobs))\n",
    "\n",
    "# ===== SELECT GLACIERS WITH DATA =====\n",
    "# main_glac_rgi_wobs = debris_prms.selectglaciersrgitable(rgiid_wobs)\n",
    "# main_glac_rgi_wobs['mb_bin_fn'] = glac_wobs_fns \n",
    "main_glac_rgi_wobs['CenLon_360'] = main_glac_rgi_wobs['CenLon']\n",
    "main_glac_rgi_wobs.loc[main_glac_rgi_wobs['CenLon_360'] < 0, 'CenLon_360'] = (\n",
    "    360 + main_glac_rgi_wobs.loc[main_glac_rgi_wobs['CenLon_360'] < 0, 'CenLon_360'])\n",
    "ds = xr.open_dataset(debris_prms.metdata_fp + '../' + debris_prms.metdata_elev_fn)\n",
    "#  argmin() finds the minimum distance between the glacier lat/lon and the GCM pixel\n",
    "lat_nearidx = (np.abs(main_glac_rgi_wobs['CenLat'].values[:,np.newaxis] - \n",
    "                      ds['latitude'][:].values).argmin(axis=1))\n",
    "lon_nearidx = (np.abs(main_glac_rgi_wobs['CenLon_360'].values[:,np.newaxis] - \n",
    "                      ds['longitude'][:].values).argmin(axis=1))\n",
    "latlon_nearidx = list(zip(lat_nearidx, lon_nearidx))\n",
    "latlon_nearidx_unique = sorted(list(set(latlon_nearidx)))\n",
    "main_glac_rgi_wobs['latlon_nearidx'] = latlon_nearidx\n",
    "latlon_unique_dict = dict(zip(latlon_nearidx_unique,np.arange(0,len(latlon_nearidx_unique))))\n",
    "latlon_unique_dict_reversed = dict(zip(np.arange(0,len(latlon_nearidx_unique)),latlon_nearidx_unique))\n",
    "main_glac_rgi_wobs['latlon_unique_no'] = main_glac_rgi_wobs['latlon_nearidx'].map(latlon_unique_dict)\n",
    "\n",
    "lat_nearidx_v4 = lat_nearidx.copy()\n",
    "\n",
    "latlon_nearidx_v4 = latlon_nearidx.copy()\n",
    "\n",
    "rgiid_dc_v4 = list(main_glac_rgi_wobs.RGIId.values)\n",
    "print(len(rgiid_dc_v4))\n",
    "\n",
    "latlon_unique_v4 = list(main_glac_rgi_wobs['latlon_unique_no'].values)\n",
    "print(len(latlon_unique_v4))\n",
    "\n",
    "print('unique lat/lons:', len(np.unique(main_glac_rgi_wobs['latlon_unique_no'])), '\\n\\n')\n",
    "# print(dc_shp_subset_wdata.loc[0:5,['RGIId', 'CenLat', 'CenLon', 'larsen_fn', 'braun_fn', 'latlon_unique_no']])\n",
    "\n",
    "# lat_list = np.array([ds.latitude[x[0]].values for x in latlon_nearidx_unique])\n",
    "# lon_list = np.array([ds.longitude[x[1]].values for x in latlon_nearidx_unique])\n",
    "# latlon_list = list(tuple(zip(list(lat_list), list(lon_list))))\n",
    "\n",
    "# # ===== CALCULATE DEBRIS ELEVATION STATS FOR GLACIERS WITH DATA FOR EACH UNIQUE LAT/LON ======\n",
    "# elev_stats_latlon_dict = {}\n",
    "# latlon_list_updated = []\n",
    "# rgiid_4cal = []\n",
    "# for nlatlon, latlon_unique in enumerate(np.unique(main_glac_rgi_wobs.latlon_unique_no)):\n",
    "# # for nlatlon, latlon_unique in enumerate([np.unique(main_glac_rgi_wobs.latlon_unique_no)[3]]):\n",
    "\n",
    "#     main_glac_rgi_subset = main_glac_rgi_wobs[main_glac_rgi_wobs['latlon_unique_no'] == latlon_unique]\n",
    "\n",
    "#     # Debris elevation stats should be done by lat/lon\n",
    "#     df_all = None\n",
    "#     elev_list_all = []\n",
    "#     df_idx_count = 0\n",
    "#     count_width_passes = 0\n",
    "#     for nglac, glac_fn in enumerate(main_glac_rgi_subset.mb_bin_fn.values):\n",
    "# #     for nglac, glac_fn in enumerate([main_glac_rgi_subset.mb_bin_fn.values[3]]):\n",
    "        \n",
    "# #         print(glac_fn.split('_')[0])\n",
    "\n",
    "#         df_raw = pd.read_csv(debris_prms.mb_binned_fp + glac_fn)\n",
    "#         df = df_raw.dropna(subset=['mb_bin_mean_mwea'])\n",
    "#         df_debris = df[(df['vm_med'] < debris_prms.vel_threshold) & \n",
    "#                        (df['dc_bin_area_perc'] > debris_prms.debrisperc_threshold)\n",
    "#                        & (df['dc_bin_count_valid'] > 0)]\n",
    "\n",
    "#         df_idx = df_debris.index.values\n",
    "#         df_idx_count += len(df_idx)\n",
    "        \n",
    "#         # Widths\n",
    "#         rgiid = 'RGI60-' + glac_fn.split('_')[0]\n",
    "#         widths_fp = debris_prms.oggm_fp + 'widths/' + 'RGI60-' + rgiid.split('-')[1].split('.')[0] + '/'\n",
    "#         widths_fn = rgiid + '_widths_m.csv'\n",
    "#         try:\n",
    "#             widths_df = pd.read_csv(widths_fp + widths_fn)\n",
    "#             h = widths_df['elev'].values\n",
    "#             widths_m = widths_df['width_m'].values\n",
    "#         except:\n",
    "#             widths_df = None\n",
    "\n",
    "#         if len(df_idx) > 0 and widths_df is not None:\n",
    "#             # only work with terminus\n",
    "#             df_idx_dif = list(df_idx[1:] - df_idx[:-1])\n",
    "#             if np.sum(df_idx_dif) == len(df_idx)-1:\n",
    "#                 df_idx_nojump = df_idx\n",
    "#             else:\n",
    "#                 idx_jumpinbins = df_idx_dif.index(next(filter(lambda x: x>1, df_idx_dif)))\n",
    "#                 df_idx_nojump = df_idx[0:idx_jumpinbins+1]\n",
    "\n",
    "#             df_debris_nojump = df_debris.loc[df_idx_nojump,:]\n",
    "#             df_debris_nojump.reset_index(inplace=True, drop=True)\n",
    "            \n",
    "#             # Median width to ensure terminus velocities can be estimated\n",
    "#             width_median = np.median(widths_m[np.where(h < df_debris_nojump['bin_center_elev_m'].max())[0]])\n",
    "            \n",
    "#             if width_median > debris_prms.width_min_dict[debris_prms.roi]:\n",
    "#                 for nelev, elev in enumerate(list(df_debris_nojump['bin_center_elev_m'].values)):\n",
    "#                     elev_list_single = list(np.repeat(elev, df_debris_nojump.loc[nelev,'dc_bin_count_valid']))\n",
    "#                     elev_list_all.extend(elev_list_single)\n",
    "#                 count_width_passes += 1\n",
    "                \n",
    "#             rgiid_4cal.append(glac_fn.split('_')[0])\n",
    "        \n",
    "#     if df_idx_count > 0 and count_width_passes > 0:\n",
    "#         dc_zmean = np.mean(elev_list_all)\n",
    "#         dc_zstd = np.std(elev_list_all)\n",
    "#         dc_zmed = malib.fast_median(elev_list_all)\n",
    "#         dc_zmad = malib.mad(elev_list_all)\n",
    "\n",
    "#         lat_deg = float(ds.latitude[latlon_unique_dict_reversed[latlon_unique][0]].values)\n",
    "#         lon_deg = float(ds.longitude[latlon_unique_dict_reversed[latlon_unique][1]].values)\n",
    "#         elev_stats_latlon_dict[lat_deg,lon_deg] = [dc_zmean, dc_zstd, dc_zmed, dc_zmad]\n",
    "#         latlon_list_updated.append((lat_deg, lon_deg))\n",
    "        \n",
    "# print('unique lat/lons updated:', len(latlon_list_updated))\n",
    "# # Update pickle of unique lat/lons that will be used for melt model\n",
    "# with open(debris_prms.latlon_unique_fp + debris_prms.latlon_unique_dict[debris_prms.roi], 'wb') as f:\n",
    "#     pickle.dump(latlon_list_updated, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.19016111999999907 0.26952440000000166 0.000370968452660213 -0.4301488159999849 0.6682286409999847 0.0003595859747526641\n",
      "Index(['RGIId', 'GLIMSId', 'BgnDate', 'EndDate', 'CenLon', 'CenLat',\n",
      "       'O1Region', 'O2Region', 'Area', 'Zmin', 'Zmax', 'Zmed', 'Slope',\n",
      "       'Aspect', 'Lmax', 'Status', 'Connect', 'Form', 'TermType', 'Surging',\n",
      "       'Linkages', 'Name', 'DC_Area', 'DC_BgnDate', 'DC_EndDate', 'DC_CTSmean',\n",
      "       'DC_Area_%', 'area_singl', 'DC_Area_v2', 'DC_Area__1', 'geometry',\n",
      "       'CenLon_360', 'latlon_nearidx', 'latlon_unique_no', 'mb_fullfn'],\n",
      "      dtype='object')\n",
      "Index(['O1Index', 'RGIId', 'CenLon', 'CenLat', 'O1Region', 'O2Region', 'Area',\n",
      "       'Zmin', 'Zmax', 'Zmed', 'Slope', 'Aspect', 'Lmax', 'Form', 'TermType',\n",
      "       'Surging', 'RefDate', 'glacno', 'rgino_str', 'RGIId_float', 'mb_fn',\n",
      "       'CenLon_360', 'latlon_nearidx', 'latlon_unique_no'],\n",
      "      dtype='object')\n",
      "-143.726806641 -143.058578\n"
     ]
    }
   ],
   "source": [
    "A = dc_shp_subset_wdata['CenLat'].values - main_glac_rgi_wobs['CenLat'].values\n",
    "B = dc_shp_subset_wdata['CenLon'].values - main_glac_rgi_wobs['CenLon'].values\n",
    "print(A.min(), A.max(), A.mean(), B.min(), B.max(), B.mean())\n",
    "\n",
    "np.where(A == A.max())\n",
    "\n",
    "print(dc_shp_subset_wdata.columns)\n",
    "print(main_glac_rgi_wobs.columns)\n",
    "\n",
    "vn = 'CenLon'\n",
    "print(main_glac_rgi_wobs.loc[1108,vn], dc_shp_subset_wdata.loc[1108,vn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109 1109 True\n",
      "1109 1109 False\n",
      "[448, 449, 450, 451, 452, 453, 454, 455, 456]\n",
      "1109 1109 False\n",
      "[(113, 850), (129, 917), (136, 803), (113, 832), (109, 837), (125, 889), (115, 833), (119, 845), (107, 838), (108, 840), (114, 854), (114, 867), (113, 873), (106, 849), (131, 916), (120, 876), (119, 827), (118, 867), (133, 807), (114, 868), (119, 878), (119, 865), (124, 896), (112, 878), (117, 844), (145, 772), (113, 870), (116, 854), (106, 856), (118, 882)]\n",
      "1109 1109 False\n",
      "[145]\n"
     ]
    }
   ],
   "source": [
    "print(len(rgiid_dc_v3), len(rgiid_dc_v1), sorted(rgiid_dc_v3) == sorted(rgiid_dc_v1))\n",
    "# print(list(set(rgiid_dc_v3) - set(rgiid_dc_v1)))\n",
    "\n",
    "# print(len(latlon_unique_v1), len(latlon_unique_v4), sorted(latlon_unique_v1) == sorted(latlon_unique_v4))\n",
    "# print(list(set(latlon_unique_v4) - set(latlon_unique_v1)))\n",
    "\n",
    "# print(len(latlon_nearidx_v3), len(latlon_nearidx_v4), sorted(latlon_nearidx_v3) == sorted(latlon_nearidx_v4))\n",
    "# print(list(set(latlon_nearidx_v4) - set(latlon_nearidx_v3)))\n",
    "\n",
    "print(len(lat_nearidx_v3), len(lat_nearidx_v4), sorted(lat_nearidx_v3) == sorted(lat_nearidx_v4))\n",
    "print(list(set(lat_nearidx_v4) - set(lat_nearidx_v3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048 glaciers in region 13 are included in this model run: ['00611', '00643', '00713', '00757', '00761', '00763', '00777', '00788', '00809', '00830', '00834', '00838', '00880', '00884', '00885', '00891', '00905', '00906', '00940', '00949', '00951', '00954', '00956', '00964', '00965', '00967', '00982', '00995', '00997', '00999', '01019', '01022', '01023', '01027', '01038', '01044', '01045', '01050', '01098', '01099', '01113', '01124', '01129', '01136', '01144', '01145', '01148', '01150', '01157', '01175'] and more\n",
      "1026 glaciers in region 14 are included in this model run: ['00005', '00018', '00032', '00036', '00043', '00057', '00072', '00104', '00145', '00163', '00222', '00287', '00353', '00363', '00471', '00543', '00548', '00555', '00595', '00700', '00722', '00742', '00764', '00767', '00796', '00805', '00850', '00891', '00899', '00952', '01001', '01022', '01070', '01075', '01165', '01191', '01206', '01226', '01228', '01244', '01285', '01361', '01379', '01391', '01400', '01409', '01425', '01454', '01474', '01489'] and more\n",
      "802 glaciers in region 15 are included in this model run: ['00026', '00055', '00057', '00186', '00232', '00233', '00234', '00355', '00356', '00368', '00379', '00399', '00406', '00423', '00475', '00503', '00612', '00617', '00621', '00655', '00835', '00850', '00868', '00869', '00872', '00880', '00881', '00885', '00894', '00898', '00899', '00909', '00910', '00911', '00920', '00957', '00996', '01004', '01024', '01030', '01031', '01032', '01062', '01077', '01078', '01087', '01089', '01094', '01096', '01098'] and more\n",
      "This study is focusing on 2876 glaciers in region [13, 14, 15]\n",
      "\n",
      "DC glaciers (used for cal): 2876 DC Area (used for cal, km2): 5841.190133\n"
     ]
    }
   ],
   "source": [
    "# Statistics of data coverage\n",
    "rgiid_4cal = sorted(rgiid_4cal)\n",
    "main_glac_rgi_4cal = debris_prms.selectglaciersrgitable(rgiid_4cal)\n",
    "dc_area_dict = dict(zip(dc_shp.RGIId.values, dc_shp.DC_Area_v2.values))\n",
    "main_glac_rgi_4cal['DC_Area_v2'] = main_glac_rgi_4cal.RGIId.map(dc_area_dict)\n",
    "print('\\nDC glaciers (used for cal):', main_glac_rgi_4cal.shape[0], \n",
    "      'DC Area (used for cal, km2):', main_glac_rgi_4cal.DC_Area_v2.sum() / 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 44.75 80.0\n",
      "1 44.0 83.5\n",
      "2 44.0 83.75\n",
      "3 43.75 84.5\n",
      "4 43.75 84.75\n",
      "5 43.5 85.0\n",
      "6 43.25 77.5\n",
      "7 43.0 76.75\n",
      "8 43.0 77.0\n",
      "9 43.0 77.25\n",
      "10 43.0 77.5\n",
      "11 42.75 76.75\n",
      "12 42.75 77.0\n",
      "13 42.75 77.25\n",
      "14 42.75 82.75\n",
      "15 42.5 74.5\n",
      "16 42.5 75.0\n",
      "17 42.5 75.25\n",
      "18 42.5 80.5\n",
      "19 42.5 80.75\n",
      "20 42.5 81.0\n",
      "21 42.5 81.75\n",
      "22 42.5 82.0\n",
      "23 42.5 82.25\n",
      "24 42.5 82.5\n",
      "25 42.5 85.25\n",
      "26 42.25 78.25\n",
      "27 42.25 78.5\n",
      "28 42.25 78.75\n",
      "29 42.25 79.0\n",
      "30 42.25 79.25\n",
      "31 42.25 79.5\n",
      "32 42.25 79.75\n",
      "33 42.25 80.0\n",
      "34 42.25 80.25\n",
      "35 42.25 80.5\n",
      "36 42.25 80.75\n",
      "37 42.25 81.0\n",
      "38 42.25 81.25\n",
      "39 42.25 81.5\n",
      "40 42.25 81.75\n",
      "41 42.0 72.0\n",
      "42 42.0 77.0\n",
      "43 42.0 77.25\n",
      "44 42.0 77.5\n",
      "45 42.0 77.75\n",
      "46 42.0 78.0\n",
      "47 42.0 78.25\n",
      "48 42.0 78.5\n",
      "49 42.0 78.75\n",
      "50 42.0 79.75\n",
      "51 42.0 80.0\n",
      "52 42.0 80.25\n",
      "53 42.0 80.5\n",
      "54 42.0 80.75\n",
      "55 41.75 77.25\n",
      "56 41.75 78.25\n",
      "57 41.75 78.5\n",
      "58 41.75 79.0\n",
      "59 41.75 80.0\n",
      "60 41.75 80.25\n",
      "61 41.5 77.25\n",
      "62 41.5 77.5\n",
      "63 41.5 78.75\n",
      "64 41.25 77.75\n",
      "65 41.25 78.25\n",
      "66 41.25 78.5\n",
      "67 41.0 75.75\n",
      "68 41.0 77.5\n",
      "69 41.0 77.75\n",
      "70 40.75 74.25\n",
      "71 40.75 76.75\n",
      "72 40.0 72.5\n",
      "73 39.75 70.5\n",
      "74 39.75 70.75\n",
      "75 39.75 71.25\n",
      "76 39.75 71.5\n",
      "77 39.75 71.75\n",
      "78 39.75 72.0\n",
      "79 39.5 70.0\n",
      "80 39.5 70.25\n",
      "81 39.5 70.5\n",
      "82 39.5 70.75\n",
      "83 39.5 71.0\n",
      "84 39.5 71.25\n",
      "85 39.5 71.5\n",
      "86 39.5 72.5\n",
      "87 39.5 72.75\n",
      "88 39.5 73.0\n",
      "89 39.5 73.25\n",
      "90 39.5 73.5\n",
      "91 39.5 74.0\n",
      "92 39.25 69.5\n",
      "93 39.25 69.75\n",
      "94 39.25 70.0\n",
      "95 39.25 70.25\n",
      "96 39.25 71.0\n",
      "97 39.25 71.75\n",
      "98 39.25 72.0\n",
      "99 39.25 72.25\n",
      "100 39.25 72.5\n",
      "101 39.25 72.75\n",
      "102 39.25 73.0\n",
      "103 39.25 73.25\n",
      "104 39.25 73.5\n",
      "105 39.25 74.25\n",
      "106 39.25 74.5\n",
      "107 39.25 74.75\n",
      "108 39.25 75.0\n",
      "109 39.0 68.5\n",
      "110 39.0 70.75\n",
      "111 39.0 71.25\n",
      "112 39.0 71.5\n",
      "113 39.0 71.75\n",
      "114 39.0 72.0\n",
      "115 39.0 72.25\n",
      "116 39.0 72.5\n",
      "117 39.0 72.75\n",
      "118 39.0 73.0\n",
      "119 39.0 73.75\n",
      "120 39.0 74.75\n",
      "121 39.0 75.0\n",
      "122 38.75 71.0\n",
      "123 38.75 71.25\n",
      "124 38.75 71.5\n",
      "125 38.75 71.75\n",
      "126 38.75 72.0\n",
      "127 38.75 72.25\n",
      "128 38.75 72.5\n",
      "129 38.75 72.75\n",
      "130 38.75 73.0\n",
      "131 38.75 73.25\n",
      "132 38.75 75.0\n",
      "133 38.75 75.25\n",
      "134 38.75 75.5\n",
      "135 38.5 71.25\n",
      "136 38.5 71.5\n",
      "137 38.5 71.75\n",
      "138 38.5 72.0\n",
      "139 38.5 72.25\n",
      "140 38.5 72.5\n",
      "141 38.5 73.25\n",
      "142 38.5 73.5\n",
      "143 38.5 75.25\n",
      "144 38.5 75.5\n",
      "145 38.25 71.0\n",
      "146 38.25 71.25\n",
      "147 38.25 71.75\n",
      "148 38.25 72.0\n",
      "149 38.25 72.25\n",
      "150 38.25 72.5\n",
      "151 38.25 72.75\n",
      "152 38.25 75.0\n",
      "153 38.25 75.25\n",
      "154 38.0 71.0\n",
      "155 38.0 71.75\n",
      "156 38.0 72.0\n",
      "157 38.0 72.25\n",
      "158 38.0 72.5\n",
      "159 38.0 87.25\n",
      "160 38.0 87.5\n",
      "161 37.75 71.75\n",
      "162 37.75 72.0\n",
      "163 37.75 72.25\n",
      "164 37.75 72.75\n",
      "165 37.5 71.25\n",
      "166 37.5 72.0\n",
      "167 37.5 72.25\n",
      "168 37.5 75.25\n",
      "169 37.25 71.75\n",
      "170 37.25 72.5\n",
      "171 37.25 73.25\n",
      "172 37.25 73.5\n",
      "173 37.25 73.75\n",
      "174 37.25 75.0\n",
      "175 37.25 75.25\n",
      "176 37.25 86.0\n",
      "177 37.0 71.25\n",
      "178 37.0 71.75\n",
      "179 37.0 72.0\n",
      "180 37.0 72.25\n",
      "181 37.0 72.75\n",
      "182 37.0 73.0\n",
      "183 37.0 73.25\n",
      "184 37.0 73.75\n",
      "185 37.0 74.0\n",
      "186 37.0 74.25\n",
      "187 37.0 74.75\n",
      "188 37.0 75.0\n",
      "189 37.0 75.25\n",
      "190 36.75 72.0\n",
      "191 36.75 72.25\n",
      "192 36.75 72.5\n",
      "193 36.75 72.75\n",
      "194 36.75 73.0\n",
      "195 36.75 73.25\n",
      "196 36.75 73.5\n",
      "197 36.75 73.75\n",
      "198 36.75 74.0\n",
      "199 36.75 74.25\n",
      "200 36.75 74.5\n",
      "201 36.75 74.75\n",
      "202 36.75 75.0\n",
      "203 36.75 75.25\n",
      "204 36.75 75.5\n",
      "205 36.75 75.75\n",
      "206 36.75 76.0\n",
      "207 36.75 76.25\n",
      "208 36.75 77.75\n",
      "209 36.75 78.25\n",
      "210 36.75 78.5\n",
      "211 36.75 84.5\n",
      "212 36.75 84.75\n",
      "213 36.75 85.0\n",
      "214 36.75 85.25\n",
      "215 36.5 70.5\n",
      "216 36.5 71.5\n",
      "217 36.5 71.75\n",
      "218 36.5 72.0\n",
      "219 36.5 72.25\n",
      "220 36.5 72.75\n",
      "221 36.5 73.0\n",
      "222 36.5 73.25\n",
      "223 36.5 73.5\n",
      "224 36.5 73.75\n",
      "225 36.5 74.0\n",
      "226 36.5 74.25\n",
      "227 36.5 74.5\n",
      "228 36.5 74.75\n",
      "229 36.5 75.0\n",
      "230 36.5 75.25\n",
      "231 36.5 75.5\n",
      "232 36.5 75.75\n",
      "233 36.5 76.0\n",
      "234 36.5 77.5\n",
      "235 36.5 78.25\n",
      "236 36.25 69.75\n",
      "237 36.25 70.25\n",
      "238 36.25 70.5\n",
      "239 36.25 71.0\n",
      "240 36.25 71.75\n",
      "241 36.25 72.0\n",
      "242 36.25 72.25\n",
      "243 36.25 72.5\n",
      "244 36.25 72.75\n",
      "245 36.25 73.0\n",
      "246 36.25 74.0\n",
      "247 36.25 74.25\n",
      "248 36.25 74.5\n",
      "249 36.25 74.75\n",
      "250 36.25 75.0\n",
      "251 36.25 75.25\n",
      "252 36.25 75.5\n",
      "253 36.25 75.75\n",
      "254 36.25 76.0\n",
      "255 36.25 78.5\n",
      "256 36.25 78.75\n",
      "257 36.25 79.0\n",
      "258 36.25 79.25\n",
      "259 36.25 79.5\n",
      "260 36.25 82.25\n",
      "261 36.25 82.5\n",
      "262 36.0 70.5\n",
      "263 36.0 70.75\n",
      "264 36.0 71.0\n",
      "265 36.0 71.25\n",
      "266 36.0 72.25\n",
      "267 36.0 72.5\n",
      "268 36.0 72.75\n",
      "269 36.0 73.0\n",
      "270 36.0 74.5\n",
      "271 36.0 74.75\n",
      "272 36.0 75.0\n",
      "273 36.0 75.25\n",
      "274 36.0 75.5\n",
      "275 36.0 75.75\n",
      "276 36.0 76.25\n",
      "277 36.0 76.5\n",
      "278 36.0 79.5\n",
      "279 36.0 79.75\n",
      "280 36.0 80.0\n",
      "281 36.0 80.25\n",
      "282 36.0 80.75\n",
      "283 36.0 81.0\n",
      "284 36.0 81.25\n",
      "285 36.0 81.5\n",
      "286 36.0 81.75\n",
      "287 35.75 70.5\n",
      "288 35.75 70.75\n",
      "289 35.75 71.0\n",
      "290 35.75 71.25\n",
      "291 35.75 72.25\n",
      "292 35.75 72.5\n",
      "293 35.75 72.75\n",
      "294 35.75 73.0\n",
      "295 35.75 73.25\n",
      "296 35.75 74.75\n",
      "297 35.75 75.0\n",
      "298 35.75 75.25\n",
      "299 35.75 75.5\n",
      "300 35.75 75.75\n",
      "301 35.75 76.0\n",
      "302 35.75 76.25\n",
      "303 35.75 76.5\n",
      "304 35.75 76.75\n",
      "305 35.75 80.25\n",
      "306 35.75 80.5\n",
      "307 35.5 70.75\n",
      "308 35.5 72.5\n",
      "309 35.5 72.75\n",
      "310 35.5 73.0\n",
      "311 35.5 75.0\n",
      "312 35.5 75.25\n",
      "313 35.5 75.5\n",
      "314 35.5 75.75\n",
      "315 35.5 76.0\n",
      "316 35.5 76.25\n",
      "317 35.5 76.5\n",
      "318 35.5 76.75\n",
      "319 35.5 77.0\n",
      "320 35.5 80.75\n",
      "321 35.5 81.0\n",
      "322 35.25 72.75\n",
      "323 35.25 74.5\n",
      "324 35.25 74.75\n",
      "325 35.25 75.0\n",
      "326 35.25 75.25\n",
      "327 35.25 76.25\n",
      "328 35.25 76.5\n",
      "329 35.25 76.75\n",
      "330 35.25 77.0\n",
      "331 35.25 77.25\n",
      "332 35.25 77.5\n",
      "333 35.25 77.75\n",
      "334 35.0 73.5\n",
      "335 35.0 74.25\n",
      "336 35.0 74.5\n",
      "337 35.0 76.75\n",
      "338 35.0 77.0\n",
      "339 35.0 77.25\n",
      "340 35.0 77.5\n",
      "341 35.0 77.75\n",
      "342 35.0 78.25\n",
      "343 34.75 73.75\n",
      "344 34.75 76.75\n",
      "345 34.75 77.0\n",
      "346 34.75 77.25\n",
      "347 34.75 77.5\n",
      "348 34.75 77.75\n",
      "349 34.75 78.5\n",
      "350 34.5 75.5\n",
      "351 34.5 77.75\n",
      "352 34.5 78.0\n",
      "353 34.5 78.25\n",
      "354 34.25 75.25\n",
      "355 34.25 75.5\n",
      "356 34.25 75.75\n",
      "357 34.25 76.0\n",
      "358 34.25 78.25\n",
      "359 34.0 75.75\n",
      "360 34.0 76.0\n",
      "361 34.0 76.25\n",
      "362 34.0 78.25\n",
      "363 33.75 75.75\n",
      "364 33.75 76.0\n",
      "365 33.75 76.25\n",
      "366 33.75 78.5\n",
      "367 33.5 76.0\n",
      "368 33.5 76.25\n",
      "369 33.5 76.5\n",
      "370 33.5 76.75\n",
      "371 33.5 91.25\n",
      "372 33.25 76.25\n",
      "373 33.25 76.5\n",
      "374 33.25 76.75\n",
      "375 33.25 91.25\n",
      "376 33.0 76.5\n",
      "377 33.0 76.75\n",
      "378 33.0 77.0\n",
      "379 33.0 77.25\n",
      "380 33.0 78.5\n",
      "381 33.0 92.0\n",
      "382 32.75 76.25\n",
      "383 32.75 76.5\n",
      "384 32.75 76.75\n",
      "385 32.75 77.0\n",
      "386 32.75 77.25\n",
      "387 32.75 77.5\n",
      "388 32.5 76.5\n",
      "389 32.5 76.75\n",
      "390 32.5 77.0\n",
      "391 32.5 77.25\n",
      "392 32.5 77.5\n",
      "393 32.5 77.75\n",
      "394 32.5 78.75\n",
      "395 32.25 76.75\n",
      "396 32.25 77.0\n",
      "397 32.25 77.25\n",
      "398 32.25 77.5\n",
      "399 32.25 77.75\n",
      "400 32.25 78.5\n",
      "401 32.0 77.5\n",
      "402 32.0 77.75\n",
      "403 32.0 78.0\n",
      "404 32.0 78.75\n",
      "405 31.75 77.5\n",
      "406 31.75 77.75\n",
      "407 31.75 78.0\n",
      "408 31.75 78.25\n",
      "409 31.75 94.75\n",
      "410 31.75 99.0\n",
      "411 31.5 78.5\n",
      "412 31.5 100.25\n",
      "413 31.25 78.25\n",
      "414 31.25 78.5\n",
      "415 31.25 78.75\n",
      "416 31.0 78.5\n",
      "417 31.0 78.75\n",
      "418 31.0 79.0\n",
      "419 31.0 79.25\n",
      "420 31.0 79.5\n",
      "421 31.0 79.75\n",
      "422 31.0 93.75\n",
      "423 30.75 78.75\n",
      "424 30.75 79.0\n",
      "425 30.75 79.25\n",
      "426 30.75 79.5\n",
      "427 30.75 79.75\n",
      "428 30.75 80.0\n",
      "429 30.75 94.0\n",
      "430 30.75 94.25\n",
      "431 30.75 94.5\n",
      "432 30.75 94.75\n",
      "433 30.75 95.0\n",
      "434 30.75 95.25\n",
      "435 30.5 79.75\n",
      "436 30.5 80.0\n",
      "437 30.5 80.25\n",
      "438 30.5 80.5\n",
      "439 30.5 81.25\n",
      "440 30.5 83.25\n",
      "441 30.5 90.5\n",
      "442 30.5 93.25\n",
      "443 30.5 93.5\n",
      "444 30.5 94.0\n",
      "445 30.5 94.25\n",
      "446 30.5 94.5\n",
      "447 30.5 94.75\n",
      "448 30.5 95.0\n",
      "449 30.5 95.25\n",
      "450 30.25 79.75\n",
      "451 30.25 80.0\n",
      "452 30.25 80.25\n",
      "453 30.25 80.5\n",
      "454 30.25 80.75\n",
      "455 30.25 81.5\n",
      "456 30.25 81.75\n",
      "457 30.25 82.0\n",
      "458 30.25 82.25\n",
      "459 30.25 90.5\n",
      "460 30.25 93.5\n",
      "461 30.25 93.75\n",
      "462 30.25 94.0\n",
      "463 30.25 94.25\n",
      "464 30.25 94.5\n",
      "465 30.25 94.75\n",
      "466 30.25 95.0\n",
      "467 30.25 95.25\n",
      "468 30.25 95.5\n",
      "469 30.25 95.75\n",
      "470 30.0 81.0\n",
      "471 30.0 81.25\n",
      "472 30.0 81.5\n",
      "473 30.0 82.25\n",
      "474 30.0 82.5\n",
      "475 30.0 84.5\n",
      "476 30.0 90.0\n",
      "477 30.0 94.25\n",
      "478 30.0 94.75\n",
      "479 30.0 95.0\n",
      "480 30.0 95.25\n",
      "481 30.0 95.5\n",
      "482 30.0 95.75\n",
      "483 30.0 96.0\n",
      "484 29.75 81.0\n",
      "485 29.75 81.5\n",
      "486 29.75 82.25\n",
      "487 29.75 82.5\n",
      "488 29.75 82.75\n",
      "489 29.75 83.0\n",
      "490 29.75 84.5\n",
      "491 29.75 94.75\n",
      "492 29.75 95.0\n",
      "493 29.75 95.75\n",
      "494 29.75 96.0\n",
      "495 29.75 96.5\n",
      "496 29.75 97.25\n",
      "497 29.75 99.5\n",
      "498 29.75 101.75\n",
      "499 29.75 102.0\n",
      "500 29.5 82.5\n",
      "501 29.5 82.75\n",
      "502 29.5 95.0\n",
      "503 29.5 95.25\n",
      "504 29.5 96.0\n",
      "505 29.5 96.25\n",
      "506 29.5 96.5\n",
      "507 29.5 96.75\n",
      "508 29.5 97.0\n",
      "509 29.5 97.25\n",
      "510 29.5 97.5\n",
      "511 29.5 101.75\n",
      "512 29.25 82.5\n",
      "513 29.25 82.75\n",
      "514 29.25 95.0\n",
      "515 29.25 96.0\n",
      "516 29.25 96.25\n",
      "517 29.25 96.5\n",
      "518 29.25 96.75\n",
      "519 29.25 97.0\n",
      "520 29.0 83.5\n",
      "521 29.0 83.75\n",
      "522 29.0 84.25\n",
      "523 29.0 90.25\n",
      "524 29.0 96.25\n",
      "525 29.0 97.0\n",
      "526 29.0 97.25\n",
      "527 29.0 97.5\n",
      "528 29.0 97.75\n",
      "529 28.75 83.0\n",
      "530 28.75 83.25\n",
      "531 28.75 83.5\n",
      "532 28.75 83.75\n",
      "533 28.75 84.0\n",
      "534 28.75 84.25\n",
      "535 28.75 84.5\n",
      "536 28.75 93.5\n",
      "537 28.75 96.5\n",
      "538 28.75 98.25\n",
      "539 28.5 83.75\n",
      "540 28.5 84.0\n",
      "541 28.5 84.25\n",
      "542 28.5 84.5\n",
      "543 28.5 84.75\n",
      "544 28.5 85.0\n",
      "545 28.5 85.25\n",
      "546 28.5 85.5\n",
      "547 28.5 85.75\n",
      "548 28.5 96.5\n",
      "549 28.5 98.25\n",
      "550 28.5 98.5\n",
      "551 28.5 98.75\n",
      "552 28.25 85.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553 28.25 85.5\n",
      "554 28.25 85.75\n",
      "555 28.25 86.0\n",
      "556 28.25 86.25\n",
      "557 28.25 86.5\n",
      "558 28.25 86.75\n",
      "559 28.25 87.5\n",
      "560 28.25 90.0\n",
      "561 28.25 90.25\n",
      "562 28.25 90.5\n",
      "563 28.25 90.75\n",
      "564 28.25 91.25\n",
      "565 28.25 91.5\n",
      "566 28.25 92.75\n",
      "567 28.25 97.0\n",
      "568 28.0 86.0\n",
      "569 28.0 86.25\n",
      "570 28.0 86.5\n",
      "571 28.0 86.75\n",
      "572 28.0 87.0\n",
      "573 28.0 87.25\n",
      "574 28.0 87.5\n",
      "575 28.0 87.75\n",
      "576 28.0 88.0\n",
      "577 28.0 88.25\n",
      "578 28.0 88.5\n",
      "579 28.0 88.75\n",
      "580 28.0 89.0\n",
      "581 28.0 89.5\n",
      "582 28.0 89.75\n",
      "583 28.0 90.0\n",
      "584 28.0 90.25\n",
      "585 28.0 90.5\n",
      "586 28.0 90.75\n",
      "587 28.0 91.25\n",
      "588 28.0 91.5\n",
      "589 28.0 91.75\n",
      "590 28.0 92.5\n",
      "591 28.0 92.75\n",
      "592 27.75 86.5\n",
      "593 27.75 86.75\n",
      "594 27.75 87.0\n",
      "595 27.75 87.25\n",
      "596 27.75 87.75\n",
      "597 27.75 88.0\n",
      "598 27.75 88.25\n",
      "599 27.75 88.75\n",
      "600 27.75 89.25\n",
      "601 27.75 92.25\n",
      "602 27.75 92.5\n",
      "603 27.5 88.0\n",
      "604 27.5 88.25\n"
     ]
    }
   ],
   "source": [
    "# ===== ADD DEBRIS ELEVATION STATS TO MET DATA ======\n",
    "overwrite_dc_stats = True\n",
    "for nlatlon, latlon in enumerate(latlon_list_updated):\n",
    "# for nlatlon, latlon in enumerate([latlon_list_updated[0]]):\n",
    "    \n",
    "    lat_deg = latlon[0]\n",
    "    lon_deg = latlon[1]\n",
    "    \n",
    "    print(nlatlon, lat_deg, lon_deg)\n",
    "    \n",
    "    if lat_deg < 0:\n",
    "        lat_str = 'S-'\n",
    "    else:\n",
    "        lat_str = 'N-' \n",
    "\n",
    "    # ===== Meteorological data =====\n",
    "    metdata_fn = debris_prms.metdata_fn_sample.replace(\n",
    "        'XXXX', str(int(np.abs(lat_deg)*100)) + lat_str + str(int(lon_deg*100)) + 'E-')\n",
    "    \n",
    "    ds = xr.open_dataset(debris_prms.metdata_fp + metdata_fn)    \n",
    "#     print('  ', ds.dc_zmean.values, elev_stats_latlon_dict[latlon][0])\n",
    "    if 'dc_zmean' not in list(ds.keys()) or overwrite_dc_stats:\n",
    "        # Add stats\n",
    "        ds['dc_zmean'] = elev_stats_latlon_dict[latlon][0]\n",
    "        ds['dc_zmean'].attrs = {'units':'m a.s.l.', 'long_name':'Mean debris cover elevation', \n",
    "                                'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "        ds['dc_zstd'] = elev_stats_latlon_dict[latlon][1]\n",
    "        ds['dc_zstd'].attrs = {'units':'m a.s.l.', 'long_name':'Standard deviation of debris cover elevation', \n",
    "                               'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "        ds['dc_zmed'] = elev_stats_latlon_dict[latlon][2]\n",
    "        ds['dc_zmed'].attrs = {'units':'m a.s.l.', 'long_name':'Median debris cover elevation', \n",
    "                               'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "        ds['dc_zmad'] = elev_stats_latlon_dict[latlon][3]\n",
    "        ds['dc_zmad'].attrs = {'units':'m a.s.l.', 'long_name':'Median absolute deviation of debris cover elevation', \n",
    "                               'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "\n",
    "        try:\n",
    "            ds.close()\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        # Export updated dataset\n",
    "        ds.to_netcdf(debris_prms.metdata_fp + metdata_fn, mode='a')\n",
    "    else:\n",
    "        print(lat_deg, lon_deg, 'exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== OLD FILE OF LOADIING MULTIPLE DATASETS =====\n",
    "# # ===== LOAD GLACIERS WITH LARSEN DATA =====\n",
    "# dc_shp_subset['larsen_fullfn'] = np.nan\n",
    "# larsen_fullfn_dict = {}\n",
    "# if 'larsen' in input.mb_datasets:\n",
    "#     mb_summary = pd.read_csv(input.larsen_fp + input.larsen_fn)\n",
    "    \n",
    "#     # Find glaciers that are debris-covered\n",
    "#     larsen_dc_rgiid = [value for value in list(mb_summary.RGIId.values) \n",
    "#                        if value in list(dc_shp_subset.RGIId.values)]\n",
    "\n",
    "#     mb_summary_dc = mb_summary[mb_summary['RGIId'].isin(larsen_dc_rgiid)]\n",
    "#     mb_summary_dc = mb_summary_dc.sort_values('RGIId')\n",
    "#     mb_summary_dc.reset_index(inplace=True, drop=True)\n",
    "#     mb_summary_dc.loc[mb_summary_dc['name'] == 'Maclaren', 'name'] = 'MacLaren'\n",
    "#     mb_summary_dc.loc[mb_summary_dc['name'] == 'Tlikakila Fork', 'name'] = 'TlikakilaGlacierFork'\n",
    "#     mb_summary_dc.loc[mb_summary_dc['name'] == 'Tlikakila N. Fork', 'name'] = 'TlikakilaNorthFork'\n",
    "#     mb_summary_dc['larsen_fullfn'] = np.nan\n",
    "    \n",
    "#     for n, glac_name in enumerate(mb_summary_dc.name.values):\n",
    "# #     for n, glac_name in enumerate([mb_summary_dc.name.values[47]]):\n",
    "# #         print(n, glac_name)\n",
    "            \n",
    "#         glac_name = glac_name.replace(' ', '')\n",
    "#         glac_fns = []\n",
    "#         start_yr = []\n",
    "#         end_yr = []\n",
    "#         for i in os.listdir(input.larsen_binned_fp):\n",
    "#             if i.startswith(glac_name):\n",
    "#                 glac_fns.append(i)\n",
    "#                 start_yr.append(i.split('.')[1][0:4])\n",
    "#                 end_yr.append(i.split('.')[2][0:4])\n",
    "                \n",
    "#         if len(glac_fns) > 0:\n",
    "#             yr_dif = np.array(end_yr).astype(int) - np.array(start_yr).astype(int)\n",
    "#             mb_fn = glac_fns[np.where(yr_dif == yr_dif.max())[0][0]]\n",
    "            \n",
    "#             # ===== Process Larsen dataset =====\n",
    "#             larsen_data_raw = np.genfromtxt(input.larsen_binned_fp + mb_fn, skip_header=3)\n",
    "#             larsen_data_header = ['E', 'DZ', 'DZ25', 'DZ75', 'AAD', 'MassChange', 'MassBal', 'NumData']\n",
    "#             larsen_data = pd.DataFrame(larsen_data_raw, columns=larsen_data_header)\n",
    "#             larsen_data['std from DZ25'] = np.absolute(larsen_data['DZ'] - larsen_data['DZ25']) / 0.67\n",
    "#             larsen_data['std from DZ75'] = np.absolute(larsen_data['DZ'] - larsen_data['DZ75']) / 0.67\n",
    "#             larsen_data[' dhdt_bin_std_ma'] = (larsen_data['std from DZ25'] + larsen_data['std from DZ75']) / 2\n",
    "#             larsen_data[' mb_bin_std_mwea'] = larsen_data[' dhdt_bin_std_ma'] * 900 / 1000\n",
    "#             larsen_data['AAD'] = larsen_data['AAD'] / 1e6\n",
    "#             larsen_data['startyear'] = int(mb_fn.split('.')[1][0:4])\n",
    "#             larsen_data['endyear'] = int(mb_fn.split('.')[2][0:4])\n",
    "#             larsen_data = larsen_data.rename({'E': '# bin_center_elev_m',\n",
    "#                                               'DZ': ' dhdt_bin_mean_ma',\n",
    "#                                               'MassBal': ' mb_bin_mean_mwea',\n",
    "#                                               'AAD': ' z1_bin_area_valid_km2',\n",
    "#                                              }, axis='columns')\n",
    "#             new_fn = mb_summary_dc.loc[n,'RGIId'].split('-')[1][1:] + '_larsen_mb_bins.csv'\n",
    "#             larsen_data.to_csv(input.larsen_binned_fp + new_fn, index=False)\n",
    "            \n",
    "#             mb_summary_dc.loc[n, 'larsen_fullfn'] = input.larsen_binned_fp + new_fn\n",
    "            \n",
    "#         else:\n",
    "#             print(n, glac_name, 'has no file\\n')\n",
    "\n",
    "#     mb_summary_dc.dropna(subset=['larsen_fullfn'], inplace=True)\n",
    "#     mb_summary_dc.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "#     print('Larsen debris-covered glaciers:', mb_summary_dc.shape[0], '\\n\\n')\n",
    "    \n",
    "#     larsen_fullfn_dict = dict(zip(mb_summary_dc['RGIId'].values, mb_summary_dc['larsen_fullfn'].values))\n",
    "# #     print(larsen_fullfn_dict)\n",
    "#     dc_shp_subset['larsen_fullfn'] = dc_shp_subset.RGIId.map(larsen_fullfn_dict)\n",
    "\n",
    "# # ===== LOAD GLACIERS WITH BRAUN DATA =====\n",
    "# dc_shp_subset['braun_fullfn'] = np.nan\n",
    "# braun_fullfn_dict = {}\n",
    "# if 'braun' in input.mb_datasets:\n",
    "#     mb_binned_fp = input.main_directory + '/../mb_data/Braun/binned_data/'\n",
    "# #     mb_binned_fp = input.mb_binned_fp\n",
    "    \n",
    "#     mb_fns = []\n",
    "#     braun_rgiids = []\n",
    "#     for i in os.listdir(mb_binned_fp):\n",
    "#         if i.endswith('_mb_bins.csv'):\n",
    "#             mb_fns.append(mb_binned_fp + i)\n",
    "#             rgiid_raw = i.split('_')[0]\n",
    "#             rgiid = 'RGI60-' + rgiid_raw.split('.')[0].zfill(2) + '.' + rgiid_raw.split('.')[1]\n",
    "#             braun_rgiids.append(rgiid)\n",
    "#     braun_fn_df = pd.DataFrame(np.zeros((len(mb_fns),2)), columns=['RGIId', 'braun_fn'])\n",
    "#     braun_fn_df['RGIId'] = braun_rgiids\n",
    "#     braun_fn_df['braun_fullfn'] = mb_fns\n",
    "    \n",
    "#     # Find glaciers that are debris-covered\n",
    "#     braun_dc_rgiid = [value for value in list(braun_fn_df.RGIId.values) \n",
    "#                        if value in list(dc_shp_subset.RGIId.values)]\n",
    "#     braun_fn_df_dc = braun_fn_df[braun_fn_df['RGIId'].isin(braun_dc_rgiid)]\n",
    "#     braun_fn_df_dc = braun_fn_df_dc.sort_values('RGIId')\n",
    "    \n",
    "#     print('Braun debris-covered glaciers:', braun_fn_df_dc.shape[0], '\\n\\n')\n",
    "    \n",
    "#     braun_fullfn_dict = dict(zip(braun_fn_df_dc['RGIId'].values, braun_fn_df_dc['braun_fullfn'].values))\n",
    "    \n",
    "#     dc_shp_subset['braun_fullfn'] = dc_shp_subset.RGIId.map(braun_fullfn_dict)\n",
    "\n",
    "# # ===== LOAD GLACIERS WITH SHEAN DATA =====\n",
    "# dc_shp_subset['shean_fullfn'] = np.nan\n",
    "# shean_fullfn_dict = {}\n",
    "# if 'shean' in input.mb_datasets:\n",
    "# #     mb_binned_fp = input.main_directory + '/../mb_data/Shean_2019_0213/mb_combined_20190213_nmad_bins/'\n",
    "#     mb_binned_fp = input.mb_binned_fp\n",
    "    \n",
    "#     mb_fns = []\n",
    "#     rgiids = []\n",
    "#     for i in os.listdir(mb_binned_fp):\n",
    "#         if i.endswith('_mb_bins.csv'):\n",
    "#             mb_fns.append(mb_binned_fp + i)\n",
    "#             rgiid_raw = i.split('_')[0]\n",
    "#             rgiid = 'RGI60-' + rgiid_raw.split('.')[0].zfill(2) + '.' + rgiid_raw.split('.')[1]\n",
    "#             rgiids.append(rgiid)\n",
    "#     mb_fn_df = pd.DataFrame(np.zeros((len(mb_fns),2)), columns=['RGIId', 'mb_fn'])\n",
    "#     mb_fn_df['RGIId'] = rgiids\n",
    "#     mb_fn_df['mb_fullfn'] = mb_fns\n",
    "    \n",
    "#     # Find glaciers that are debris-covered\n",
    "#     mb_dc_rgiid = [value for value in list(mb_fn_df.RGIId.values) \n",
    "#                    if value in list(dc_shp_subset.RGIId.values)]\n",
    "#     mb_fn_df_dc = mb_fn_df[mb_fn_df['RGIId'].isin(mb_dc_rgiid)]\n",
    "#     mb_fn_df_dc = mb_fn_df_dc.sort_values('RGIId')\n",
    "    \n",
    "#     print('shean debris-covered glaciers:', mb_fn_df_dc.shape[0], '\\n\\n')\n",
    "    \n",
    "#     shean_fullfn_dict = dict(zip(mb_fn_df_dc['RGIId'].values, mb_fn_df_dc['mb_fullfn'].values))\n",
    "# #     print(shea_fullfn_dict)\n",
    "#     dc_shp_subset['shean_fullfn'] = dc_shp_subset.RGIId.map(shean_fullfn_dict)\n",
    "\n",
    "# # Merge dictionaries together\n",
    "# mb_fn_dict = dict(list(larsen_fullfn_dict.items()) + list(braun_fullfn_dict.items()) + \n",
    "#                   list(shean_fullfn_dict.items()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debris_thickness_global]",
   "language": "python",
   "name": "conda-env-debris_thickness_global-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
