{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "Compute elevation statistics for the debris-covered areas in each latitude and longitude\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from scipy import ndimage\n",
    "import xarray as xr\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "from pygeotools.lib import malib, warplib, geolib, iolib, timelib\n",
    "\n",
    "import debrisglobal.globaldebris_input as debris_prms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All DC glaciers: 2919 All DC Area (km2): 220.176821\n",
      "Subset DC glaciers: 156 Subset DC Area (km2): 126.509554\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGIId</th>\n",
       "      <th>GLIMSId</th>\n",
       "      <th>BgnDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>...</th>\n",
       "      <th>Name</th>\n",
       "      <th>DC_Area</th>\n",
       "      <th>DC_BgnDate</th>\n",
       "      <th>DC_EndDate</th>\n",
       "      <th>DC_CTSmean</th>\n",
       "      <th>DC_Area_%</th>\n",
       "      <th>area_singl</th>\n",
       "      <th>DC_Area_v2</th>\n",
       "      <th>DC_Area__1</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RGI60-11.00002</td>\n",
       "      <td>G013614E47485N</td>\n",
       "      <td>20030799</td>\n",
       "      <td>20030999</td>\n",
       "      <td>13.614373</td>\n",
       "      <td>47.483905</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.292</td>\n",
       "      <td>2203</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>186300</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>29.698587</td>\n",
       "      <td>8.128</td>\n",
       "      <td>900</td>\n",
       "      <td>186399</td>\n",
       "      <td>8.133</td>\n",
       "      <td>MULTIPOLYGON (((13.60653 47.47813, 13.60692 47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RGI60-11.00047</td>\n",
       "      <td>G012719E47139N</td>\n",
       "      <td>20030799</td>\n",
       "      <td>20030999</td>\n",
       "      <td>12.718158</td>\n",
       "      <td>47.139499</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2307</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>152100</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>20.334521</td>\n",
       "      <td>6.692</td>\n",
       "      <td>900</td>\n",
       "      <td>156609</td>\n",
       "      <td>6.890</td>\n",
       "      <td>MULTIPOLYGON (((12.70776 47.13999, 12.70815 47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RGI60-11.00054</td>\n",
       "      <td>G012372E47149N</td>\n",
       "      <td>20030799</td>\n",
       "      <td>20030999</td>\n",
       "      <td>12.370435</td>\n",
       "      <td>47.149801</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.274</td>\n",
       "      <td>2359</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>143100</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>17.590514</td>\n",
       "      <td>6.293</td>\n",
       "      <td>900</td>\n",
       "      <td>143075</td>\n",
       "      <td>6.292</td>\n",
       "      <td>MULTIPOLYGON (((12.35997 47.14789, 12.36037 47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RGI60-11.00068</td>\n",
       "      <td>G012345E47132N</td>\n",
       "      <td>20030799</td>\n",
       "      <td>20030999</td>\n",
       "      <td>12.343717</td>\n",
       "      <td>47.135779</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.738</td>\n",
       "      <td>2162</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>176400</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>18.493408</td>\n",
       "      <td>6.443</td>\n",
       "      <td>900</td>\n",
       "      <td>176364</td>\n",
       "      <td>6.441</td>\n",
       "      <td>MULTIPOLYGON (((12.35453 47.12994, 12.35493 47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RGI60-11.00106</td>\n",
       "      <td>G012697E47099N</td>\n",
       "      <td>20030799</td>\n",
       "      <td>20030999</td>\n",
       "      <td>12.698172</td>\n",
       "      <td>47.094468</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>17.774</td>\n",
       "      <td>2086</td>\n",
       "      <td>...</td>\n",
       "      <td>Pasterze</td>\n",
       "      <td>2984400</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>23.575460</td>\n",
       "      <td>16.791</td>\n",
       "      <td>4500</td>\n",
       "      <td>3036802</td>\n",
       "      <td>17.086</td>\n",
       "      <td>MULTIPOLYGON (((12.70993 47.08010, 12.71112 47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>RGI60-11.03694</td>\n",
       "      <td>G006263E44892N</td>\n",
       "      <td>20030813</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>6.259492</td>\n",
       "      <td>44.893911</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2405</td>\n",
       "      <td>...</td>\n",
       "      <td>FR4N01166E06 du Vallon des Etages</td>\n",
       "      <td>813600</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>42.305511</td>\n",
       "      <td>36.289</td>\n",
       "      <td>900</td>\n",
       "      <td>814213</td>\n",
       "      <td>36.316</td>\n",
       "      <td>MULTIPOLYGON (((6.25929 44.88545, 6.25967 44.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>RGI60-11.03698</td>\n",
       "      <td>G006988E45987N</td>\n",
       "      <td>20030813</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>6.995296</td>\n",
       "      <td>45.985482</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8.124</td>\n",
       "      <td>2193</td>\n",
       "      <td>...</td>\n",
       "      <td>FR4N01234A01 du Tour</td>\n",
       "      <td>573300</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>38.465296</td>\n",
       "      <td>7.057</td>\n",
       "      <td>5401</td>\n",
       "      <td>577015</td>\n",
       "      <td>7.103</td>\n",
       "      <td>MULTIPOLYGON (((7.00593 45.96921, 7.00709 45.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>RGI60-11.03701</td>\n",
       "      <td>G007144E45371N</td>\n",
       "      <td>20030813</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>7.145103</td>\n",
       "      <td>45.375305</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.373</td>\n",
       "      <td>2761</td>\n",
       "      <td>...</td>\n",
       "      <td>FR4N01153B19 du Mulinet</td>\n",
       "      <td>403200</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>38.446785</td>\n",
       "      <td>16.991</td>\n",
       "      <td>900</td>\n",
       "      <td>404213</td>\n",
       "      <td>17.034</td>\n",
       "      <td>MULTIPOLYGON (((7.15623 45.36957, 7.15661 45.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>RGI60-11.03740</td>\n",
       "      <td>G007123E45253N</td>\n",
       "      <td>20030813</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>7.118216</td>\n",
       "      <td>45.254020</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.067</td>\n",
       "      <td>2773</td>\n",
       "      <td>...</td>\n",
       "      <td>FR4N01153C19 du Baounet 1</td>\n",
       "      <td>453600</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>41.382340</td>\n",
       "      <td>21.945</td>\n",
       "      <td>1800</td>\n",
       "      <td>464972</td>\n",
       "      <td>22.495</td>\n",
       "      <td>MULTIPOLYGON (((7.12013 45.24476, 7.12090 45.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>RGI60-11.03760</td>\n",
       "      <td>G006147E45146N</td>\n",
       "      <td>20030813</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>6.146433</td>\n",
       "      <td>45.141572</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.008</td>\n",
       "      <td>2608</td>\n",
       "      <td>...</td>\n",
       "      <td>FR4N01163C06 des Quirlies 1</td>\n",
       "      <td>299700</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>51.667262</td>\n",
       "      <td>14.925</td>\n",
       "      <td>1799</td>\n",
       "      <td>299571</td>\n",
       "      <td>14.919</td>\n",
       "      <td>MULTIPOLYGON (((6.14564 45.13193, 6.14602 45.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              RGIId         GLIMSId   BgnDate   EndDate     CenLon     CenLat  \\\n",
       "0    RGI60-11.00002  G013614E47485N  20030799  20030999  13.614373  47.483905   \n",
       "1    RGI60-11.00047  G012719E47139N  20030799  20030999  12.718158  47.139499   \n",
       "2    RGI60-11.00054  G012372E47149N  20030799  20030999  12.370435  47.149801   \n",
       "3    RGI60-11.00068  G012345E47132N  20030799  20030999  12.343717  47.135779   \n",
       "4    RGI60-11.00106  G012697E47099N  20030799  20030999  12.698172  47.094468   \n",
       "..              ...             ...       ...       ...        ...        ...   \n",
       "151  RGI60-11.03694  G006263E44892N  20030813  -9999999   6.259492  44.893911   \n",
       "152  RGI60-11.03698  G006988E45987N  20030813  -9999999   6.995296  45.985482   \n",
       "153  RGI60-11.03701  G007144E45371N  20030813  -9999999   7.145103  45.375305   \n",
       "154  RGI60-11.03740  G007123E45253N  20030813  -9999999   7.118216  45.254020   \n",
       "155  RGI60-11.03760  G006147E45146N  20030813  -9999999   6.146433  45.141572   \n",
       "\n",
       "    O1Region O2Region    Area  Zmin  ...                               Name  \\\n",
       "0         11        1   2.292  2203  ...                               None   \n",
       "1         11        1   2.273  2307  ...                               None   \n",
       "2         11        1   2.274  2359  ...                               None   \n",
       "3         11        1   2.738  2162  ...                               None   \n",
       "4         11        1  17.774  2086  ...                           Pasterze   \n",
       "..       ...      ...     ...   ...  ...                                ...   \n",
       "151       11        1   2.242  2405  ...  FR4N01166E06 du Vallon des Etages   \n",
       "152       11        1   8.124  2193  ...               FR4N01234A01 du Tour   \n",
       "153       11        1   2.373  2761  ...            FR4N01153B19 du Mulinet   \n",
       "154       11        1   2.067  2773  ...          FR4N01153C19 du Baounet 1   \n",
       "155       11        1   2.008  2608  ...        FR4N01163C06 des Quirlies 1   \n",
       "\n",
       "     DC_Area  DC_BgnDate  DC_EndDate  DC_CTSmean  DC_Area_%  area_singl  \\\n",
       "0     186300        2013        2017   29.698587      8.128         900   \n",
       "1     152100        2013        2017   20.334521      6.692         900   \n",
       "2     143100        2013        2017   17.590514      6.293         900   \n",
       "3     176400        2013        2017   18.493408      6.443         900   \n",
       "4    2984400        2013        2017   23.575460     16.791        4500   \n",
       "..       ...         ...         ...         ...        ...         ...   \n",
       "151   813600        2013        2017   42.305511     36.289         900   \n",
       "152   573300        2013        2017   38.465296      7.057        5401   \n",
       "153   403200        2013        2017   38.446785     16.991         900   \n",
       "154   453600        2013        2017   41.382340     21.945        1800   \n",
       "155   299700        2013        2017   51.667262     14.925        1799   \n",
       "\n",
       "     DC_Area_v2  DC_Area__1                                           geometry  \n",
       "0        186399       8.133  MULTIPOLYGON (((13.60653 47.47813, 13.60692 47...  \n",
       "1        156609       6.890  MULTIPOLYGON (((12.70776 47.13999, 12.70815 47...  \n",
       "2        143075       6.292  MULTIPOLYGON (((12.35997 47.14789, 12.36037 47...  \n",
       "3        176364       6.441  MULTIPOLYGON (((12.35453 47.12994, 12.35493 47...  \n",
       "4       3036802      17.086  MULTIPOLYGON (((12.70993 47.08010, 12.71112 47...  \n",
       "..          ...         ...                                                ...  \n",
       "151      814213      36.316  MULTIPOLYGON (((6.25929 44.88545, 6.25967 44.8...  \n",
       "152      577015       7.103  MULTIPOLYGON (((7.00593 45.96921, 7.00709 45.9...  \n",
       "153      404213      17.034  MULTIPOLYGON (((7.15623 45.36957, 7.15661 45.3...  \n",
       "154      464972      22.495  MULTIPOLYGON (((7.12013 45.24476, 7.12090 45.2...  \n",
       "155      299571      14.919  MULTIPOLYGON (((6.14564 45.13193, 6.14602 45.1...  \n",
       "\n",
       "[156 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debris cover extent shapefile with statistics\n",
    "dc_shp = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[debris_prms.roi])\n",
    "dc_shp = dc_shp.sort_values(by=['RGIId'])\n",
    "\n",
    "print('All DC glaciers:', dc_shp.shape[0], 'All DC Area (km2):', dc_shp.DC_Area_v2.sum() / 1e6)\n",
    "\n",
    "# Subset by percent debris-covered or debris-covered area\n",
    "dc_shp_subset = dc_shp[((dc_shp['DC_Area__1'] > debris_prms.dc_percarea_threshold) | \n",
    "                        (dc_shp['DC_Area_v2'] / 1e6 > debris_prms.dc_area_threshold))\n",
    "                        & (dc_shp['Area'] > debris_prms.min_glac_area)].copy()\n",
    "dc_shp_subset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "rgino_str_list_subset = [x.split('-')[1] for x in dc_shp_subset.RGIId.values]\n",
    "\n",
    "print('Subset DC glaciers:', dc_shp_subset.shape[0], 'Subset DC Area (km2):', dc_shp_subset.DC_Area_v2.sum() / 1e6)\n",
    "\n",
    "dc_shp_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 glaciers in region 11 are included in this model run: ['00002', '00047', '00054', '00068', '00106', '00110', '00116', '00135', '00141', '00190', '00199', '00233', '00278', '00376', '00415', '00459', '00469', '00487', '00524', '00541', '00597', '00719', '00781', '00797', '00830', '00846', '00871', '00886', '00887', '00897', '00918', '00929', '00932', '00943', '00945', '00950', '00957', '00958', '01144', '01187', '01193', '01246', '01275', '01296', '01328', '01346', '01450', '01478', '01509', '01550'] and more\n",
      "This study is focusing on 156 glaciers in region [11]\n",
      "unique lat/lons: 47 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select glaciers using RGI and find unique latlons\n",
    "#  (Scherler DC shapefiles do not have same CenLat and CenLon for some reason)\n",
    "main_glac_rgi_subset = debris_prms.selectglaciersrgitable(rgino_str_list_subset)\n",
    "main_glac_rgi_subset['CenLon_360'] = main_glac_rgi_subset['CenLon']\n",
    "main_glac_rgi_subset.loc[main_glac_rgi_subset['CenLon_360'] < 0, 'CenLon_360'] = (\n",
    "    360 + main_glac_rgi_subset.loc[main_glac_rgi_subset['CenLon_360'] < 0, 'CenLon_360'])\n",
    "\n",
    "# Load met data and find nearest latlon indices\n",
    "ds = xr.open_dataset(debris_prms.metdata_fp + '../' + debris_prms.metdata_elev_fn)\n",
    "#  argmin() finds the minimum distance between the glacier lat/lon and the GCM pixel\n",
    "lat_nearidx = (np.abs(main_glac_rgi_subset['CenLat'].values[:,np.newaxis] - \n",
    "                      ds['latitude'][:].values).argmin(axis=1))\n",
    "lon_nearidx = (np.abs(main_glac_rgi_subset['CenLon_360'].values[:,np.newaxis] - \n",
    "                      ds['longitude'][:].values).argmin(axis=1))\n",
    "latlon_nearidx = list(zip(lat_nearidx, lon_nearidx))\n",
    "latlon_nearidx_unique = sorted(list(set(latlon_nearidx)))\n",
    "main_glac_rgi_subset['latlon_nearidx'] = latlon_nearidx\n",
    "latlon_unique_dict = dict(zip(latlon_nearidx_unique,np.arange(0,len(latlon_nearidx_unique))))\n",
    "latlon_unique_dict_reversed = dict(zip(np.arange(0,len(latlon_nearidx_unique)),latlon_nearidx_unique))\n",
    "main_glac_rgi_subset['latlon_unique_no'] = main_glac_rgi_subset['latlon_nearidx'].map(latlon_unique_dict)\n",
    "\n",
    "print('unique lat/lons:', len(np.unique(main_glac_rgi_subset['latlon_unique_no'])), '\\n\\n')\n",
    "\n",
    "# Delete me\n",
    "latlon_nearidx_unique_v1 = latlon_nearidx_unique.copy()\n",
    "\n",
    "lat_list = np.array([ds.latitude[x[0]].values for x in latlon_nearidx_unique])\n",
    "lon_list = np.array([ds.longitude[x[1]].values for x in latlon_nearidx_unique])\n",
    "latlon_list = list(tuple(zip(list(lat_list), list(lon_list))))\n",
    "\n",
    "# Pickle unique lat/lons that will be used for melt model\n",
    "with open(debris_prms.latlon_unique_fp + debris_prms.latlon_unique_dict[debris_prms.roi], 'wb') as f:\n",
    "    pickle.dump(latlon_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debris-covered glaciers: 150 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== LOAD GLACIERS WITH DATA =====\n",
    "main_glac_rgi_subset['mb_fn'] = np.nan\n",
    "mb_binned_fp = debris_prms.mb_binned_fp\n",
    "\n",
    "regions_str = [str(x).zfill(2) for x in debris_prms.roi_rgidict[debris_prms.roi]]\n",
    "\n",
    "mb_fns = []\n",
    "mb_rgiids = []\n",
    "for i in os.listdir(mb_binned_fp):\n",
    "    if i.endswith('_mb_bins.csv') and i.split('_')[0].split('.')[0].zfill(2) in regions_str:\n",
    "        mb_fns.append(i)\n",
    "        rgiid_raw = i.split('_')[0]\n",
    "        rgiid = 'RGI60-' + rgiid_raw.split('.')[0].zfill(2) + '.' + rgiid_raw.split('.')[1]\n",
    "        mb_rgiids.append(rgiid)\n",
    "mb_rgiids = sorted(mb_rgiids)\n",
    "mb_fns = sorted(mb_fns)\n",
    "mb_fn_df = pd.DataFrame(np.zeros((len(mb_fns),2)), columns=['RGIId', 'mb_fn'])\n",
    "mb_fn_df['RGIId'] = mb_rgiids\n",
    "mb_fn_df['mb_fn'] = mb_fns\n",
    "\n",
    "# Find glaciers that are debris-covered\n",
    "mb_dc_rgiid = [value for value in list(mb_fn_df.RGIId.values) if value in list(main_glac_rgi_subset.RGIId.values)]\n",
    "mb_fn_df_dc = mb_fn_df[mb_fn_df['RGIId'].isin(mb_dc_rgiid)]\n",
    "mb_fn_df_dc = mb_fn_df_dc.sort_values('RGIId')\n",
    "\n",
    "print('Debris-covered glaciers:', mb_fn_df_dc.shape[0], '\\n\\n')\n",
    "\n",
    "mb_fn_dict = dict(zip(mb_fn_df_dc['RGIId'].values, mb_fn_df_dc['mb_fn'].values))\n",
    "\n",
    "main_glac_rgi_subset['mb_fn'] = main_glac_rgi_subset.RGIId.map(mb_fn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique lat/lons: 47 \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O1Index</th>\n",
       "      <th>RGIId</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>Zmax</th>\n",
       "      <th>Zmed</th>\n",
       "      <th>...</th>\n",
       "      <th>TermType</th>\n",
       "      <th>Surging</th>\n",
       "      <th>RefDate</th>\n",
       "      <th>glacno</th>\n",
       "      <th>rgino_str</th>\n",
       "      <th>RGIId_float</th>\n",
       "      <th>CenLon_360</th>\n",
       "      <th>latlon_nearidx</th>\n",
       "      <th>latlon_unique_no</th>\n",
       "      <th>mb_fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RGI60-11.00002</td>\n",
       "      <td>13.613500</td>\n",
       "      <td>47.484500</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.292</td>\n",
       "      <td>2203</td>\n",
       "      <td>2855</td>\n",
       "      <td>2526</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20039999</td>\n",
       "      <td>2</td>\n",
       "      <td>11.00002</td>\n",
       "      <td>11.00002</td>\n",
       "      <td>13.613500</td>\n",
       "      <td>(170, 54)</td>\n",
       "      <td>0</td>\n",
       "      <td>11.00002_mb_bins.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>RGI60-11.00047</td>\n",
       "      <td>12.719400</td>\n",
       "      <td>47.138600</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2307</td>\n",
       "      <td>3253</td>\n",
       "      <td>2967</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20039999</td>\n",
       "      <td>47</td>\n",
       "      <td>11.00047</td>\n",
       "      <td>11.00047</td>\n",
       "      <td>12.719400</td>\n",
       "      <td>(171, 51)</td>\n",
       "      <td>2</td>\n",
       "      <td>11.00047_mb_bins.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>RGI60-11.00054</td>\n",
       "      <td>12.371700</td>\n",
       "      <td>47.148700</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.274</td>\n",
       "      <td>2359</td>\n",
       "      <td>3196</td>\n",
       "      <td>2779</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20039999</td>\n",
       "      <td>54</td>\n",
       "      <td>11.00054</td>\n",
       "      <td>11.00054</td>\n",
       "      <td>12.371700</td>\n",
       "      <td>(171, 49)</td>\n",
       "      <td>1</td>\n",
       "      <td>11.00054_mb_bins.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>RGI60-11.00068</td>\n",
       "      <td>12.345300</td>\n",
       "      <td>47.132200</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.738</td>\n",
       "      <td>2162</td>\n",
       "      <td>3440</td>\n",
       "      <td>2759</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20039999</td>\n",
       "      <td>68</td>\n",
       "      <td>11.00068</td>\n",
       "      <td>11.00068</td>\n",
       "      <td>12.345300</td>\n",
       "      <td>(171, 49)</td>\n",
       "      <td>1</td>\n",
       "      <td>11.00068_mb_bins.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>RGI60-11.00106</td>\n",
       "      <td>12.696700</td>\n",
       "      <td>47.099100</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>17.774</td>\n",
       "      <td>2086</td>\n",
       "      <td>3487</td>\n",
       "      <td>2984</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20039999</td>\n",
       "      <td>106</td>\n",
       "      <td>11.00106</td>\n",
       "      <td>11.00106</td>\n",
       "      <td>12.696700</td>\n",
       "      <td>(172, 51)</td>\n",
       "      <td>9</td>\n",
       "      <td>11.00106_mb_bins.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3686</td>\n",
       "      <td>RGI60-11.03687</td>\n",
       "      <td>6.334000</td>\n",
       "      <td>44.865000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.040</td>\n",
       "      <td>2256</td>\n",
       "      <td>3513</td>\n",
       "      <td>2925</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20030921</td>\n",
       "      <td>3687</td>\n",
       "      <td>11.03687</td>\n",
       "      <td>11.03687</td>\n",
       "      <td>6.334000</td>\n",
       "      <td>(181, 25)</td>\n",
       "      <td>46</td>\n",
       "      <td>11.03687_mb_bins.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3697</td>\n",
       "      <td>RGI60-11.03698</td>\n",
       "      <td>6.988000</td>\n",
       "      <td>45.987000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8.124</td>\n",
       "      <td>2193</td>\n",
       "      <td>3707</td>\n",
       "      <td>2977</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20030813</td>\n",
       "      <td>3698</td>\n",
       "      <td>11.03698</td>\n",
       "      <td>11.03698</td>\n",
       "      <td>6.988000</td>\n",
       "      <td>(176, 28)</td>\n",
       "      <td>30</td>\n",
       "      <td>11.03698_mb_bins.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3700</td>\n",
       "      <td>RGI60-11.03701</td>\n",
       "      <td>7.144000</td>\n",
       "      <td>45.371000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.373</td>\n",
       "      <td>2761</td>\n",
       "      <td>3340</td>\n",
       "      <td>3046</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20030813</td>\n",
       "      <td>3701</td>\n",
       "      <td>11.03701</td>\n",
       "      <td>11.03701</td>\n",
       "      <td>7.144000</td>\n",
       "      <td>(179, 29)</td>\n",
       "      <td>43</td>\n",
       "      <td>11.03701_mb_bins.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3739</td>\n",
       "      <td>RGI60-11.03740</td>\n",
       "      <td>7.122775</td>\n",
       "      <td>45.252968</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.067</td>\n",
       "      <td>2773</td>\n",
       "      <td>3310</td>\n",
       "      <td>3026</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20030813</td>\n",
       "      <td>3740</td>\n",
       "      <td>11.03740</td>\n",
       "      <td>11.03740</td>\n",
       "      <td>7.122775</td>\n",
       "      <td>(179, 28)</td>\n",
       "      <td>42</td>\n",
       "      <td>11.03740_mb_bins.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3759</td>\n",
       "      <td>RGI60-11.03760</td>\n",
       "      <td>6.146941</td>\n",
       "      <td>45.146187</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.008</td>\n",
       "      <td>2608</td>\n",
       "      <td>3387</td>\n",
       "      <td>2945</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20030813</td>\n",
       "      <td>3760</td>\n",
       "      <td>11.03760</td>\n",
       "      <td>11.03760</td>\n",
       "      <td>6.146941</td>\n",
       "      <td>(179, 25)</td>\n",
       "      <td>39</td>\n",
       "      <td>11.03760_mb_bins.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     O1Index           RGIId     CenLon     CenLat  O1Region  O2Region  \\\n",
       "0          1  RGI60-11.00002  13.613500  47.484500        11         1   \n",
       "1         46  RGI60-11.00047  12.719400  47.138600        11         1   \n",
       "2         53  RGI60-11.00054  12.371700  47.148700        11         1   \n",
       "3         67  RGI60-11.00068  12.345300  47.132200        11         1   \n",
       "4        105  RGI60-11.00106  12.696700  47.099100        11         1   \n",
       "..       ...             ...        ...        ...       ...       ...   \n",
       "145     3686  RGI60-11.03687   6.334000  44.865000        11         1   \n",
       "146     3697  RGI60-11.03698   6.988000  45.987000        11         1   \n",
       "147     3700  RGI60-11.03701   7.144000  45.371000        11         1   \n",
       "148     3739  RGI60-11.03740   7.122775  45.252968        11         1   \n",
       "149     3759  RGI60-11.03760   6.146941  45.146187        11         1   \n",
       "\n",
       "       Area  Zmin  Zmax  Zmed  ...  TermType  Surging   RefDate  glacno  \\\n",
       "0     2.292  2203  2855  2526  ...         0        9  20039999       2   \n",
       "1     2.273  2307  3253  2967  ...         0        9  20039999      47   \n",
       "2     2.274  2359  3196  2779  ...         0        9  20039999      54   \n",
       "3     2.738  2162  3440  2759  ...         0        9  20039999      68   \n",
       "4    17.774  2086  3487  2984  ...         0        9  20039999     106   \n",
       "..      ...   ...   ...   ...  ...       ...      ...       ...     ...   \n",
       "145   3.040  2256  3513  2925  ...         0        9  20030921    3687   \n",
       "146   8.124  2193  3707  2977  ...         0        9  20030813    3698   \n",
       "147   2.373  2761  3340  3046  ...         0        9  20030813    3701   \n",
       "148   2.067  2773  3310  3026  ...         0        9  20030813    3740   \n",
       "149   2.008  2608  3387  2945  ...         0        9  20030813    3760   \n",
       "\n",
       "     rgino_str  RGIId_float  CenLon_360  latlon_nearidx latlon_unique_no  \\\n",
       "0     11.00002     11.00002   13.613500       (170, 54)                0   \n",
       "1     11.00047     11.00047   12.719400       (171, 51)                2   \n",
       "2     11.00054     11.00054   12.371700       (171, 49)                1   \n",
       "3     11.00068     11.00068   12.345300       (171, 49)                1   \n",
       "4     11.00106     11.00106   12.696700       (172, 51)                9   \n",
       "..         ...          ...         ...             ...              ...   \n",
       "145   11.03687     11.03687    6.334000       (181, 25)               46   \n",
       "146   11.03698     11.03698    6.988000       (176, 28)               30   \n",
       "147   11.03701     11.03701    7.144000       (179, 29)               43   \n",
       "148   11.03740     11.03740    7.122775       (179, 28)               42   \n",
       "149   11.03760     11.03760    6.146941       (179, 25)               39   \n",
       "\n",
       "                    mb_fn  \n",
       "0    11.00002_mb_bins.csv  \n",
       "1    11.00047_mb_bins.csv  \n",
       "2    11.00054_mb_bins.csv  \n",
       "3    11.00068_mb_bins.csv  \n",
       "4    11.00106_mb_bins.csv  \n",
       "..                    ...  \n",
       "145  11.03687_mb_bins.csv  \n",
       "146  11.03698_mb_bins.csv  \n",
       "147  11.03701_mb_bins.csv  \n",
       "148  11.03740_mb_bins.csv  \n",
       "149  11.03760_mb_bins.csv  \n",
       "\n",
       "[150 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== SELECT GLACIERS WITH DATA ====\n",
    "main_glac_rgi_wobs = main_glac_rgi_subset.dropna(subset=['mb_fn']).copy()\n",
    "# print('subset wdata length:', main_glac_rgi_wobs.shape)\n",
    "main_glac_rgi_wobs.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Update the latlon unique pickle files\n",
    "latlon_nearidx_unique = sorted(list(set(main_glac_rgi_wobs['latlon_nearidx'].values)))\n",
    "latlon_unique_dict = dict(zip(latlon_nearidx_unique,np.arange(0,len(latlon_nearidx_unique))))\n",
    "latlon_unique_dict_reversed = dict(zip(np.arange(0,len(latlon_nearidx_unique)),latlon_nearidx_unique))\n",
    "main_glac_rgi_wobs['latlon_unique_no'] = main_glac_rgi_wobs['latlon_nearidx'].map(latlon_unique_dict)\n",
    "\n",
    "print('unique lat/lons:', len(np.unique(main_glac_rgi_wobs['latlon_unique_no'])), '\\n\\n')\n",
    "\n",
    "lat_list = np.array([ds.latitude[x[0]].values for x in latlon_nearidx_unique])\n",
    "lon_list = np.array([ds.longitude[x[1]].values for x in latlon_nearidx_unique])\n",
    "latlon_list = list(tuple(zip(list(lat_list), list(lon_list))))\n",
    "\n",
    "# Pickle unique lat/lons that will be used for melt model\n",
    "with open(debris_prms.latlon_unique_fp + debris_prms.latlon_unique_dict[debris_prms.roi], 'wb') as f:\n",
    "    pickle.dump(latlon_list, f)\n",
    "    \n",
    "main_glac_rgi_wobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('DELETE ME - HACK FOR DEVELOPMENT')\n",
    "# print(np.where(main_glac_rgi_wobs['latlon_unique_no'] == 172)[0])\n",
    "# main_glac_rgi_wobs = main_glac_rgi_wobs.loc[372:373,:]\n",
    "# main_glac_rgi_wobs['mb_fn'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGI60-11.00002 RGI60-11.00002\n",
      "RGI60-11.00054 RGI60-11.00054\n",
      "RGI60-11.00068 RGI60-11.00068\n",
      "RGI60-11.00110 RGI60-11.00110\n",
      "RGI60-11.00047 RGI60-11.00047\n",
      "RGI60-11.00719 RGI60-11.00719\n",
      "RGI60-11.00487 RGI60-11.00487\n",
      "RGI60-11.00376 RGI60-11.00376\n",
      "RGI60-11.00541 RGI60-11.00541\n",
      "RGI60-11.00597 RGI60-11.00597\n",
      "RGI60-11.00415 RGI60-11.00415\n",
      "RGI60-11.00459 RGI60-11.00459\n",
      "RGI60-11.00469 RGI60-11.00469\n",
      "RGI60-11.00524 RGI60-11.00524\n",
      "RGI60-11.00116 RGI60-11.00116\n",
      "RGI60-11.00141 RGI60-11.00141\n",
      "RGI60-11.00233 RGI60-11.00233\n",
      "RGI60-11.00278 RGI60-11.00278\n",
      "RGI60-11.00135 RGI60-11.00135\n",
      "RGI60-11.00190 RGI60-11.00190\n",
      "RGI60-11.00199 RGI60-11.00199\n",
      "RGI60-11.00106 RGI60-11.00106\n",
      "RGI60-11.00830 RGI60-11.00830\n",
      "RGI60-11.01144 RGI60-11.01144\n",
      "RGI60-11.01187 RGI60-11.01187\n",
      "RGI60-11.01193 RGI60-11.01193\n",
      "RGI60-11.01246 RGI60-11.01246\n",
      "RGI60-11.00918 RGI60-11.00918\n",
      "RGI60-11.00932 RGI60-11.00932\n",
      "RGI60-11.00797 RGI60-11.00797\n",
      "RGI60-11.00781 RGI60-11.00781\n",
      "RGI60-11.00846 RGI60-11.00846\n",
      "RGI60-11.00897 RGI60-11.00897\n",
      "RGI60-11.00943 RGI60-11.00943\n",
      "RGI60-11.00950 RGI60-11.00950\n",
      "RGI60-11.00957 RGI60-11.00957\n",
      "RGI60-11.00871 RGI60-11.00871\n",
      "RGI60-11.00886 RGI60-11.00886\n",
      "RGI60-11.00887 RGI60-11.00887\n",
      "RGI60-11.00929 RGI60-11.00929\n",
      "RGI60-11.00945 RGI60-11.00945\n",
      "RGI60-11.00958 RGI60-11.00958\n",
      "RGI60-11.01990 RGI60-11.01990\n",
      "RGI60-11.01621 RGI60-11.01621\n",
      "RGI60-11.01622 RGI60-11.01622\n",
      "RGI60-11.01678 RGI60-11.01678\n",
      "RGI60-11.01791 RGI60-11.01791\n",
      "RGI60-11.02006 RGI60-11.02006\n",
      "RGI60-11.01346 RGI60-11.01346\n",
      "RGI60-11.01450 RGI60-11.01450\n",
      "RGI60-11.01478 RGI60-11.01478\n",
      "RGI60-11.01550 RGI60-11.01550\n",
      "RGI60-11.01698 RGI60-11.01698\n",
      "RGI60-11.01719 RGI60-11.01719\n",
      "RGI60-11.01797 RGI60-11.01797\n",
      "RGI60-11.01827 RGI60-11.01827\n",
      "RGI60-11.01912 RGI60-11.01912\n",
      "RGI60-11.01275 RGI60-11.01275\n",
      "RGI60-11.01328 RGI60-11.01328\n",
      "RGI60-11.01509 RGI60-11.01509\n",
      "RGI60-11.01576 RGI60-11.01576\n",
      "RGI60-11.01876 RGI60-11.01876\n",
      "RGI60-11.02064 RGI60-11.02064\n",
      "RGI60-11.01296 RGI60-11.01296\n",
      "RGI60-11.01987 RGI60-11.01987\n",
      "RGI60-11.01946 RGI60-11.01946\n",
      "RGI60-11.02051 RGI60-11.02051\n",
      "RGI60-11.01604 RGI60-11.01604\n",
      "RGI60-11.01776 RGI60-11.01776\n",
      "RGI60-11.01974 RGI60-11.01974\n",
      "RGI60-11.01806 RGI60-11.01806\n",
      "RGI60-11.01834 RGI60-11.01834\n",
      "RGI60-11.02249 RGI60-11.02249\n",
      "RGI60-11.02495 RGI60-11.02495\n",
      "RGI60-11.02507 RGI60-11.02507\n",
      "RGI60-11.02385 RGI60-11.02385\n",
      "RGI60-11.02119 RGI60-11.02119\n",
      "RGI60-11.02222 RGI60-11.02222\n",
      "RGI60-11.02245 RGI60-11.02245\n",
      "RGI60-11.02285 RGI60-11.02285\n",
      "RGI60-11.02337 RGI60-11.02337\n",
      "RGI60-11.02351 RGI60-11.02351\n",
      "RGI60-11.02173 RGI60-11.02173\n",
      "RGI60-11.02427 RGI60-11.02427\n",
      "RGI60-11.02460 RGI60-11.02460\n",
      "RGI60-11.02515 RGI60-11.02515\n",
      "RGI60-11.02793 RGI60-11.02793\n",
      "RGI60-11.02884 RGI60-11.02884\n",
      "RGI60-11.03466 RGI60-11.03466\n",
      "RGI60-11.03638 RGI60-11.03638\n",
      "RGI60-11.03642 RGI60-11.03642\n",
      "RGI60-11.03643 RGI60-11.03643\n",
      "RGI60-11.03698 RGI60-11.03698\n",
      "RGI60-11.02866 RGI60-11.02866\n",
      "RGI60-11.02890 RGI60-11.02890\n",
      "RGI60-11.02584 RGI60-11.02584\n",
      "RGI60-11.02709 RGI60-11.02709\n",
      "RGI60-11.02715 RGI60-11.02715\n",
      "RGI60-11.02749 RGI60-11.02749\n",
      "RGI60-11.02755 RGI60-11.02755\n",
      "RGI60-11.02787 RGI60-11.02787\n",
      "RGI60-11.02796 RGI60-11.02796\n",
      "RGI60-11.02801 RGI60-11.02801\n",
      "RGI60-11.02810 RGI60-11.02810\n",
      "RGI60-11.02843 RGI60-11.02843\n",
      "RGI60-11.02558 RGI60-11.02558\n",
      "RGI60-11.02593 RGI60-11.02593\n",
      "RGI60-11.02630 RGI60-11.02630\n",
      "RGI60-11.02645 RGI60-11.02645\n",
      "RGI60-11.02676 RGI60-11.02676\n",
      "RGI60-11.02737 RGI60-11.02737\n",
      "RGI60-11.02739 RGI60-11.02739\n",
      "RGI60-11.02819 RGI60-11.02819\n",
      "RGI60-11.02822 RGI60-11.02822\n",
      "RGI60-11.02902 RGI60-11.02902\n",
      "RGI60-11.02922 RGI60-11.02922\n",
      "RGI60-11.02596 RGI60-11.02596\n",
      "RGI60-11.02624 RGI60-11.02624\n",
      "RGI60-11.02746 RGI60-11.02746\n",
      "RGI60-11.02764 RGI60-11.02764\n",
      "RGI60-11.02858 RGI60-11.02858\n",
      "RGI60-11.03005 RGI60-11.03005\n",
      "RGI60-11.03020 RGI60-11.03020\n",
      "RGI60-11.03648 RGI60-11.03648\n",
      "RGI60-11.03651 RGI60-11.03651\n",
      "RGI60-11.03001 RGI60-11.03001\n",
      "RGI60-11.03039 RGI60-11.03039\n",
      "RGI60-11.03124 RGI60-11.03124\n",
      "RGI60-11.03147 RGI60-11.03147\n",
      "RGI60-11.03556 RGI60-11.03556\n",
      "RGI60-11.03662 RGI60-11.03662\n",
      "RGI60-11.03114 RGI60-11.03114\n",
      "RGI60-11.03674 RGI60-11.03674\n",
      "RGI60-11.03760 RGI60-11.03760\n",
      "RGI60-11.03672 RGI60-11.03672\n",
      "RGI60-11.03427 RGI60-11.03427\n",
      "RGI60-11.03546 RGI60-11.03546\n",
      "RGI60-11.03667 RGI60-11.03667\n",
      "RGI60-11.03671 RGI60-11.03671\n",
      "RGI60-11.03182 RGI60-11.03182\n",
      "RGI60-11.03655 RGI60-11.03655\n",
      "RGI60-11.03740 RGI60-11.03740\n",
      "RGI60-11.03373 RGI60-11.03373\n",
      "RGI60-11.03701 RGI60-11.03701\n",
      "RGI60-11.03675 RGI60-11.03675\n",
      "RGI60-11.03676 RGI60-11.03676\n",
      "RGI60-11.03683 RGI60-11.03683\n",
      "RGI60-11.03264 RGI60-11.03264\n",
      "RGI60-11.03308 RGI60-11.03308\n",
      "RGI60-11.03687 RGI60-11.03687\n",
      "unique lat/lons updated: 47\n"
     ]
    }
   ],
   "source": [
    "# ===== DEBRIS ELEVATION STATS ====================================================================================\n",
    "# CALCULATE DEBRIS ELEVATION STATS FOR GLACIERS WITH DATA FOR EACH UNIQUE LAT/LON\n",
    "elev_stats_latlon_dict = {}\n",
    "latlon_list_updated = []\n",
    "rgiid_4cal = []\n",
    "for nlatlon, latlon_unique in enumerate(np.unique(main_glac_rgi_wobs.latlon_unique_no)):\n",
    "# for nlatlon, latlon_unique in enumerate([np.unique(main_glac_rgi_wobs.latlon_unique_no)[0]]):\n",
    "\n",
    "    main_glac_rgi_subset = main_glac_rgi_wobs[main_glac_rgi_wobs['latlon_unique_no'] == latlon_unique]\n",
    "    main_glac_rgi_subset.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Debris elevation stats should be done by lat/lon\n",
    "    df_all = None\n",
    "    elev_list_all = []\n",
    "    df_idx_count = 0\n",
    "    count_width_passes = 0\n",
    "    for nglac, glac_fn in enumerate(main_glac_rgi_subset.mb_fn.values):\n",
    "#     for nglac, glac_fn in enumerate([main_glac_rgi_subset.mb_fn.values[0]]):\n",
    "\n",
    "        glac_fullfn = debris_prms.mb_binned_fp + glac_fn\n",
    "        \n",
    "        glac_str_noleadzero = glac_fullfn.split('/')[-1].split('_')[0]\n",
    "        rgiid = 'RGI60-' + glac_str_noleadzero.split('.')[0].zfill(2) + '.' + glac_str_noleadzero.split('.')[1]\n",
    "\n",
    "        print(main_glac_rgi_subset.loc[nglac,'RGIId'], rgiid)\n",
    "        \n",
    "        # Select bins that meet calibratioin criteria\n",
    "        df_raw = pd.read_csv(glac_fullfn)\n",
    "        df = df_raw.dropna(subset=['mb_bin_mean_mwea'])\n",
    "        df['z1_bin_areas_perc_cum'] = np.cumsum(df['z1_bin_area_valid_km2']) /df['z1_bin_area_valid_km2'].sum() * 100\n",
    "        # add width to bins\n",
    "        widths_fp = debris_prms.oggm_fp + 'widths/' + 'RGI60-' + rgiid.split('-')[1].split('.')[0] + '/'\n",
    "        widths_fn = rgiid + '_widths_m.csv'\n",
    "        try:\n",
    "            # Add width to each elevation bin\n",
    "            widths_df = pd.read_csv(widths_fp + widths_fn)\n",
    "            elev_nearidx = (np.abs(df['bin_center_elev_m'].values[:,np.newaxis] - \n",
    "                                   widths_df['elev'].values).argmin(axis=1))\n",
    "            df['width_m'] = widths_df.loc[elev_nearidx,'width_m'].values\n",
    "        except:\n",
    "            df['width_m'] = 0\n",
    "        \n",
    "        df_idx = np.where((df['vm_med'] <= debris_prms.vel_threshold) \n",
    "                          & (df['width_m'] >= debris_prms.width_min_dict[debris_prms.roi])\n",
    "                          & (df['dc_bin_area_perc'] >= debris_prms.debrisperc_threshold)\n",
    "                          & (df['dc_bin_count_valid'] >= 10)\n",
    "                          & (df['z1_bin_areas_perc_cum'] <= debris_prms.term_area_perc)\n",
    "                          )[0]\n",
    "        df_debris = df.loc[df_idx,:]\n",
    "        df_debris.reset_index(inplace=True, drop=True)\n",
    "        df_idx_count += len(df_idx)\n",
    "        \n",
    "            \n",
    "        if len(df_idx) > 0:\n",
    "            for nelev, elev in enumerate(list(df_debris['bin_center_elev_m'].values)):\n",
    "                elev_list_single = list(np.repeat(elev, df_debris.loc[nelev,'dc_bin_count_valid']))\n",
    "                elev_list_all.extend(elev_list_single)\n",
    "            \n",
    "#             # only work with terminus\n",
    "#             df_idx_dif = list(df_idx[1:] - df_idx[:-1])\n",
    "#             if np.sum(df_idx_dif) == len(df_idx)-1:\n",
    "#                 df_idx_nojump = df_idx\n",
    "#             else:\n",
    "#                 idx_jumpinbins = df_idx_dif.index(next(filter(lambda x: x>1, df_idx_dif)))\n",
    "#                 df_idx_nojump = df_idx[0:idx_jumpinbins+1]\n",
    "#             df_debris_nojump = df_debris.loc[df_idx_nojump,:]\n",
    "#             df_debris_nojump.reset_index(inplace=True, drop=True)\n",
    "#             # Median width to ensure terminus velocities can be estimated\n",
    "#             width_median = np.median(widths_m[np.where(h < df_debris_nojump['bin_center_elev_m'].max())[0]])\n",
    "#             if width_median > debris_prms.width_min_dict[debris_prms.roi]:\n",
    "#                 for nelev, elev in enumerate(list(df_debris_nojump['bin_center_elev_m'].values)):\n",
    "#                     elev_list_single = list(np.repeat(elev, df_debris_nojump.loc[nelev,'dc_bin_count_valid']))\n",
    "#                     elev_list_all.extend(elev_list_single)\n",
    "#                 count_width_passes += 1\n",
    "    \n",
    "            rgiid_4cal.append(rgiid.split('-')[1])\n",
    "        \n",
    "    if df_idx_count > 0:\n",
    "        dc_zmean = np.mean(elev_list_all)\n",
    "        dc_zstd = np.std(elev_list_all)\n",
    "        dc_zmed = malib.fast_median(elev_list_all)\n",
    "        dc_zmad = malib.mad(elev_list_all)\n",
    "        \n",
    "        lat_deg = float(ds.latitude[latlon_unique_dict_reversed[latlon_unique][0]].values)\n",
    "        lon_deg = float(ds.longitude[latlon_unique_dict_reversed[latlon_unique][1]].values)\n",
    "        elev_stats_latlon_dict[lat_deg,lon_deg] = [dc_zmean, dc_zstd, dc_zmed, dc_zmad]\n",
    "        latlon_list_updated.append((lat_deg, lon_deg))\n",
    "        \n",
    "print('unique lat/lons updated:', len(latlon_list_updated))\n",
    "# Update pickle of unique lat/lons that will be used for melt model\n",
    "with open(debris_prms.latlon_unique_fp + debris_prms.latlon_unique_dict[debris_prms.roi], 'wb') as f:\n",
    "    pickle.dump(latlon_list_updated, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 glaciers in region 11 are included in this model run: ['00002', '00047', '00054', '00068', '00106', '00110', '00116', '00135', '00141', '00190', '00199', '00233', '00278', '00376', '00459', '00469', '00487', '00524', '00541', '00597', '00719', '00781', '00797', '00830', '00846', '00871', '00886', '00887', '00897', '00918', '00929', '00932', '00943', '00945', '00950', '00957', '00958', '01144', '01187', '01193', '01246', '01275', '01296', '01328', '01346', '01450', '01478', '01509', '01550', '01604'] and more\n",
      "This study is focusing on 147 glaciers in region [11]\n",
      "\n",
      "DC glaciers (used for cal): 147 DC Area (used for cal, km2): 122.84179\n"
     ]
    }
   ],
   "source": [
    "# Statistics of data coverage\n",
    "rgiid_4cal = sorted(rgiid_4cal)\n",
    "main_glac_rgi_4cal = debris_prms.selectglaciersrgitable(rgiid_4cal)\n",
    "dc_area_dict = dict(zip(dc_shp.RGIId.values, dc_shp.DC_Area_v2.values))\n",
    "main_glac_rgi_4cal['DC_Area_v2'] = main_glac_rgi_4cal.RGIId.map(dc_area_dict)\n",
    "print('\\nDC glaciers (used for cal):', main_glac_rgi_4cal.shape[0], \n",
    "      'DC Area (used for cal, km2):', main_glac_rgi_4cal.DC_Area_v2.sum() / 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -43.25 170.75\n",
      "  existed: 1233.2008567348882 vs 1157.875226039783\n",
      "1 -43.25 171.0\n",
      "  existed: 1180.7060755336618 vs 1192.5833333333333\n",
      "2 -43.5 170.0\n",
      "  existed: 827.355871886121 vs 827.355871886121\n",
      "3 -43.5 170.25\n",
      "  existed: 1041.164316966456 vs 1041.164316966456\n",
      "4 -43.5 170.5\n",
      "  existed: 1122.3825991991264 vs 1122.3825991991264\n",
      "5 -43.75 170.0\n",
      "  existed: 1069.362657091562 vs 1069.362657091562\n",
      "6 -44.0 169.5\n",
      "  existed: 1670.0393700787401 vs 1670.0393700787401\n",
      "7 -44.5 168.25\n",
      "  existed: 1026.4147130153597 vs 1026.4147130153597\n",
      "8 -44.5 168.5\n",
      "  existed: 1297.0892575039495 vs 1297.0892575039495\n",
      "9 -44.5 168.75\n",
      "  existed: 1389.0 vs 1389.0\n"
     ]
    }
   ],
   "source": [
    "# ===== ADD DEBRIS ELEVATION STATS TO MET DATA ======\n",
    "overwrite_dc_stats = True\n",
    "for nlatlon, latlon in enumerate(latlon_list_updated):\n",
    "# for nlatlon, latlon in enumerate([latlon_list_updated[0]]):\n",
    "    \n",
    "    lat_deg = latlon[0]\n",
    "    lon_deg = latlon[1]\n",
    "    \n",
    "    print(nlatlon, lat_deg, lon_deg)\n",
    "    \n",
    "    if lat_deg < 0:\n",
    "        lat_str = 'S-'\n",
    "    else:\n",
    "        lat_str = 'N-' \n",
    "\n",
    "    # ===== Meteorological data =====\n",
    "    metdata_fn = debris_prms.metdata_fn_sample.replace(\n",
    "        'XXXX', str(int(np.abs(lat_deg)*100)) + lat_str + str(int(lon_deg*100)) + 'E-')\n",
    "    \n",
    "    ds = xr.open_dataset(debris_prms.metdata_fp + metdata_fn) \n",
    "    try:\n",
    "        print('  existed:', ds.dc_zmean.values, 'vs', elev_stats_latlon_dict[latlon][0])\n",
    "    except:\n",
    "        pass\n",
    "    if 'dc_zmean' not in list(ds.keys()) or overwrite_dc_stats:\n",
    "        # Add stats\n",
    "        ds['dc_zmean'] = elev_stats_latlon_dict[latlon][0]\n",
    "        ds['dc_zmean'].attrs = {'units':'m a.s.l.', 'long_name':'Mean debris cover elevation', \n",
    "                                'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "        ds['dc_zstd'] = elev_stats_latlon_dict[latlon][1]\n",
    "        ds['dc_zstd'].attrs = {'units':'m a.s.l.', 'long_name':'Standard deviation of debris cover elevation', \n",
    "                               'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "        ds['dc_zmed'] = elev_stats_latlon_dict[latlon][2]\n",
    "        ds['dc_zmed'].attrs = {'units':'m a.s.l.', 'long_name':'Median debris cover elevation', \n",
    "                               'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "        ds['dc_zmad'] = elev_stats_latlon_dict[latlon][3]\n",
    "        ds['dc_zmad'].attrs = {'units':'m a.s.l.', 'long_name':'Median absolute deviation of debris cover elevation', \n",
    "                               'comment':'converted from debris cover with data that will be used for subdebris melt inversion'}\n",
    "\n",
    "        try:\n",
    "            ds.close()\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        # Export updated dataset\n",
    "        ds.to_netcdf(debris_prms.metdata_fp + metdata_fn, mode='a')\n",
    "    else:\n",
    "        print(lat_deg, lon_deg, 'exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== OLD FILE OF LOADIING MULTIPLE DATASETS =====\n",
    "# # ===== LOAD GLACIERS WITH LARSEN DATA =====\n",
    "# dc_shp_subset['larsen_fullfn'] = np.nan\n",
    "# larsen_fullfn_dict = {}\n",
    "# if 'larsen' in input.mb_datasets:\n",
    "#     mb_summary = pd.read_csv(input.larsen_fp + input.larsen_fn)\n",
    "    \n",
    "#     # Find glaciers that are debris-covered\n",
    "#     larsen_dc_rgiid = [value for value in list(mb_summary.RGIId.values) \n",
    "#                        if value in list(dc_shp_subset.RGIId.values)]\n",
    "\n",
    "#     mb_summary_dc = mb_summary[mb_summary['RGIId'].isin(larsen_dc_rgiid)]\n",
    "#     mb_summary_dc = mb_summary_dc.sort_values('RGIId')\n",
    "#     mb_summary_dc.reset_index(inplace=True, drop=True)\n",
    "#     mb_summary_dc.loc[mb_summary_dc['name'] == 'Maclaren', 'name'] = 'MacLaren'\n",
    "#     mb_summary_dc.loc[mb_summary_dc['name'] == 'Tlikakila Fork', 'name'] = 'TlikakilaGlacierFork'\n",
    "#     mb_summary_dc.loc[mb_summary_dc['name'] == 'Tlikakila N. Fork', 'name'] = 'TlikakilaNorthFork'\n",
    "#     mb_summary_dc['larsen_fullfn'] = np.nan\n",
    "    \n",
    "#     for n, glac_name in enumerate(mb_summary_dc.name.values):\n",
    "# #     for n, glac_name in enumerate([mb_summary_dc.name.values[47]]):\n",
    "# #         print(n, glac_name)\n",
    "            \n",
    "#         glac_name = glac_name.replace(' ', '')\n",
    "#         glac_fns = []\n",
    "#         start_yr = []\n",
    "#         end_yr = []\n",
    "#         for i in os.listdir(input.larsen_binned_fp):\n",
    "#             if i.startswith(glac_name):\n",
    "#                 glac_fns.append(i)\n",
    "#                 start_yr.append(i.split('.')[1][0:4])\n",
    "#                 end_yr.append(i.split('.')[2][0:4])\n",
    "                \n",
    "#         if len(glac_fns) > 0:\n",
    "#             yr_dif = np.array(end_yr).astype(int) - np.array(start_yr).astype(int)\n",
    "#             mb_fn = glac_fns[np.where(yr_dif == yr_dif.max())[0][0]]\n",
    "            \n",
    "#             # ===== Process Larsen dataset =====\n",
    "#             larsen_data_raw = np.genfromtxt(input.larsen_binned_fp + mb_fn, skip_header=3)\n",
    "#             larsen_data_header = ['E', 'DZ', 'DZ25', 'DZ75', 'AAD', 'MassChange', 'MassBal', 'NumData']\n",
    "#             larsen_data = pd.DataFrame(larsen_data_raw, columns=larsen_data_header)\n",
    "#             larsen_data['std from DZ25'] = np.absolute(larsen_data['DZ'] - larsen_data['DZ25']) / 0.67\n",
    "#             larsen_data['std from DZ75'] = np.absolute(larsen_data['DZ'] - larsen_data['DZ75']) / 0.67\n",
    "#             larsen_data[' dhdt_bin_std_ma'] = (larsen_data['std from DZ25'] + larsen_data['std from DZ75']) / 2\n",
    "#             larsen_data[' mb_bin_std_mwea'] = larsen_data[' dhdt_bin_std_ma'] * 900 / 1000\n",
    "#             larsen_data['AAD'] = larsen_data['AAD'] / 1e6\n",
    "#             larsen_data['startyear'] = int(mb_fn.split('.')[1][0:4])\n",
    "#             larsen_data['endyear'] = int(mb_fn.split('.')[2][0:4])\n",
    "#             larsen_data = larsen_data.rename({'E': '# bin_center_elev_m',\n",
    "#                                               'DZ': ' dhdt_bin_mean_ma',\n",
    "#                                               'MassBal': ' mb_bin_mean_mwea',\n",
    "#                                               'AAD': ' z1_bin_area_valid_km2',\n",
    "#                                              }, axis='columns')\n",
    "#             new_fn = mb_summary_dc.loc[n,'RGIId'].split('-')[1][1:] + '_larsen_mb_bins.csv'\n",
    "#             larsen_data.to_csv(input.larsen_binned_fp + new_fn, index=False)\n",
    "            \n",
    "#             mb_summary_dc.loc[n, 'larsen_fullfn'] = input.larsen_binned_fp + new_fn\n",
    "            \n",
    "#         else:\n",
    "#             print(n, glac_name, 'has no file\\n')\n",
    "\n",
    "#     mb_summary_dc.dropna(subset=['larsen_fullfn'], inplace=True)\n",
    "#     mb_summary_dc.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "#     print('Larsen debris-covered glaciers:', mb_summary_dc.shape[0], '\\n\\n')\n",
    "    \n",
    "#     larsen_fullfn_dict = dict(zip(mb_summary_dc['RGIId'].values, mb_summary_dc['larsen_fullfn'].values))\n",
    "# #     print(larsen_fullfn_dict)\n",
    "#     dc_shp_subset['larsen_fullfn'] = dc_shp_subset.RGIId.map(larsen_fullfn_dict)\n",
    "\n",
    "# # ===== LOAD GLACIERS WITH BRAUN DATA =====\n",
    "# dc_shp_subset['braun_fullfn'] = np.nan\n",
    "# braun_fullfn_dict = {}\n",
    "# if 'braun' in input.mb_datasets:\n",
    "#     mb_binned_fp = input.main_directory + '/../mb_data/Braun/binned_data/'\n",
    "# #     mb_binned_fp = input.mb_binned_fp\n",
    "    \n",
    "#     mb_fns = []\n",
    "#     braun_rgiids = []\n",
    "#     for i in os.listdir(mb_binned_fp):\n",
    "#         if i.endswith('_mb_bins.csv'):\n",
    "#             mb_fns.append(mb_binned_fp + i)\n",
    "#             rgiid_raw = i.split('_')[0]\n",
    "#             rgiid = 'RGI60-' + rgiid_raw.split('.')[0].zfill(2) + '.' + rgiid_raw.split('.')[1]\n",
    "#             braun_rgiids.append(rgiid)\n",
    "#     braun_fn_df = pd.DataFrame(np.zeros((len(mb_fns),2)), columns=['RGIId', 'braun_fn'])\n",
    "#     braun_fn_df['RGIId'] = braun_rgiids\n",
    "#     braun_fn_df['braun_fullfn'] = mb_fns\n",
    "    \n",
    "#     # Find glaciers that are debris-covered\n",
    "#     braun_dc_rgiid = [value for value in list(braun_fn_df.RGIId.values) \n",
    "#                        if value in list(dc_shp_subset.RGIId.values)]\n",
    "#     braun_fn_df_dc = braun_fn_df[braun_fn_df['RGIId'].isin(braun_dc_rgiid)]\n",
    "#     braun_fn_df_dc = braun_fn_df_dc.sort_values('RGIId')\n",
    "    \n",
    "#     print('Braun debris-covered glaciers:', braun_fn_df_dc.shape[0], '\\n\\n')\n",
    "    \n",
    "#     braun_fullfn_dict = dict(zip(braun_fn_df_dc['RGIId'].values, braun_fn_df_dc['braun_fullfn'].values))\n",
    "    \n",
    "#     dc_shp_subset['braun_fullfn'] = dc_shp_subset.RGIId.map(braun_fullfn_dict)\n",
    "\n",
    "# # ===== LOAD GLACIERS WITH SHEAN DATA =====\n",
    "# dc_shp_subset['shean_fullfn'] = np.nan\n",
    "# shean_fullfn_dict = {}\n",
    "# if 'shean' in input.mb_datasets:\n",
    "# #     mb_binned_fp = input.main_directory + '/../mb_data/Shean_2019_0213/mb_combined_20190213_nmad_bins/'\n",
    "#     mb_binned_fp = input.mb_binned_fp\n",
    "    \n",
    "#     mb_fns = []\n",
    "#     rgiids = []\n",
    "#     for i in os.listdir(mb_binned_fp):\n",
    "#         if i.endswith('_mb_bins.csv'):\n",
    "#             mb_fns.append(mb_binned_fp + i)\n",
    "#             rgiid_raw = i.split('_')[0]\n",
    "#             rgiid = 'RGI60-' + rgiid_raw.split('.')[0].zfill(2) + '.' + rgiid_raw.split('.')[1]\n",
    "#             rgiids.append(rgiid)\n",
    "#     mb_fn_df = pd.DataFrame(np.zeros((len(mb_fns),2)), columns=['RGIId', 'mb_fn'])\n",
    "#     mb_fn_df['RGIId'] = rgiids\n",
    "#     mb_fn_df['mb_fullfn'] = mb_fns\n",
    "    \n",
    "#     # Find glaciers that are debris-covered\n",
    "#     mb_dc_rgiid = [value for value in list(mb_fn_df.RGIId.values) \n",
    "#                    if value in list(dc_shp_subset.RGIId.values)]\n",
    "#     mb_fn_df_dc = mb_fn_df[mb_fn_df['RGIId'].isin(mb_dc_rgiid)]\n",
    "#     mb_fn_df_dc = mb_fn_df_dc.sort_values('RGIId')\n",
    "    \n",
    "#     print('shean debris-covered glaciers:', mb_fn_df_dc.shape[0], '\\n\\n')\n",
    "    \n",
    "#     shean_fullfn_dict = dict(zip(mb_fn_df_dc['RGIId'].values, mb_fn_df_dc['mb_fullfn'].values))\n",
    "# #     print(shea_fullfn_dict)\n",
    "#     dc_shp_subset['shean_fullfn'] = dc_shp_subset.RGIId.map(shean_fullfn_dict)\n",
    "\n",
    "# # Merge dictionaries together\n",
    "# mb_fn_dict = dict(list(larsen_fullfn_dict.items()) + list(braun_fullfn_dict.items()) + \n",
    "#                   list(shean_fullfn_dict.items()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debris_thickness_global]",
   "language": "python",
   "name": "conda-env-debris_thickness_global-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
