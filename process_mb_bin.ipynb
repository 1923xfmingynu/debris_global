{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate a 3-panel plot for input arrays\n",
    "def plot_array(dem, clim=None, titles=None, cmap='inferno', label=None, overlay=None, fn=None, close_fig=True):\n",
    "    fig, ax = plt.subplots(1,1, sharex=True, sharey=True, figsize=(10,5))\n",
    "    alpha = 1.0\n",
    "    #Gray background\n",
    "    ax.set_facecolor('0.5')\n",
    "    #Force aspect ratio to match images\n",
    "    ax.set(aspect='equal')\n",
    "    #Turn off axes labels/ticks\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if titles is not None:\n",
    "        ax.set_title(titles[0])\n",
    "    #Plot background shaded relief map\n",
    "    if overlay is not None:\n",
    "        alpha = 0.7\n",
    "        ax.imshow(overlay, cmap='gray', clim=(1,255))\n",
    "    #Plot each array\n",
    "    im_list = [ax.imshow(dem, clim=clim, cmap=cmap, alpha=alpha)]\n",
    "    fig.tight_layout()\n",
    "    fig.colorbar(im_list[0], label=label, extend='both', shrink=0.5)\n",
    "    if fn is not None:\n",
    "        fig.savefig(fn, bbox_inches='tight', pad_inches=0, dpi=150)\n",
    "    if close_fig:\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "def nearest_nonzero_idx(a,x,y):\n",
    "    r,c = np.nonzero(a)\n",
    "    min_idx = ((r - x)**2 + (c - y)**2).argmin()\n",
    "    return r[min_idx], c[min_idx]\n",
    "\n",
    "\n",
    "def maskedarray_gt(data, value):\n",
    "    \"\"\" Greater than operation on masked array to avoid warning errors \"\"\"\n",
    "    data = np.nan_to_num(data,0)\n",
    "    data[data > value] = value\n",
    "    return data\n",
    "\n",
    "\n",
    "def maskedarray_lt(data, value):\n",
    "    \"\"\" Less than operation on masked array to avoid warning errors \"\"\"\n",
    "    data = np.nan_to_num(data,0)\n",
    "    data[data < value] = value\n",
    "    return data\n",
    "\n",
    "\n",
    "def ts_fromdebris_func(h, a, b, c):\n",
    "        \"\"\" estimate surface temperature from debris thickness (h is debris thickness, a and k are coefficients) \n",
    "        Hill Equation\"\"\"\n",
    "        return a * h**c / (b**c + h**c)\n",
    "def debris_fromts_func(ts, a, b, c):\n",
    "    \"\"\" estimate debris thickness from surface temperature (ts is surface temperature, a and k are coefficients) \n",
    "    Hill Equation\"\"\"\n",
    "    return (ts * b**c / (a - ts))**(1/c)\n",
    "\n",
    "# def meltfactor_fromdebris_func(h, a, k, melt_2cm):\n",
    "#     \"\"\" estimate melt factor from debris thickness (h is debris thickness, a and k are coefficients) \n",
    "#     Hill equation \"\"\"\n",
    "#     melt_h = a / (1 + 2 * k * a * h)\n",
    "#     melt_factor = melt_h / melt_2cm\n",
    "#     melt_factor[melt_factor > 1] = 1\n",
    "#     return melt_factor\n",
    "\n",
    "def debris_fromts_maskedarray(ts_raw, a, b, c):\n",
    "    \"\"\" Apply debris_fromts_func to masked array\n",
    "        includes a mask of maximum values, since Michaelis-Mentin Equation has natural maximum \n",
    "    Parameters\n",
    "    ----------\n",
    "    ts_raw : np.ma.array\n",
    "        masked array of the unmodified surface temperature\n",
    "    Returns\n",
    "    -------\n",
    "    hd : np.ma.array \n",
    "        masked array of the debris thickness (m)\n",
    "    \"\"\"\n",
    "    ts = ts_raw.copy()\n",
    "    max_value = ts_fromdebris_func(50, a, b, c)\n",
    "    debris_thick_ts = np.ma.array(maskedarray_gt(ts.data, max_value), mask=np.ma.getmask(ts))\n",
    "    debris_thick_ts = np.ma.array(maskedarray_lt(ts.data, 0), mask=np.ma.getmask(ts))\n",
    "    hd = debris_fromts_func(ts.data, a, b, c)\n",
    "    return hd\n",
    "\n",
    "\n",
    "def emergence_pixels(gf, vel_x_raw, vel_y_raw, icethickness_raw, xres, yres, \n",
    "                     vel_min=0, max_velocity=600, vel_depth_avg_factor=0.8, option_border=1,\n",
    "                     positive_is_east=True, positive_is_north=True, constant_icethickness=False, debug=True):\n",
    "    \"\"\" Compute the emergence velocity using an ice flux approach\n",
    "    \"\"\"\n",
    "    # Glacier mask\n",
    "    glac_mask = np.zeros(vel_x_raw.shape) + 1\n",
    "    glac_mask[gf.z1.mask] = 0\n",
    "    \n",
    "    # Replace nan with 0\n",
    "    vel_x_raw = np.nan_to_num(vel_x_raw,0)\n",
    "    vel_y_raw = np.nan_to_num(vel_y_raw,0)\n",
    "    \n",
    "    # Modify vel_y by multiplying velocity by -1 such that matrix operations agree with flow direction\n",
    "    #    Specifically, a negative y velocity means the pixel is flowing south.\n",
    "    #    However, if you were to subtract that value from the rows, it would head north in the matrix.\n",
    "    #    This is due to the fact that the number of rows start at 0 at the top.\n",
    "    #    Therefore, multipylying by -1 aligns the matrix operations with the flow direction\n",
    "    if positive_is_north:\n",
    "        vel_y = -1*vel_y_raw * vel_depth_avg_factor\n",
    "    else:\n",
    "        vel_y = vel_y_raw * vel_depth_avg_factor\n",
    "    if positive_is_east:\n",
    "        vel_x = vel_x_raw * vel_depth_avg_factor\n",
    "    else:\n",
    "        vel_x = -1*vel_x_raw * vel_depth_avg_factor\n",
    "    vel_total = (vel_y**2 + vel_x**2)**0.5\n",
    "    # Ice thickness\n",
    "    icethickness = icethickness_raw.copy()\n",
    "    if constant_icethickness:\n",
    "        icethickness[:,:] = 1\n",
    "        icethickness = icethickness * glac_mask\n",
    "#     print('mean ice thickness:', np.round(icethickness.mean(),0), 'm')\n",
    "    # Compute the initial volume\n",
    "    volume_initial = icethickness * (xres * yres)\n",
    "    pix_maxres = xres\n",
    "    if yres > pix_maxres:\n",
    "        pix_maxres = yres\n",
    "    # Quality control options:\n",
    "    # Apply a border based on the max specified velocity to prevent errors associated with pixels going out of bounds\n",
    "    if option_border == 1:\n",
    "        border = int(max_velocity / pix_maxres) + 1\n",
    "        for r in range(vel_x.shape[0]):\n",
    "            for c in range(vel_x.shape[1]):\n",
    "                if (r < border) | (r >= vel_x.shape[0] - border) | (c < border) | (c >= vel_x.shape[1] - border):\n",
    "                    vel_x[r,c] = 0\n",
    "                    vel_y[r,c] = 0\n",
    "    # Minimum/maximum velocity bounds\n",
    "    vel_x[vel_total < vel_min] = 0\n",
    "    vel_y[vel_total < vel_min] = 0\n",
    "    vel_x[vel_total > max_velocity] = 0\n",
    "    vel_y[vel_total > max_velocity] = 0\n",
    "#     # Remove clusters of high velocity on stagnant portions of glaciers due to feature tracking of cliffs and ponds\n",
    "#     if option_stagnantbands == 1:\n",
    "#         vel_x[bands <= stagnant_band] = 0\n",
    "#         vel_y[bands <= stagnant_band] = 0        \n",
    "    # Compute displacement in units of pixels\n",
    "    vel_x_pix = vel_x / xres\n",
    "    vel_y_pix = vel_y / yres\n",
    "    # Compute the displacement and fraction of pixels moved for all columns (x-axis)\n",
    "    # col_x1 is the number of columns to the closest pixel receiving ice [ex. 2.6 returns 2, -2.6 returns -2]\n",
    "    #    int() automatically rounds towards zero\n",
    "    col_x1 = vel_x_pix.astype(int)\n",
    "    # col_x2 is the number of columns to the further pixel receiving ice [ex. 2.6 returns 3, -2.6 returns -3]\n",
    "    #    np.sign() returns a value of 1 or -1, so it's adding 1 pixel away from zero\n",
    "    col_x2 = (vel_x_pix + np.sign(vel_x_pix)).astype(int)\n",
    "    # rem_x2 is the fraction of the pixel that remains in the further pixel (col_x2) \n",
    "    #    [ex. 2.6 returns 0.6, -2.6 returns 0.6]\n",
    "    #    np.sign() returns a value of 1 or -1, so multiplying by that ensures you have a positive value\n",
    "    #    then when you take the remainder using \"% 1\", you obtain the desired fraction\n",
    "    rem_x2 = np.multiply(np.sign(vel_x_pix), vel_x_pix) % 1\n",
    "    # rem_x1 is the fraction of the pixel that remains in the closer pixel (col_x1) \n",
    "    #    [ex. 2.6 returns 0.4, -2.6 returns 0.4]\n",
    "    rem_x1 = 1 - rem_x2\n",
    "    # Repeat the displacement and fraction computations for all rows (y-axis)\n",
    "    row_y1 = vel_y_pix.astype(int)\n",
    "    row_y2 = (vel_y_pix + np.sign(vel_y_pix)).astype(int)\n",
    "    rem_y2 = np.multiply(np.sign(vel_y_pix), vel_y_pix) % 1\n",
    "    rem_y1 = 1 - rem_y2\n",
    "          \n",
    "    # Compute the mass flux for each pixel\n",
    "    volume_final = np.zeros(volume_initial.shape)\n",
    "    for r in range(vel_x.shape[0]):\n",
    "        for c in range(vel_x.shape[1]):\n",
    "            volume_final[r+row_y1[r,c], c+col_x1[r,c]] = (\n",
    "                volume_final[r+row_y1[r,c], c+col_x1[r,c]] + rem_y1[r,c]*rem_x1[r,c]*volume_initial[r,c]\n",
    "                )\n",
    "            volume_final[r+row_y2[r,c], c+col_x1[r,c]] = (\n",
    "                volume_final[r+row_y2[r,c], c+col_x1[r,c]] + rem_y2[r,c]*rem_x1[r,c]*volume_initial[r,c]\n",
    "                )\n",
    "            volume_final[r+row_y1[r,c], c+col_x2[r,c]] = (\n",
    "                volume_final[r+row_y1[r,c], c+col_x2[r,c]] + rem_y1[r,c]*rem_x2[r,c]*volume_initial[r,c]\n",
    "                )\n",
    "            volume_final[r+row_y2[r,c], c+col_x2[r,c]] = (\n",
    "                volume_final[r+row_y2[r,c], c+col_x2[r,c]] + rem_y2[r,c]*rem_x2[r,c]*volume_initial[r,c]\n",
    "                )\n",
    "         \n",
    "    # Redistribute off-glacier volume back onto the nearest pixel on the glacier\n",
    "    offglac_row, offglac_col = np.where((glac_mask == 0) & (volume_final > 0))\n",
    "    for nidx in range(0,len(offglac_row)):\n",
    "        nrow = offglac_row[nidx]\n",
    "        ncol = offglac_col[nidx]\n",
    "        ridx, cidx = nearest_nonzero_idx(glac_mask, nrow, ncol)\n",
    "        # Add off-glacier volume back onto nearest pixel on glacier\n",
    "        volume_final[ridx,cidx] += volume_final[nrow,ncol]\n",
    "        volume_final[nrow,ncol] = 0\n",
    "            \n",
    "    # Check that mass is conserved (threshold = 0.1 m x pixel_size**2)\n",
    "    if debug:\n",
    "        print('Mass is conserved?', np.absolute(volume_final.sum() - volume_initial.sum()) / \n",
    "              volume_initial.sum() < 0.01)\n",
    "        print(np.round(np.absolute(volume_final.sum() - volume_initial.sum()),1), \n",
    "              np.round(np.absolute(volume_final.sum() - volume_initial.sum()) / volume_initial.sum() * 100,2), '%')\n",
    "        \n",
    "    if np.absolute(volume_final.sum() - volume_initial.sum()) / volume_initial.sum() > 0.01:\n",
    "        print('MASS NOT CONSERVED FOR EMERGENCE VELOCITY')\n",
    "    # Final ice thickness\n",
    "    icethickness_final = volume_final / (xres * yres)\n",
    "    # Emergence velocity\n",
    "    emergence_velocity = icethickness_final - icethickness\n",
    "    return emergence_velocity\n",
    "\n",
    "\n",
    "\n",
    "# class GlacFeat:\n",
    "#     def __init__(self, feat, glacname_fieldname, glacnum_fieldname):\n",
    "\n",
    "#         self.glacname = feat.GetField(glacname_fieldname)\n",
    "#         if self.glacname is None:\n",
    "#             self.glacname = \"\"\n",
    "#         else:\n",
    "#             #RGI has some nonstandard characters\n",
    "#             #self.glacname = self.glacname.decode('unicode_escape').encode('ascii','ignore')\n",
    "#             #glacname = re.sub(r'[^\\x00-\\x7f]',r'', glacname)\n",
    "#             self.glacname = re.sub(r'\\W+', '', self.glacname)\n",
    "#             self.glacname = self.glacname.replace(\" \", \"\")\n",
    "#             self.glacname = self.glacname.replace(\"_\", \"\")\n",
    "#             self.glacname = self.glacname.replace(\"/\", \"\")\n",
    "\n",
    "#         self.glacnum = feat.GetField(glacnum_fieldname)\n",
    "#         fn = feat.GetDefnRef().GetName()\n",
    "#         #RGIId (String) = RGI50-01.00004\n",
    "#         self.glacnum = '%0.5f' % float(self.glacnum.split('-')[-1])\n",
    "\n",
    "#         if self.glacname:\n",
    "#             self.feat_fn = \"%s_%s\" % (self.glacnum, self.glacname)\n",
    "#         else:\n",
    "#             self.feat_fn = str(self.glacnum)\n",
    "\n",
    "#         self.glac_geom_orig = geolib.geom_dup(feat.GetGeometryRef())\n",
    "#         self.glac_geom = geolib.geom_dup(self.glac_geom_orig)\n",
    "#         #Hack to deal with fact that this is not preserved in geom when loaded from pickle on disk\n",
    "#         self.glac_geom_srs_wkt = self.glac_geom.GetSpatialReference().ExportToWkt()\n",
    "\n",
    "#         #Attributes written by mb_calc\n",
    "#         self.z1 = None\n",
    "#         self.z1_hs = None\n",
    "#         self.z1_stats = None\n",
    "#         self.z1_ela = None\n",
    "#         self.z2 = None\n",
    "#         self.z2_hs = None\n",
    "#         self.z2_stats = None\n",
    "#         self.z2_ela = None\n",
    "#         self.z2_aspect = None\n",
    "#         self.z2_aspect_stats = None\n",
    "#         self.z2_slope = None\n",
    "#         self.z2_slope_stats = None\n",
    "#         self.res = None\n",
    "#         self.dhdt = None\n",
    "#         self.dc_dhdt = None\n",
    "#         self.mb = None\n",
    "#         self.dc_mb = None\n",
    "#         self.mb_mean = None\n",
    "#         self.t1 = None\n",
    "#         self.t2 = None\n",
    "#         self.dt = None\n",
    "#         self.t1_mean = None\n",
    "#         self.t2_mean = None\n",
    "#         self.dt_mean = None\n",
    "\n",
    "#         self.H = None\n",
    "#         self.H_mean = np.nan\n",
    "#         self.vx = None\n",
    "#         self.vy = None\n",
    "#         self.vm = None\n",
    "#         self.vm_mean = np.nan\n",
    "#         self.divQ = None\n",
    "#         self.emvel = None\n",
    "# #         self.debris_class = None\n",
    "#         self.debris_thick = None\n",
    "#         self.debris_thick_mean = np.nan\n",
    "#         self.perc_clean = np.nan\n",
    "#         self.perc_debris = np.nan\n",
    "#         self.perc_pond = np.nan\n",
    "\n",
    "#     def geom_srs_update(self, srs=None):\n",
    "#         if self.glac_geom.GetSpatialReference() is None:\n",
    "#             if srs is None:\n",
    "#                 srs = osr.SpatialReference()\n",
    "#                 srs.ImportFromWkt(self.glac_geom_srs_wkt)\n",
    "#             self.glac_geom.AssignSpatialReference(srs)\n",
    "\n",
    "#     def geom_attributes(self, srs=None):\n",
    "#         self.geom_srs_update()\n",
    "#         if srs is not None:\n",
    "#             #Should reproject here to equal area, before geom_attributes\n",
    "#             #self.glac_geom.AssignSpatialReference(glac_shp_srs)\n",
    "#             #self.glac_geom_local = geolib.geom2localortho(self.glac_geom)\n",
    "#             geolib.geom_transform(self.glac_geom, srs)\n",
    "\n",
    "#         self.glac_geom_extent = geolib.geom_extent(self.glac_geom)\n",
    "#         self.glac_area = self.glac_geom.GetArea()\n",
    "#         self.glac_area_km2 = self.glac_area / 1E6\n",
    "#         self.cx, self.cy = self.glac_geom.Centroid().GetPoint_2D()\n",
    "        \n",
    "\n",
    "# #RGI uses 50 m bins\n",
    "# def hist_plot(gf, bin_width=50.0, dz_clim=(-2.0, 2.0), exportcsv=True, csv_ending='', mb_df=None, outdir_csv=None):\n",
    "#     #print(\"Generating histograms\")\n",
    "#     #Create bins for full range of input data and specified bin width\n",
    "\n",
    "#     #NOTE: these counts/areas are for valid pixels only\n",
    "#     #Not necessarily a true representation of actual glacier hypsometry\n",
    "#     #Need a void-filled DEM for this\n",
    "#     if mb_df is not None:\n",
    "#         # Align bins with mass balance data\n",
    "#         bin_center_min = mb_df.loc[0,'bin_center_elev_m']\n",
    "#         while bin_center_min > gf.z1.min() + bin_width/2:\n",
    "#             bin_center_min -= mb_bin_size\n",
    "#         bin_center_max = mb_df['bin_center_elev_m'].values[-1]\n",
    "#         while bin_center_max < gf.z1.max():\n",
    "#             bin_center_max += mb_bin_size    \n",
    "#         z_bin_centers = np.arange(bin_center_min, bin_center_max + mb_bin_size/2, mb_bin_size)\n",
    "#         z_bin_edges = np.arange(bin_center_min - mb_bin_size / 2, bin_center_max + mb_bin_size, mb_bin_size)\n",
    "#     else:\n",
    "#         z_bin_edges, z_bin_centers = malib.get_bins(gf.z1, bin_width)\n",
    "        \n",
    "#     #Need to compress here, otherwise histogram uses masked values!\n",
    "#     z1_bin_counts, z1_bin_edges = np.histogram(gf.z1.compressed(), bins=z_bin_edges)\n",
    "#     z1_bin_areas = z1_bin_counts * gf.res[0] * gf.res[1] / 1E6\n",
    "#     #RGI standard is integer thousandths of glaciers total area\n",
    "#     #Should check to make sure sum of bin areas equals total area\n",
    "#     #z1_bin_areas_perc = 100. * z1_bin_areas / np.sum(z1_bin_areas)\n",
    "#     z1_bin_areas_perc = 100. * (z1_bin_areas / gf.glac_area_km2)\n",
    "\n",
    "#     #If we only have one elevation grid with dhdt\n",
    "#     if gf.z2 is not None:\n",
    "#         z2_bin_counts, z2_bin_edges = np.histogram(gf.z2.compressed(), bins=z_bin_edges)\n",
    "#         z2_bin_areas = z2_bin_counts * gf.res[0] * gf.res[1] / 1E6\n",
    "#         #z2_bin_areas_perc = 100. * z2_bin_areas / np.sum(z2_bin_areas)\n",
    "#         z2_bin_areas_perc = 100. * (z1_bin_areas / gf.glac_area_km2)\n",
    "#     else:\n",
    "#         z2_bin_counts = z1_bin_counts\n",
    "#         z2_bin_edges = z1_bin_edges\n",
    "#         z2_bin_areas = z1_bin_areas\n",
    "#         z2_bin_areas_perc = z1_bin_areas_perc\n",
    "        \n",
    "#     if gf.dc_area is not None:\n",
    "#         dc_bin_counts, dc_bin_edges = np.histogram(gf.dc_area.compressed(), bins=z_bin_edges)\n",
    "#         dc_bin_areas = dc_bin_counts * gf.res[0] * gf.res[1] / 1E6\n",
    "# #         dc_bin_areas_perc = 100. * (dc_bin_areas / gf.glac_area_km2)\n",
    "#         dc_bin_areas_perc = 100. * (dc_bin_areas / z1_bin_areas)\n",
    "# #         outbins_df['bin_debris_perc'] = outbins_df['dc_bin_count_valid'] / outbins_df['z1_bin_count_valid'] * 100\n",
    "\n",
    "#     #Create arrays to store output\n",
    "#     slope_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "#     slope_bin_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "#     aspect_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "#     aspect_bin_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "#     if gf.dhdt is not None:\n",
    "#         mb_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         np.ma.set_fill_value(mb_bin_med, np.nan)\n",
    "#         mb_bin_mad = np.ma.masked_all_like(mb_bin_med)\n",
    "#         mb_bin_mean = np.ma.masked_all_like(mb_bin_med)\n",
    "#         mb_bin_std = np.ma.masked_all_like(mb_bin_med)\n",
    "#         dhdt_bin_med = np.ma.masked_all_like(mb_bin_med)\n",
    "#         dhdt_bin_mad = np.ma.masked_all_like(mb_bin_med)\n",
    "#         dhdt_bin_mean = np.ma.masked_all_like(mb_bin_med)\n",
    "#         dhdt_bin_std = np.ma.masked_all_like(mb_bin_med)\n",
    "#         dhdt_bin_count = np.ma.masked_all_like(mb_bin_med)\n",
    "#     if gf.dc_dhdt is not None:\n",
    "#         dc_mb_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         np.ma.set_fill_value(dc_mb_bin_med, np.nan)\n",
    "#         dc_mb_bin_mad = np.ma.masked_all_like(dc_mb_bin_med)\n",
    "#         dc_mb_bin_mean = np.ma.masked_all_like(dc_mb_bin_med)\n",
    "#         dc_mb_bin_std = np.ma.masked_all_like(dc_mb_bin_med)\n",
    "#         dc_dhdt_bin_med = np.ma.masked_all_like(dc_mb_bin_med)\n",
    "#         dc_dhdt_bin_mad = np.ma.masked_all_like(dc_mb_bin_med)\n",
    "#         dc_dhdt_bin_mean = np.ma.masked_all_like(dc_mb_bin_med)\n",
    "#         dc_dhdt_bin_std = np.ma.masked_all_like(dc_mb_bin_med)\n",
    "#         dc_dhdt_bin_count = np.ma.masked_all_like(dc_mb_bin_med)\n",
    "#     if gf.vm is not None:\n",
    "#         vm_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         vm_bin_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "#     if gf.H is not None:\n",
    "#         H_bin_mean = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         H_bin_std = np.ma.masked_all_like(z1_bin_areas)\n",
    "#     if gf.emvel is not None:\n",
    "#         emvel_bin_mean = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         emvel_bin_std = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         emvel_bin_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         emvel_bin_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "# #     if gf.debris_class is not None:\n",
    "# #         debris_thick_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "# #         debris_thick_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "\n",
    "#     if gf.debris_thick_ts is not None:\n",
    "#         debris_thick_ts_mean = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         debris_thick_ts_std = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         debris_thick_ts_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         debris_thick_ts_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "#     if gf.meltfactor_ts is not None:\n",
    "#         meltfactor_ts_mean = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         meltfactor_ts_std = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         meltfactor_ts_med = np.ma.masked_all_like(z1_bin_areas)\n",
    "#         meltfactor_ts_mad = np.ma.masked_all_like(z1_bin_areas)\n",
    "\n",
    "#     #Bin sample count must be greater than this value\n",
    "#     min_bin_samp_count = input.min_bin_samp_count\n",
    "\n",
    "#     #Loop through each bin and extract stats\n",
    "#     idx = np.digitize(gf.z1, z_bin_edges)\n",
    "#     for bin_n in range(z_bin_centers.size):\n",
    "#         if gf.dhdt is not None:\n",
    "#             mb_bin_samp = gf.mb[(idx == bin_n+1)]\n",
    "#             if mb_bin_samp.count() > min_bin_samp_count:\n",
    "#                 mb_bin_med[bin_n] = malib.fast_median(mb_bin_samp)\n",
    "#                 mb_bin_mad[bin_n] = malib.mad(mb_bin_samp)\n",
    "#                 mb_bin_mean[bin_n] = mb_bin_samp.mean()\n",
    "#                 mb_bin_std[bin_n] = mb_bin_samp.std()\n",
    "#             dhdt_bin_samp = gf.dhdt[(idx == bin_n+1)]\n",
    "#             if dhdt_bin_samp.count() > min_bin_samp_count:\n",
    "#                 dhdt_bin_med[bin_n] = malib.fast_median(dhdt_bin_samp)\n",
    "#                 dhdt_bin_mad[bin_n] = malib.mad(dhdt_bin_samp)\n",
    "#                 dhdt_bin_mean[bin_n] = dhdt_bin_samp.mean()\n",
    "#                 dhdt_bin_std[bin_n] = dhdt_bin_samp.std()\n",
    "#                 dhdt_bin_count[bin_n] = dhdt_bin_samp.count()\n",
    "        \n",
    "#         if gf.dc_dhdt is not None:\n",
    "#             dc_mb_bin_samp = gf.dc_mb[(idx == bin_n+1)]\n",
    "#             if dc_mb_bin_samp.count() > min_bin_samp_count:\n",
    "#                 dc_mb_bin_med[bin_n] = malib.fast_median(dc_mb_bin_samp)\n",
    "#                 dc_mb_bin_mad[bin_n] = malib.mad(dc_mb_bin_samp)\n",
    "#                 dc_mb_bin_mean[bin_n] = dc_mb_bin_samp.mean()\n",
    "#                 dc_mb_bin_std[bin_n] = dc_mb_bin_samp.std()\n",
    "#             dc_dhdt_bin_samp = gf.dc_dhdt[(idx == bin_n+1)]\n",
    "#             if dc_dhdt_bin_samp.count() > min_bin_samp_count:\n",
    "#                 dc_dhdt_bin_med[bin_n] = malib.fast_median(dc_dhdt_bin_samp)\n",
    "#                 dc_dhdt_bin_mad[bin_n] = malib.mad(dc_dhdt_bin_samp)\n",
    "#                 dc_dhdt_bin_mean[bin_n] = dc_dhdt_bin_samp.mean()\n",
    "#                 dc_dhdt_bin_std[bin_n] = dc_dhdt_bin_samp.std()\n",
    "#                 dc_dhdt_bin_count[bin_n] = dc_dhdt_bin_samp.count()\n",
    "                \n",
    "#         if gf.debris_thick is not None:\n",
    "#             debris_thick_bin_samp = gf.debris_thick[(idx == bin_n+1)]\n",
    "#             if debris_thick_bin_samp.size > min_bin_samp_count:\n",
    "#                 debris_thick_med[bin_n] = malib.fast_median(debris_thick_bin_samp)\n",
    "#                 debris_thick_mad[bin_n] = malib.mad(debris_thick_bin_samp)\n",
    "        \n",
    "#         if gf.debris_thick_ts is not None:\n",
    "#             debris_thick_ts_bin_samp = gf.debris_thick_ts[(idx == bin_n+1)]\n",
    "#             if debris_thick_ts_bin_samp.size > min_bin_samp_count:\n",
    "#                 debris_thick_ts_mean[bin_n] = debris_thick_ts_bin_samp.mean()\n",
    "#                 debris_thick_ts_std[bin_n] = debris_thick_ts_bin_samp.std()\n",
    "#                 debris_thick_ts_med[bin_n] = malib.fast_median(debris_thick_ts_bin_samp)\n",
    "#                 debris_thick_ts_mad[bin_n] = malib.mad(debris_thick_ts_bin_samp)\n",
    "#         if gf.meltfactor_ts is not None:\n",
    "#             meltfactor_ts_bin_samp = gf.meltfactor_ts[(idx == bin_n+1)]\n",
    "#             if meltfactor_ts_bin_samp.size > min_bin_samp_count:\n",
    "#                 meltfactor_ts_mean[bin_n] = meltfactor_ts_bin_samp.mean()\n",
    "#                 meltfactor_ts_std[bin_n] = meltfactor_ts_bin_samp.std()\n",
    "#                 meltfactor_ts_med[bin_n] = malib.fast_median(meltfactor_ts_bin_samp)\n",
    "#                 meltfactor_ts_mad[bin_n] = malib.mad(meltfactor_ts_bin_samp)\n",
    "        \n",
    "# #         if gf.debris_class is not None:\n",
    "# #             debris_class_bin_samp = gf.debris_class[(idx == bin_n+1)]\n",
    "# #             dhdt_clean_bin_samp = gf.dhdt_clean[(idx == bin_n+1)]\n",
    "# #             dhdt_debris_bin_samp = gf.dhdt_debris[(idx == bin_n+1)]\n",
    "# #             dhdt_pond_bin_samp = gf.dhdt_pond[(idx == bin_n+1)]\n",
    "# #             if debris_class_bin_samp.count() > min_bin_samp_count:\n",
    "# #                 perc_clean[bin_n] = 100. * (debris_class_bin_samp == 1).sum()/debris_class_bin_samp.count()\n",
    "# #                 perc_debris[bin_n] = 100. * (debris_class_bin_samp == 2).sum()/debris_class_bin_samp.count()\n",
    "# #                 perc_pond[bin_n] = 100. * (debris_class_bin_samp == 3).sum()/debris_class_bin_samp.count()\n",
    "# #             if dhdt_clean_bin_samp.count() > min_bin_samp_count:\n",
    "# #                 dhdt_clean_bin_med[bin_n] = malib.fast_median(dhdt_clean_bin_samp)\n",
    "# #             if dhdt_debris_bin_samp.count() > min_bin_samp_count:\n",
    "# #                 dhdt_debris_bin_med[bin_n] = malib.fast_median(dhdt_debris_bin_samp)\n",
    "# #             if dhdt_pond_bin_samp.count() > min_bin_samp_count:\n",
    "# #                 dhdt_pond_bin_med[bin_n] = malib.fast_median(dhdt_pond_bin_samp)\n",
    "#         if gf.vm is not None:\n",
    "#             vm_bin_samp = gf.vm[(idx == bin_n+1)]\n",
    "#             if vm_bin_samp.size > min_bin_samp_count:\n",
    "#                 vm_bin_med[bin_n] = malib.fast_median(vm_bin_samp)\n",
    "#                 vm_bin_mad[bin_n] = malib.mad(vm_bin_samp)\n",
    "#         if gf.H is not None:\n",
    "#             H_bin_samp = gf.H[(idx == bin_n+1)]\n",
    "#             if H_bin_samp.size > min_bin_samp_count:\n",
    "#                 H_bin_mean[bin_n] = H_bin_samp.mean()\n",
    "#                 H_bin_std[bin_n] = H_bin_samp.std()\n",
    "#         if gf.emvel is not None:\n",
    "#             emvel_bin_samp = gf.emvel[(idx == bin_n+1)]\n",
    "#             if emvel_bin_samp.size > min_bin_samp_count:\n",
    "#                 emvel_bin_mean[bin_n] = emvel_bin_samp.mean()\n",
    "#                 emvel_bin_std[bin_n] = emvel_bin_samp.std()\n",
    "#                 emvel_bin_med[bin_n] = malib.fast_median(emvel_bin_samp)\n",
    "#                 emvel_bin_mad[bin_n] = malib.mad(emvel_bin_samp)\n",
    "#         slope_bin_samp = gf.z1_slope[(idx == bin_n+1)]\n",
    "#         if slope_bin_samp.size > min_bin_samp_count:\n",
    "#             slope_bin_med[bin_n] = malib.fast_median(slope_bin_samp)\n",
    "#             slope_bin_mad[bin_n] = malib.mad(slope_bin_samp)\n",
    "#         aspect_bin_samp = gf.z1_aspect[(idx == bin_n+1)]\n",
    "#         if aspect_bin_samp.size > min_bin_samp_count:\n",
    "#             aspect_bin_med[bin_n] = malib.fast_median(aspect_bin_samp)\n",
    "#             aspect_bin_mad[bin_n] = malib.mad(aspect_bin_samp)\n",
    "\n",
    "#     if gf.dhdt is not None:\n",
    "#         dhdt_bin_areas = dhdt_bin_count * gf.res[0] * gf.res[1] / 1E6\n",
    "#         #dhdt_bin_areas_perc = 100. * dhdt_bin_areas / np.sum(dhdt_bin_areas)\n",
    "#         dhdt_bin_areas_perc = 100. * (dhdt_bin_areas / gf.glac_area_km2)\n",
    "\n",
    "#     outbins_header = ('bin_center_elev_m,z1_bin_count_valid,z1_bin_area_valid_km2,z1_bin_area_perc,z2_bin_count_valid'\n",
    "#                       + ',z2_bin_area_valid_km2,z2_bin_area_perc,slope_bin_med,aspect_bin_med')\n",
    "#     fmt = '%0.1f,%0.0f,%0.3f,%0.2f,%0.0f,%0.3f,%0.2f,%0.2f,%0.2f'\n",
    "#     outbins = [z_bin_centers, z1_bin_counts, z1_bin_areas, z1_bin_areas_perc, z2_bin_counts, z2_bin_areas, \n",
    "#                z2_bin_areas_perc, slope_bin_med, aspect_bin_med]\n",
    "#     if gf.dhdt is not None:\n",
    "#         outbins_header = (outbins_header + ',dhdt_bin_count,dhdt_bin_area_valid_km2,dhdt_bin_area_perc,' + \n",
    "#                           'dhdt_bin_med_ma,dhdt_bin_mad_ma,dhdt_bin_mean_ma,dhdt_bin_std_ma,mb_bin_med_mwea,' + \n",
    "#                           'mb_bin_mad_mwea,mb_bin_mean_mwea,mb_bin_std_mwea')\n",
    "#         fmt += ',%0.0f,%0.3f,%0.2f,%0.2f,%0.2f,%0.2f,%0.2f,%0.2f,%0.2f,%0.2f,%0.2f'\n",
    "#         outbins.extend([dhdt_bin_count, dhdt_bin_areas, dhdt_bin_areas_perc, dhdt_bin_med, dhdt_bin_mad, \n",
    "#                         dhdt_bin_mean, dhdt_bin_std, mb_bin_med, mb_bin_mad, mb_bin_mean, mb_bin_std])\n",
    "#     if gf.dc_dhdt is not None:\n",
    "#         outbins_header = (outbins_header + ',dc_dhdt_bin_count,dc_dhdt_bin_med_ma,dc_dhdt_bin_mad_ma,' +\n",
    "#                           'dc_dhdt_bin_mean_ma,dc_dhdt_bin_std_ma,dc_mb_bin_med_mwea,dc_mb_bin_mad_mwea,' + \n",
    "#                           'dc_mb_bin_mean_mwea,dc_mb_bin_std_mwea')\n",
    "#         fmt += ',%0.0f,%0.2f,%0.2f,%0.2f,%0.2f,%0.2f,%0.2f,%0.2f,%0.2f'\n",
    "#         outbins.extend([dc_dhdt_bin_count, dc_dhdt_bin_med, dc_dhdt_bin_mad, dc_dhdt_bin_mean, dc_dhdt_bin_std, \n",
    "#                         dc_mb_bin_med, dc_mb_bin_mad, dc_mb_bin_mean, dc_mb_bin_std])\n",
    "#     if gf.dc_area is not None:\n",
    "#         outbins_header += ',dc_bin_count_valid,dc_bin_area_valid_km2,dc_bin_area_perc'\n",
    "#         fmt += ',%0.0f,%0.3f,%0.2f'\n",
    "#         outbins.extend([dc_bin_counts, dc_bin_areas, dc_bin_areas_perc])\n",
    "# #         outbins.extend([z1_bin_counts, z1_bin_areas, z1_bin_areas_perc])\n",
    "        \n",
    "        \n",
    "#     if gf.debris_thick is not None:\n",
    "#         outbins_header += ',hd_med_m,hd_mad_m'\n",
    "#         fmt += ',%0.2f,%0.2f'\n",
    "#         debris_thick_med[debris_thick_med == -(np.inf)] = 0.00\n",
    "#         debris_thick_mad[debris_thick_mad == -(np.inf)] = 0.00\n",
    "#         outbins.extend([debris_thick_med, debris_thick_mad])\n",
    "    \n",
    "#     if gf.debris_thick_ts is not None:\n",
    "#         outbins_header += ',hd_ts_mean_m,hd_ts_std_m,hd_ts_med_m,hd_ts_mad_m'\n",
    "#         fmt += ',%0.2f,%0.2f,%0.2f,%0.2f'\n",
    "#         debris_thick_ts_mean[debris_thick_ts_mean == -(np.inf)] = 0.00\n",
    "#         debris_thick_ts_std[debris_thick_ts_std == -(np.inf)] = 0.00\n",
    "#         debris_thick_ts_med[debris_thick_ts_med == -(np.inf)] = 0.00\n",
    "#         debris_thick_ts_mad[debris_thick_ts_mad == -(np.inf)] = 0.00\n",
    "#         outbins.extend([debris_thick_ts_mean, debris_thick_ts_std, debris_thick_ts_med, debris_thick_ts_mad])\n",
    "#     if gf.meltfactor_ts is not None:\n",
    "#         outbins_header += ',mf_ts_mean,mf_ts_std,mf_ts_med,mf_ts_mad'\n",
    "#         fmt += ',%0.2f,%0.2f,%0.2f,%0.2f'\n",
    "#         meltfactor_ts_mean[meltfactor_ts_mean == -(np.inf)] = 1\n",
    "#         meltfactor_ts_mean[meltfactor_ts_mean <= 0] = 1\n",
    "#         meltfactor_ts_std[meltfactor_ts_std == -(np.inf)] = 0\n",
    "#         meltfactor_ts_std[meltfactor_ts_std <= 0] = 0\n",
    "#         meltfactor_ts_med[meltfactor_ts_med == -(np.inf)] = 1\n",
    "#         meltfactor_ts_med[meltfactor_ts_med <= 0] = 1\n",
    "#         meltfactor_ts_mad[meltfactor_ts_mad == -(np.inf)] = 0\n",
    "#         meltfactor_ts_mad[meltfactor_ts_mad <= 0] = 0\n",
    "#         outbins.extend([meltfactor_ts_mean, meltfactor_ts_std, meltfactor_ts_med, meltfactor_ts_mad])\n",
    "    \n",
    "#     if gf.vm is not None:\n",
    "#         outbins_header += ',vm_med,vm_mad'\n",
    "#         fmt += ',%0.2f,%0.2f'\n",
    "#         outbins.extend([vm_bin_med, vm_bin_mad])\n",
    "#     if gf.H is not None:\n",
    "#         outbins_header += ',H_mean,H_std'\n",
    "#         fmt += ',%0.2f,%0.2f'\n",
    "#         outbins.extend([H_bin_mean, H_bin_std])\n",
    "\n",
    "#     if gf.emvel is not None:\n",
    "#         outbins_header += ',emvel_mean,emvel_std,emvel_med,emvel_mad'\n",
    "#         fmt += ',%0.3f,%0.3f,%0.3f,%0.3f'\n",
    "#         outbins.extend([emvel_bin_mean, emvel_bin_std, emvel_bin_med, emvel_bin_mad])\n",
    "    \n",
    "#     outbins = np.ma.array(outbins).T.astype('float32')\n",
    "#     np.ma.set_fill_value(outbins, np.nan)\n",
    "#     outbins = outbins.filled(np.nan)\n",
    "    \n",
    "#     outbins_df = pd.DataFrame(outbins, columns=outbins_header.split(','))\n",
    "    \n",
    "#     if mb_df is not None:\n",
    "#         # ADD MASS BALANCE DATA\n",
    "#         mb_df = mb_df[np.isfinite(mb_df['bin_center_elev_m'])]\n",
    "#         mb_df.reset_index(inplace=True, drop=True)\n",
    "#         # start index for merge\n",
    "#         if mb_df.loc[0,'bin_center_elev_m'] >= outbins_df.loc[0,'bin_center_elev_m']:\n",
    "#             mb_df_idx1 = 0\n",
    "#             outbins_idx1 = np.where(outbins_df['bin_center_elev_m'] == mb_df.loc[0,'bin_center_elev_m'])[0][0]\n",
    "#         else:\n",
    "#             outbins_idx1 = 0\n",
    "#             mb_df_idx1 = np.where(outbins_df.loc[0,'bin_center_elev_m'] == mb_df['bin_center_elev_m'])[0][0]\n",
    "#     #     print('idx1:', \n",
    "#     #           '\\noutbins:', outbins_idx1, outbins_df.loc[outbins_idx1,'bin_center_elev_m'],\n",
    "#     #           '\\ndfbins:', mb_df_idx1, mb_df.loc[mb_df_idx1,'# bin_center_elev_m'])\n",
    "#         # end index for merge\n",
    "#         if (outbins_df.loc[outbins_df.shape[0]-1,'bin_center_elev_m'] >= \n",
    "#             mb_df.loc[mb_df.shape[0]-1,'bin_center_elev_m']):\n",
    "#             outbins_idx2 = np.where(\n",
    "#                 outbins_df['bin_center_elev_m'] == mb_df.loc[mb_df.shape[0]-1,'bin_center_elev_m'])[0][0]\n",
    "#             mb_df_idx2 = mb_df.shape[0]-1\n",
    "#         else:\n",
    "#             outbins_idx2 = outbins_df.shape[0]-1\n",
    "#             mb_df_idx2 = np.where(\n",
    "#                 outbins_df.loc[outbins_df.shape[0]-1,'bin_center_elev_m'] == mb_df['bin_center_elev_m'])[0][0]\n",
    "#     #     print('idx2:', \n",
    "#     #           '\\noutbins:', outbins_idx2, outbins_df.loc[outbins_idx2,'bin_center_elev_m'],\n",
    "#     #           '\\ndfbins:', mb_df_idx2, mb_df.loc[mb_df_idx2,'# bin_center_elev_m'])\n",
    "#         outbins_df[' mb_bin_mean_mwea'] = np.nan\n",
    "#         outbins_df[' mb_bin_std_mwea'] = np.nan\n",
    "#         outbins_df[' mb_bin_area_valid_km2'] = np.nan\n",
    "#         outbins_df.loc[outbins_idx1:outbins_idx2+1,' mb_bin_mean_mwea'] = (\n",
    "#             mb_df.loc[mb_df_idx1:mb_df_idx2+1,' mb_bin_mean_mwea'])\n",
    "#         outbins_df.loc[outbins_idx1:outbins_idx2+1,' mb_bin_std_mwea'] = (\n",
    "#             mb_df.loc[mb_df_idx1:mb_df_idx2+1,' mb_bin_std_mwea'])\n",
    "#         outbins_df.loc[outbins_idx1:outbins_idx2+1,' mb_bin_area_valid_km2'] = (\n",
    "#             mb_df.loc[mb_df_idx1:mb_df_idx2+1,' z1_bin_area_valid_km2'])\n",
    "#         try:\n",
    "#             outbins_df['startyear'] = mb_df.loc[mb_df_idx1,'startyear']\n",
    "#             outbins_df['endyear'] = mb_df.loc[mb_df_idx1,'endyear']\n",
    "#         except:\n",
    "#             outbins_df['startyear'] = 2000\n",
    "#             outbins_df['endyear'] = 2012\n",
    "    \n",
    "#     if exportcsv:\n",
    "#         if int(gf.feat_fn.split('.')[0]) < 10:\n",
    "#             outbins_fullfn = os.path.join(outdir_csv, gf.feat_fn[0:7] + csv_ending)\n",
    "#         else:\n",
    "#             outbins_fullfn = os.path.join(outdir_csv, gf.feat_fn[0:8] + csv_ending)\n",
    "#         outbins_df.to_csv(outbins_fullfn, index=False)\n",
    "    \n",
    "#     outbins_df = pd.DataFrame(outbins, columns=outbins_header.split(','))\n",
    "    \n",
    "#     return outbins_df, z_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "Compute debris thickness through sub-debris and temperature inversion methods\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from scipy import ndimage\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import median_absolute_deviation\n",
    "import xarray as xr\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "from pygeotools.lib import malib, warplib, geolib, iolib, timelib\n",
    "# from imview.lib import pltlib\n",
    "\n",
    "# import globaldebris_input as input\n",
    "import debrisglobal.globaldebris_input as debris_prms\n",
    "from debrisglobal.glacfeat import GlacFeat\n",
    "\n",
    "calc_emergence = True\n",
    "\n",
    "verbose=False\n",
    "debug=False\n",
    "extra_layers=True\n",
    "\n",
    "csv_ending = '_mb_bins.csv'\n",
    "# outdir_csv = '/'.join(debris_prms.dhdt_fn_dict[debris_prms.roi].split('/')[:-1]) + '/binned_data/'\n",
    "outdir_csv = debris_prms.mb_binned_fp\n",
    "if os.path.exists(outdir_csv) == False:\n",
    "    os.makedirs(outdir_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RGI60-11.00002' 'RGI60-11.00047' 'RGI60-11.00054' 'RGI60-11.00068'\n",
      " 'RGI60-11.00106' 'RGI60-11.00110' 'RGI60-11.00116' 'RGI60-11.00135'\n",
      " 'RGI60-11.00141' 'RGI60-11.00190' 'RGI60-11.00199' 'RGI60-11.00233'\n",
      " 'RGI60-11.00278' 'RGI60-11.00376' 'RGI60-11.00415' 'RGI60-11.00459'\n",
      " 'RGI60-11.00469' 'RGI60-11.00487' 'RGI60-11.00524' 'RGI60-11.00541'\n",
      " 'RGI60-11.00597' 'RGI60-11.00719' 'RGI60-11.00781' 'RGI60-11.00797'\n",
      " 'RGI60-11.00830' 'RGI60-11.00846' 'RGI60-11.00871' 'RGI60-11.00886'\n",
      " 'RGI60-11.00887' 'RGI60-11.00897' 'RGI60-11.00918' 'RGI60-11.00929'\n",
      " 'RGI60-11.00932' 'RGI60-11.00943' 'RGI60-11.00945' 'RGI60-11.00950'\n",
      " 'RGI60-11.00957' 'RGI60-11.00958' 'RGI60-11.01144' 'RGI60-11.01187'\n",
      " 'RGI60-11.01193' 'RGI60-11.01246' 'RGI60-11.01275' 'RGI60-11.01296'\n",
      " 'RGI60-11.01328' 'RGI60-11.01346' 'RGI60-11.01450' 'RGI60-11.01478'\n",
      " 'RGI60-11.01509' 'RGI60-11.01550' 'RGI60-11.01576' 'RGI60-11.01604'\n",
      " 'RGI60-11.01621' 'RGI60-11.01622' 'RGI60-11.01678' 'RGI60-11.01698'\n",
      " 'RGI60-11.01719' 'RGI60-11.01776' 'RGI60-11.01791' 'RGI60-11.01797'\n",
      " 'RGI60-11.01806' 'RGI60-11.01827' 'RGI60-11.01834' 'RGI60-11.01876'\n",
      " 'RGI60-11.01912' 'RGI60-11.01946' 'RGI60-11.01974' 'RGI60-11.01987'\n",
      " 'RGI60-11.01990' 'RGI60-11.02006' 'RGI60-11.02051' 'RGI60-11.02064'\n",
      " 'RGI60-11.02119' 'RGI60-11.02173' 'RGI60-11.02222' 'RGI60-11.02245'\n",
      " 'RGI60-11.02249' 'RGI60-11.02285' 'RGI60-11.02337' 'RGI60-11.02351'\n",
      " 'RGI60-11.02385' 'RGI60-11.02427' 'RGI60-11.02460' 'RGI60-11.02495'\n",
      " 'RGI60-11.02507' 'RGI60-11.02515' 'RGI60-11.02558' 'RGI60-11.02584'\n",
      " 'RGI60-11.02593' 'RGI60-11.02596' 'RGI60-11.02624' 'RGI60-11.02630'\n",
      " 'RGI60-11.02645' 'RGI60-11.02676' 'RGI60-11.02709' 'RGI60-11.02715'\n",
      " 'RGI60-11.02737' 'RGI60-11.02739' 'RGI60-11.02746' 'RGI60-11.02749'\n",
      " 'RGI60-11.02755' 'RGI60-11.02764' 'RGI60-11.02787' 'RGI60-11.02793'\n",
      " 'RGI60-11.02796' 'RGI60-11.02801' 'RGI60-11.02810' 'RGI60-11.02819'\n",
      " 'RGI60-11.02822' 'RGI60-11.02843' 'RGI60-11.02858' 'RGI60-11.02866'\n",
      " 'RGI60-11.02884' 'RGI60-11.02890' 'RGI60-11.02902' 'RGI60-11.02916'\n",
      " 'RGI60-11.02922' 'RGI60-11.02924' 'RGI60-11.02979' 'RGI60-11.03001'\n",
      " 'RGI60-11.03005' 'RGI60-11.03020' 'RGI60-11.03039' 'RGI60-11.03114'\n",
      " 'RGI60-11.03124' 'RGI60-11.03147' 'RGI60-11.03154' 'RGI60-11.03182'\n",
      " 'RGI60-11.03264' 'RGI60-11.03308' 'RGI60-11.03373' 'RGI60-11.03427'\n",
      " 'RGI60-11.03466' 'RGI60-11.03546' 'RGI60-11.03556' 'RGI60-11.03638'\n",
      " 'RGI60-11.03642' 'RGI60-11.03643' 'RGI60-11.03648' 'RGI60-11.03651'\n",
      " 'RGI60-11.03655' 'RGI60-11.03662' 'RGI60-11.03667' 'RGI60-11.03671'\n",
      " 'RGI60-11.03672' 'RGI60-11.03674' 'RGI60-11.03675' 'RGI60-11.03676'\n",
      " 'RGI60-11.03683' 'RGI60-11.03684' 'RGI60-11.03687' 'RGI60-11.03694'\n",
      " 'RGI60-11.03698' 'RGI60-11.03701' 'RGI60-11.03740' 'RGI60-11.03760']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGIId</th>\n",
       "      <th>GLIMSId</th>\n",
       "      <th>BgnDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>...</th>\n",
       "      <th>DC_Area</th>\n",
       "      <th>DC_BgnDate</th>\n",
       "      <th>DC_EndDate</th>\n",
       "      <th>DC_CTSmean</th>\n",
       "      <th>DC_Area_%</th>\n",
       "      <th>area_singl</th>\n",
       "      <th>DC_Area_v2</th>\n",
       "      <th>DC_Area__1</th>\n",
       "      <th>geometry</th>\n",
       "      <th>CenLon_360</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RGI60-11.00002</td>\n",
       "      <td>G013614E47485N</td>\n",
       "      <td>20030799</td>\n",
       "      <td>20030999</td>\n",
       "      <td>13.614373</td>\n",
       "      <td>47.483905</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.292</td>\n",
       "      <td>2203</td>\n",
       "      <td>...</td>\n",
       "      <td>186300</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>29.698587</td>\n",
       "      <td>8.128</td>\n",
       "      <td>900</td>\n",
       "      <td>186399</td>\n",
       "      <td>8.133</td>\n",
       "      <td>MULTIPOLYGON (((13.60653 47.47813, 13.60692 47...</td>\n",
       "      <td>13.614373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RGI60-11.00047</td>\n",
       "      <td>G012719E47139N</td>\n",
       "      <td>20030799</td>\n",
       "      <td>20030999</td>\n",
       "      <td>12.718158</td>\n",
       "      <td>47.139499</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2307</td>\n",
       "      <td>...</td>\n",
       "      <td>152100</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>20.334521</td>\n",
       "      <td>6.692</td>\n",
       "      <td>900</td>\n",
       "      <td>156609</td>\n",
       "      <td>6.890</td>\n",
       "      <td>MULTIPOLYGON (((12.70776 47.13999, 12.70815 47...</td>\n",
       "      <td>12.718158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RGI60-11.00054</td>\n",
       "      <td>G012372E47149N</td>\n",
       "      <td>20030799</td>\n",
       "      <td>20030999</td>\n",
       "      <td>12.370435</td>\n",
       "      <td>47.149801</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.274</td>\n",
       "      <td>2359</td>\n",
       "      <td>...</td>\n",
       "      <td>143100</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>17.590514</td>\n",
       "      <td>6.293</td>\n",
       "      <td>900</td>\n",
       "      <td>143075</td>\n",
       "      <td>6.292</td>\n",
       "      <td>MULTIPOLYGON (((12.35997 47.14789, 12.36037 47...</td>\n",
       "      <td>12.370435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RGI60-11.00068</td>\n",
       "      <td>G012345E47132N</td>\n",
       "      <td>20030799</td>\n",
       "      <td>20030999</td>\n",
       "      <td>12.343717</td>\n",
       "      <td>47.135779</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.738</td>\n",
       "      <td>2162</td>\n",
       "      <td>...</td>\n",
       "      <td>176400</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>18.493408</td>\n",
       "      <td>6.443</td>\n",
       "      <td>900</td>\n",
       "      <td>176364</td>\n",
       "      <td>6.441</td>\n",
       "      <td>MULTIPOLYGON (((12.35453 47.12994, 12.35493 47...</td>\n",
       "      <td>12.343717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RGI60-11.00106</td>\n",
       "      <td>G012697E47099N</td>\n",
       "      <td>20030799</td>\n",
       "      <td>20030999</td>\n",
       "      <td>12.698172</td>\n",
       "      <td>47.094468</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>17.774</td>\n",
       "      <td>2086</td>\n",
       "      <td>...</td>\n",
       "      <td>2984400</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>23.575460</td>\n",
       "      <td>16.791</td>\n",
       "      <td>4500</td>\n",
       "      <td>3036802</td>\n",
       "      <td>17.086</td>\n",
       "      <td>MULTIPOLYGON (((12.70993 47.08010, 12.71112 47...</td>\n",
       "      <td>12.698172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>RGI60-11.03694</td>\n",
       "      <td>G006263E44892N</td>\n",
       "      <td>20030813</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>6.259492</td>\n",
       "      <td>44.893911</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2405</td>\n",
       "      <td>...</td>\n",
       "      <td>813600</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>42.305511</td>\n",
       "      <td>36.289</td>\n",
       "      <td>900</td>\n",
       "      <td>814213</td>\n",
       "      <td>36.316</td>\n",
       "      <td>MULTIPOLYGON (((6.25929 44.88545, 6.25967 44.8...</td>\n",
       "      <td>6.259492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>RGI60-11.03698</td>\n",
       "      <td>G006988E45987N</td>\n",
       "      <td>20030813</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>6.995296</td>\n",
       "      <td>45.985482</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8.124</td>\n",
       "      <td>2193</td>\n",
       "      <td>...</td>\n",
       "      <td>573300</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>38.465296</td>\n",
       "      <td>7.057</td>\n",
       "      <td>5401</td>\n",
       "      <td>577015</td>\n",
       "      <td>7.103</td>\n",
       "      <td>MULTIPOLYGON (((7.00593 45.96921, 7.00709 45.9...</td>\n",
       "      <td>6.995296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>RGI60-11.03701</td>\n",
       "      <td>G007144E45371N</td>\n",
       "      <td>20030813</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>7.145103</td>\n",
       "      <td>45.375305</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.373</td>\n",
       "      <td>2761</td>\n",
       "      <td>...</td>\n",
       "      <td>403200</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>38.446785</td>\n",
       "      <td>16.991</td>\n",
       "      <td>900</td>\n",
       "      <td>404213</td>\n",
       "      <td>17.034</td>\n",
       "      <td>MULTIPOLYGON (((7.15623 45.36957, 7.15661 45.3...</td>\n",
       "      <td>7.145103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>RGI60-11.03740</td>\n",
       "      <td>G007123E45253N</td>\n",
       "      <td>20030813</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>7.118216</td>\n",
       "      <td>45.254020</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.067</td>\n",
       "      <td>2773</td>\n",
       "      <td>...</td>\n",
       "      <td>453600</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>41.382340</td>\n",
       "      <td>21.945</td>\n",
       "      <td>1800</td>\n",
       "      <td>464972</td>\n",
       "      <td>22.495</td>\n",
       "      <td>MULTIPOLYGON (((7.12013 45.24476, 7.12090 45.2...</td>\n",
       "      <td>7.118216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>RGI60-11.03760</td>\n",
       "      <td>G006147E45146N</td>\n",
       "      <td>20030813</td>\n",
       "      <td>-9999999</td>\n",
       "      <td>6.146433</td>\n",
       "      <td>45.141572</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.008</td>\n",
       "      <td>2608</td>\n",
       "      <td>...</td>\n",
       "      <td>299700</td>\n",
       "      <td>2013</td>\n",
       "      <td>2017</td>\n",
       "      <td>51.667262</td>\n",
       "      <td>14.925</td>\n",
       "      <td>1799</td>\n",
       "      <td>299571</td>\n",
       "      <td>14.919</td>\n",
       "      <td>MULTIPOLYGON (((6.14564 45.13193, 6.14602 45.1...</td>\n",
       "      <td>6.146433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              RGIId         GLIMSId   BgnDate   EndDate     CenLon     CenLat  \\\n",
       "0    RGI60-11.00002  G013614E47485N  20030799  20030999  13.614373  47.483905   \n",
       "1    RGI60-11.00047  G012719E47139N  20030799  20030999  12.718158  47.139499   \n",
       "2    RGI60-11.00054  G012372E47149N  20030799  20030999  12.370435  47.149801   \n",
       "3    RGI60-11.00068  G012345E47132N  20030799  20030999  12.343717  47.135779   \n",
       "4    RGI60-11.00106  G012697E47099N  20030799  20030999  12.698172  47.094468   \n",
       "..              ...             ...       ...       ...        ...        ...   \n",
       "151  RGI60-11.03694  G006263E44892N  20030813  -9999999   6.259492  44.893911   \n",
       "152  RGI60-11.03698  G006988E45987N  20030813  -9999999   6.995296  45.985482   \n",
       "153  RGI60-11.03701  G007144E45371N  20030813  -9999999   7.145103  45.375305   \n",
       "154  RGI60-11.03740  G007123E45253N  20030813  -9999999   7.118216  45.254020   \n",
       "155  RGI60-11.03760  G006147E45146N  20030813  -9999999   6.146433  45.141572   \n",
       "\n",
       "    O1Region O2Region    Area  Zmin  ...  DC_Area  DC_BgnDate  DC_EndDate  \\\n",
       "0         11        1   2.292  2203  ...   186300        2013        2017   \n",
       "1         11        1   2.273  2307  ...   152100        2013        2017   \n",
       "2         11        1   2.274  2359  ...   143100        2013        2017   \n",
       "3         11        1   2.738  2162  ...   176400        2013        2017   \n",
       "4         11        1  17.774  2086  ...  2984400        2013        2017   \n",
       "..       ...      ...     ...   ...  ...      ...         ...         ...   \n",
       "151       11        1   2.242  2405  ...   813600        2013        2017   \n",
       "152       11        1   8.124  2193  ...   573300        2013        2017   \n",
       "153       11        1   2.373  2761  ...   403200        2013        2017   \n",
       "154       11        1   2.067  2773  ...   453600        2013        2017   \n",
       "155       11        1   2.008  2608  ...   299700        2013        2017   \n",
       "\n",
       "     DC_CTSmean  DC_Area_%  area_singl  DC_Area_v2  DC_Area__1  \\\n",
       "0     29.698587      8.128         900      186399       8.133   \n",
       "1     20.334521      6.692         900      156609       6.890   \n",
       "2     17.590514      6.293         900      143075       6.292   \n",
       "3     18.493408      6.443         900      176364       6.441   \n",
       "4     23.575460     16.791        4500     3036802      17.086   \n",
       "..          ...        ...         ...         ...         ...   \n",
       "151   42.305511     36.289         900      814213      36.316   \n",
       "152   38.465296      7.057        5401      577015       7.103   \n",
       "153   38.446785     16.991         900      404213      17.034   \n",
       "154   41.382340     21.945        1800      464972      22.495   \n",
       "155   51.667262     14.925        1799      299571      14.919   \n",
       "\n",
       "                                              geometry  CenLon_360  \n",
       "0    MULTIPOLYGON (((13.60653 47.47813, 13.60692 47...   13.614373  \n",
       "1    MULTIPOLYGON (((12.70776 47.13999, 12.70815 47...   12.718158  \n",
       "2    MULTIPOLYGON (((12.35997 47.14789, 12.36037 47...   12.370435  \n",
       "3    MULTIPOLYGON (((12.35453 47.12994, 12.35493 47...   12.343717  \n",
       "4    MULTIPOLYGON (((12.70993 47.08010, 12.71112 47...   12.698172  \n",
       "..                                                 ...         ...  \n",
       "151  MULTIPOLYGON (((6.25929 44.88545, 6.25967 44.8...    6.259492  \n",
       "152  MULTIPOLYGON (((7.00593 45.96921, 7.00709 45.9...    6.995296  \n",
       "153  MULTIPOLYGON (((7.15623 45.36957, 7.15661 45.3...    7.145103  \n",
       "154  MULTIPOLYGON (((7.12013 45.24476, 7.12090 45.2...    7.118216  \n",
       "155  MULTIPOLYGON (((6.14564 45.13193, 6.14602 45.1...    6.146433  \n",
       "\n",
       "[156 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debris cover extent shapefile with statistics\n",
    "dc_shp = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[debris_prms.roi])\n",
    "dc_shp = dc_shp.sort_values(by=['RGIId'])\n",
    "\n",
    "# Subset by percent debris-covered or debris-covered area\n",
    "dc_shp_subset = dc_shp[((dc_shp['DC_Area__1'] > debris_prms.dc_percarea_threshold) | \n",
    "                        (dc_shp['DC_Area_v2'] / 1e6 > debris_prms.dc_area_threshold))\n",
    "                        & (dc_shp['Area'] > debris_prms.min_glac_area)].copy()\n",
    "dc_shp_subset.reset_index(inplace=True, drop=True)\n",
    "dc_shp_subset['CenLon_360'] = dc_shp_subset['CenLon']\n",
    "dc_shp_subset.loc[dc_shp_subset['CenLon_360'] < 0, 'CenLon_360'] = (\n",
    "    360 + dc_shp_subset.loc[dc_shp_subset['CenLon_360'] < 0, 'CenLon_360'])\n",
    "print(dc_shp_subset.RGIId.values)\n",
    "dc_shp_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 glaciers in region 11 are included in this model run: ['00002', '00047', '00054', '00068', '00106', '00110', '00116', '00135', '00141', '00190', '00199', '00233', '00278', '00376', '00415', '00459', '00469', '00487', '00524', '00541', '00597', '00719', '00781', '00797', '00830', '00846', '00871', '00886', '00887', '00897', '00918', '00929', '00932', '00943', '00945', '00950', '00957', '00958', '01144', '01187', '01193', '01246', '01275', '01296', '01328', '01346', '01450', '01478', '01509', '01550'] and more\n",
      "This study is focusing on 156 glaciers in region [11]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O1Index</th>\n",
       "      <th>RGIId</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>Zmax</th>\n",
       "      <th>Zmed</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Lmax</th>\n",
       "      <th>Form</th>\n",
       "      <th>TermType</th>\n",
       "      <th>Surging</th>\n",
       "      <th>RefDate</th>\n",
       "      <th>glacno</th>\n",
       "      <th>rgino_str</th>\n",
       "      <th>RGIId_float</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlacNo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RGI60-11.00002</td>\n",
       "      <td>13.613500</td>\n",
       "      <td>47.484500</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.292</td>\n",
       "      <td>2203</td>\n",
       "      <td>2855</td>\n",
       "      <td>2526</td>\n",
       "      <td>18.6</td>\n",
       "      <td>49</td>\n",
       "      <td>1853</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20039999</td>\n",
       "      <td>2</td>\n",
       "      <td>11.00002</td>\n",
       "      <td>11.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>RGI60-11.00047</td>\n",
       "      <td>12.719400</td>\n",
       "      <td>47.138600</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2307</td>\n",
       "      <td>3253</td>\n",
       "      <td>2967</td>\n",
       "      <td>21.1</td>\n",
       "      <td>342</td>\n",
       "      <td>2336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20039999</td>\n",
       "      <td>47</td>\n",
       "      <td>11.00047</td>\n",
       "      <td>11.00047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>RGI60-11.00054</td>\n",
       "      <td>12.371700</td>\n",
       "      <td>47.148700</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.274</td>\n",
       "      <td>2359</td>\n",
       "      <td>3196</td>\n",
       "      <td>2779</td>\n",
       "      <td>27.1</td>\n",
       "      <td>17</td>\n",
       "      <td>1765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20039999</td>\n",
       "      <td>54</td>\n",
       "      <td>11.00054</td>\n",
       "      <td>11.00054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>RGI60-11.00068</td>\n",
       "      <td>12.345300</td>\n",
       "      <td>47.132200</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.738</td>\n",
       "      <td>2162</td>\n",
       "      <td>3440</td>\n",
       "      <td>2759</td>\n",
       "      <td>15.2</td>\n",
       "      <td>347</td>\n",
       "      <td>5390</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20039999</td>\n",
       "      <td>68</td>\n",
       "      <td>11.00068</td>\n",
       "      <td>11.00068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>RGI60-11.00106</td>\n",
       "      <td>12.696700</td>\n",
       "      <td>47.099100</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>17.774</td>\n",
       "      <td>2086</td>\n",
       "      <td>3487</td>\n",
       "      <td>2984</td>\n",
       "      <td>15.9</td>\n",
       "      <td>112</td>\n",
       "      <td>8667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20039999</td>\n",
       "      <td>106</td>\n",
       "      <td>11.00106</td>\n",
       "      <td>11.00106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>3693</td>\n",
       "      <td>RGI60-11.03694</td>\n",
       "      <td>6.263000</td>\n",
       "      <td>44.892000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2405</td>\n",
       "      <td>3301</td>\n",
       "      <td>2839</td>\n",
       "      <td>31.9</td>\n",
       "      <td>18</td>\n",
       "      <td>1678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20030813</td>\n",
       "      <td>3694</td>\n",
       "      <td>11.03694</td>\n",
       "      <td>11.03694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3697</td>\n",
       "      <td>RGI60-11.03698</td>\n",
       "      <td>6.988000</td>\n",
       "      <td>45.987000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8.124</td>\n",
       "      <td>2193</td>\n",
       "      <td>3707</td>\n",
       "      <td>2977</td>\n",
       "      <td>19.0</td>\n",
       "      <td>309</td>\n",
       "      <td>4112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20030813</td>\n",
       "      <td>3698</td>\n",
       "      <td>11.03698</td>\n",
       "      <td>11.03698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>3700</td>\n",
       "      <td>RGI60-11.03701</td>\n",
       "      <td>7.144000</td>\n",
       "      <td>45.371000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.373</td>\n",
       "      <td>2761</td>\n",
       "      <td>3340</td>\n",
       "      <td>3046</td>\n",
       "      <td>16.5</td>\n",
       "      <td>285</td>\n",
       "      <td>1706</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20030813</td>\n",
       "      <td>3701</td>\n",
       "      <td>11.03701</td>\n",
       "      <td>11.03701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>3739</td>\n",
       "      <td>RGI60-11.03740</td>\n",
       "      <td>7.122775</td>\n",
       "      <td>45.252968</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.067</td>\n",
       "      <td>2773</td>\n",
       "      <td>3310</td>\n",
       "      <td>3026</td>\n",
       "      <td>13.1</td>\n",
       "      <td>340</td>\n",
       "      <td>2705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20030813</td>\n",
       "      <td>3740</td>\n",
       "      <td>11.03740</td>\n",
       "      <td>11.03740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>3759</td>\n",
       "      <td>RGI60-11.03760</td>\n",
       "      <td>6.146941</td>\n",
       "      <td>45.146187</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.008</td>\n",
       "      <td>2608</td>\n",
       "      <td>3387</td>\n",
       "      <td>2945</td>\n",
       "      <td>21.5</td>\n",
       "      <td>98</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20030813</td>\n",
       "      <td>3760</td>\n",
       "      <td>11.03760</td>\n",
       "      <td>11.03760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        O1Index           RGIId     CenLon     CenLat  O1Region  O2Region  \\\n",
       "GlacNo                                                                      \n",
       "0             1  RGI60-11.00002  13.613500  47.484500        11         1   \n",
       "1            46  RGI60-11.00047  12.719400  47.138600        11         1   \n",
       "2            53  RGI60-11.00054  12.371700  47.148700        11         1   \n",
       "3            67  RGI60-11.00068  12.345300  47.132200        11         1   \n",
       "4           105  RGI60-11.00106  12.696700  47.099100        11         1   \n",
       "...         ...             ...        ...        ...       ...       ...   \n",
       "151        3693  RGI60-11.03694   6.263000  44.892000        11         1   \n",
       "152        3697  RGI60-11.03698   6.988000  45.987000        11         1   \n",
       "153        3700  RGI60-11.03701   7.144000  45.371000        11         1   \n",
       "154        3739  RGI60-11.03740   7.122775  45.252968        11         1   \n",
       "155        3759  RGI60-11.03760   6.146941  45.146187        11         1   \n",
       "\n",
       "          Area  Zmin  Zmax  Zmed  Slope  Aspect  Lmax  Form  TermType  \\\n",
       "GlacNo                                                                  \n",
       "0        2.292  2203  2855  2526   18.6      49  1853     0         0   \n",
       "1        2.273  2307  3253  2967   21.1     342  2336     0         0   \n",
       "2        2.274  2359  3196  2779   27.1      17  1765     0         0   \n",
       "3        2.738  2162  3440  2759   15.2     347  5390     0         0   \n",
       "4       17.774  2086  3487  2984   15.9     112  8667     0         0   \n",
       "...        ...   ...   ...   ...    ...     ...   ...   ...       ...   \n",
       "151      2.242  2405  3301  2839   31.9      18  1678     0         0   \n",
       "152      8.124  2193  3707  2977   19.0     309  4112     0         0   \n",
       "153      2.373  2761  3340  3046   16.5     285  1706     0         0   \n",
       "154      2.067  2773  3310  3026   13.1     340  2705     0         0   \n",
       "155      2.008  2608  3387  2945   21.5      98  2004     0         0   \n",
       "\n",
       "        Surging   RefDate  glacno rgino_str  RGIId_float  \n",
       "GlacNo                                                    \n",
       "0             9  20039999       2  11.00002     11.00002  \n",
       "1             9  20039999      47  11.00047     11.00047  \n",
       "2             9  20039999      54  11.00054     11.00054  \n",
       "3             9  20039999      68  11.00068     11.00068  \n",
       "4             9  20039999     106  11.00106     11.00106  \n",
       "...         ...       ...     ...       ...          ...  \n",
       "151           9  20030813    3694  11.03694     11.03694  \n",
       "152           9  20030813    3698  11.03698     11.03698  \n",
       "153           9  20030813    3701  11.03701     11.03701  \n",
       "154           9  20030813    3740  11.03740     11.03740  \n",
       "155           9  20030813    3760  11.03760     11.03760  \n",
       "\n",
       "[156 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgiid_list = [x.split('-')[1] for x in dc_shp_subset['RGIId'].values]\n",
    "main_glac_rgi_subset = debris_prms.selectglaciersrgitable(rgiid_list)\n",
    "main_glac_rgi_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(main_glac_rgi_subset.rgino_str == '15.03473')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 120 RGI60-11.03005\n",
      "\n",
      "\n",
      "HACK TO BYPASS VALID AREA\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== PROCESS EACH GLACIER =====\n",
    "# for nglac, glac_idx in enumerate(main_glac_rgi_subset.index.values):\n",
    "for nglac, glac_idx in enumerate([main_glac_rgi_subset.index.values[120]]): # Miage\n",
    "# for nglac, glac_idx in enumerate([main_glac_rgi_subset.index.values[2307]]): # Ngozumpa\n",
    "\n",
    "    glac_str = main_glac_rgi_subset.loc[glac_idx,'rgino_str']\n",
    "    rgiid = main_glac_rgi_subset.loc[glac_idx,'RGIId']\n",
    "    region = glac_str.split('.')[0]\n",
    "\n",
    "    if int(region) < 10:\n",
    "        glac_str_noleadzero = str(int(glac_str.split('.')[0])) + '.' + glac_str.split('.')[1]\n",
    "    else:\n",
    "        glac_str_noleadzero = glac_str\n",
    "\n",
    "    if os.path.exists(debris_prms.hd_fp + debris_prms.hd_fn_sample.replace('XXXX',glac_str_noleadzero)) == False:\n",
    "\n",
    "        print(nglac, glac_idx, rgiid)\n",
    "\n",
    "        # ===== Project shapefile =====\n",
    "        thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "        thick_fn = rgiid + '_thickness.tif'\n",
    "\n",
    "        proj_fn = os.path.join(thick_dir, thick_fn) # THIS PROJECTION IS KEY!\n",
    "        ds = gdal.Open(proj_fn)\n",
    "        prj = ds.GetProjection()\n",
    "        srs = osr.SpatialReference(wkt=prj)\n",
    "        aea_srs = srs\n",
    "\n",
    "        # Shape layer processing\n",
    "        # If projected shapefile already exists, then skip projection\n",
    "        glac_shp_proj_fn = (debris_prms.glac_shp_proj_fp + glac_str + '_crs' + \n",
    "                            str(aea_srs.GetAttrValue(\"AUTHORITY\", 1)) + '.shp')\n",
    "        dc_shp_proj_fn = (debris_prms.glac_shp_proj_fp + glac_str + '_dc_crs' + \n",
    "                          str(aea_srs.GetAttrValue(\"AUTHORITY\", 1)) + '.shp')\n",
    "        if os.path.exists(glac_shp_proj_fn) == False:\n",
    "            glac_shp_init = gpd.read_file(debris_prms.glac_shp_fn_dict[region])\n",
    "            if verbose:\n",
    "                print('Shp init crs:', glac_shp_init.crs)\n",
    "            glac_shp_single = glac_shp_init[glac_shp_init['RGIId'] == rgiid]\n",
    "            glac_shp_single = glac_shp_single.reset_index()\n",
    "            glac_shp_proj = glac_shp_single.to_crs({'init': 'epsg:' + str(aea_srs.GetAttrValue(\"AUTHORITY\", 1))})\n",
    "            glac_shp_proj.to_file(glac_shp_proj_fn)\n",
    "\n",
    "        if os.path.exists(dc_shp_proj_fn) == False:\n",
    "            dc_shp_init = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[debris_prms.roi])\n",
    "            dc_shp_single = dc_shp_init[dc_shp_init['RGIId'] == rgiid]\n",
    "            dc_shp_single = dc_shp_single.reset_index()\n",
    "            dc_shp_proj = dc_shp_single.to_crs({'init': 'epsg:' + str(aea_srs.GetAttrValue(\"AUTHORITY\", 1))})\n",
    "            dc_shp_proj.to_file(dc_shp_proj_fn)\n",
    "\n",
    "        glac_shp_ds = ogr.Open(glac_shp_proj_fn, 0)\n",
    "        glac_shp_lyr = glac_shp_ds.GetLayer()\n",
    "        #This should be contained in features\n",
    "        glac_shp_srs = glac_shp_lyr.GetSpatialRef()\n",
    "        feat_count = glac_shp_lyr.GetFeatureCount()\n",
    "        if verbose:\n",
    "            print(\"Input glacier polygon count: %i\" % feat_count)\n",
    "\n",
    "        dc_shp_ds = ogr.Open(dc_shp_proj_fn, 0)\n",
    "        dc_shp_lyr = dc_shp_ds.GetLayer()\n",
    "        #This should be contained in features\n",
    "        dc_shp_srs = dc_shp_lyr.GetSpatialRef()\n",
    "        feat_count = dc_shp_lyr.GetFeatureCount()\n",
    "        if verbose:\n",
    "            print(\"Input glacier polygon count (debris cover): %i\" % feat_count)\n",
    "\n",
    "        # Load DEM\n",
    "        z1_dir = debris_prms.oggm_fp + 'dems/RGI60-' + str(region.zfill(2)) + '/'\n",
    "        z1_fn = rgiid + '_dem.tif'\n",
    "        z1_ds = gdal.Open(z1_dir + z1_fn)\n",
    "        z1_int_geom = geolib.ds_geom_intersection([z1_ds, z1_ds], t_srs=glac_shp_srs)\n",
    "\n",
    "        glacname_fieldname = \"Name\"\n",
    "        glacnum_fieldname = \"RGIId\"\n",
    "        glacnum_fmt = '%08.5f'\n",
    "\n",
    "        for n, feat in enumerate(glac_shp_lyr):\n",
    "            gf = GlacFeat(feat, glacname_fieldname, glacnum_fieldname)\n",
    "            if verbose:\n",
    "                print(\"%i of %i: %s\" % (n+1, feat_count, gf.feat_fn))\n",
    "            #NOTE: Input must be in projected coordinate system, ideally equal area\n",
    "            #Should check this and reproject\n",
    "            gf.geom_attributes(srs=aea_srs)\n",
    "\n",
    "        if verbose:\n",
    "            print(gf.feat_fn)\n",
    "\n",
    "\n",
    "        fn_dict = OrderedDict()\n",
    "        #We at least want to warp the two input DEMs\n",
    "        fn_dict['z1'] = os.path.join(z1_dir, z1_fn)\n",
    "\n",
    "        if extra_layers and (gf.glac_area_km2 > debris_prms.min_glac_area_writeout):\n",
    "            if verbose:\n",
    "                print(gf.glacnum)\n",
    "                \n",
    "            dhdt_fn = debris_prms.dhdt_fn_dict[debris_prms.roi]\n",
    "            if dhdt_fn is not None:\n",
    "                fn_dict['dhdt'] = dhdt_fn\n",
    "\n",
    "            # Ice thickness data\n",
    "            ice_thick_fn = os.path.join(thick_dir, thick_fn)\n",
    "            if os.path.exists(ice_thick_fn):\n",
    "                fn_dict['ice_thick'] = ice_thick_fn\n",
    "\n",
    "            if os.path.exists(debris_prms.v_dir + debris_prms.vx_fn_dict[debris_prms.roi]):\n",
    "                fn_dict['vx'] = debris_prms.v_dir + debris_prms.vx_fn_dict[debris_prms.roi]\n",
    "                fn_dict['vy'] = debris_prms.v_dir + debris_prms.vy_fn_dict[debris_prms.roi]\n",
    "\n",
    "            if os.path.exists(debris_prms.ts_fp + debris_prms.ts_fn_dict[debris_prms.roi]):\n",
    "                fn_dict['ts'] = debris_prms.ts_fp + debris_prms.ts_fn_dict[debris_prms.roi]\n",
    "\n",
    "\n",
    "        #Expand extent to include buffered region around glacier polygon\n",
    "        warp_extent = geolib.pad_extent(gf.glac_geom_extent, width=debris_prms.buff_dist)\n",
    "        if verbose:\n",
    "            print(\"Expanding extent\")\n",
    "            print(gf.glac_geom_extent)\n",
    "            print(warp_extent)\n",
    "            print(aea_srs)\n",
    "\n",
    "        #Warp everything to common res/extent/proj\n",
    "        z1_gt = gdal.Open(fn_dict['z1']).GetGeoTransform()\n",
    "        z1_res = np.min([z1_gt[1], -z1_gt[5]])\n",
    "        ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, \\\n",
    "                extent=warp_extent, t_srs=aea_srs, verbose=verbose, \\\n",
    "                r='cubic')\n",
    "        ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "\n",
    "        if verbose:\n",
    "            print(ds_list)\n",
    "            print(fn_dict.keys())\n",
    "\n",
    "        #Prepare mask for all glaciers within buffered area, not just the current glacier polygon\n",
    "        glac_shp_ds = ogr.Open(glac_shp_proj_fn, 0)\n",
    "        glac_shp_lyr = glac_shp_ds.GetLayer()\n",
    "        dc_shp_ds = ogr.Open(dc_shp_proj_fn, 0)\n",
    "        dc_shp_lyr = dc_shp_ds.GetLayer()\n",
    "\n",
    "        #Get global glacier mask\n",
    "        #Want this to be True over ALL glacier surfaces, not just the current polygon\n",
    "        glac_shp_lyr_mask = geolib.lyr2mask(glac_shp_lyr, ds_dict['ice_thick'])\n",
    "        dc_shp_lyr_mask = geolib.lyr2mask(dc_shp_lyr, ds_dict['ice_thick'])\n",
    "\n",
    "        #Create buffer around glacier polygon\n",
    "        glac_geom_buff = gf.glac_geom.Buffer(debris_prms.buff_dist)\n",
    "        #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "        glac_geom_buff_mask = geolib.geom2mask(glac_geom_buff, ds_dict['ice_thick'])\n",
    "\n",
    "        # ds masks\n",
    "        ds_list_masked = [iolib.ds_getma(i) for i in ds_list]\n",
    "        dem1 = np.ma.masked_less_equal(ds_list_masked[0], 0)\n",
    "        dems_mask = dem1.mask\n",
    "        if verbose:\n",
    "            print('list of datasets:', len(ds_list_masked), fn_dict.values())\n",
    "\n",
    "        #Combine to identify ~1 km buffer around glacier polygon over static rock\n",
    "        static_buffer_mask = np.ma.mask_or(~glac_shp_lyr_mask, glac_geom_buff_mask)\n",
    "        static_shp_lyr_mask = np.ma.mask_or(static_buffer_mask, dems_mask)\n",
    "\n",
    "        if 'z1' in ds_dict:\n",
    "            #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "            glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1'])\n",
    "            gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']))\n",
    "            #gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "            \n",
    "            gf.res = geolib.get_res(ds_dict['z1'])\n",
    "\n",
    "            # Debris cover\n",
    "            dc_mask = np.ma.mask_or(dc_shp_lyr_mask, glac_geom_mask)\n",
    "            gf.dc_area = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=dc_mask)\n",
    "\n",
    "#             # Check if DEM has huge errors or not - replace if necessary\n",
    "#             if input.roi in ['01']:\n",
    "\n",
    "#                 gf.z1_check = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "#                 if gf.z1_check.min() < 0:\n",
    "\n",
    "#                     # Add backup DEM for regions with known poor quality (ex. Alaska)\n",
    "#                     print('switching DEMs')\n",
    "#                     fn_dict['z1_backup'] = input.z1_backup_dict[input.roi]\n",
    "#                     # Warp everything to common res/extent/proj (a second time)\n",
    "#                     ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, \\\n",
    "#                             extent=warp_extent, t_srs=aea_srs, verbose=verbose, \\\n",
    "#                             r='cubic')\n",
    "#                     ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "\n",
    "#                     if verbose:\n",
    "#                         print(ds_list)\n",
    "#                         print(fn_dict.keys())\n",
    "\n",
    "#                     # ds masks\n",
    "#                     ds_list_masked = [iolib.ds_getma(i) for i in ds_list]\n",
    "#                     dem1 = np.ma.masked_less_equal(ds_list_masked[-1], 0)\n",
    "#                     dems_mask = dem1.mask\n",
    "#                     if verbose:\n",
    "#                         print('list of datasets:', len(ds_list_masked), fn_dict.values())\n",
    "\n",
    "#                     #Combine to identify ~1 km buffer around glacier polygon over static rock\n",
    "#                     static_buffer_mask = np.ma.mask_or(~glac_shp_lyr_mask, glac_geom_buff_mask)\n",
    "#                     static_shp_lyr_mask = np.ma.mask_or(static_buffer_mask, dems_mask)\n",
    "\n",
    "#                     #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "#                     glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1_backup'])\n",
    "#                     gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1_backup']), mask=glac_geom_mask)\n",
    "#                     #gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "\n",
    "#                     # Debris cover\n",
    "#                     dc_mask = np.ma.mask_or(dc_shp_lyr_mask, glac_geom_mask)\n",
    "#                     gf.dc_area = np.ma.array(iolib.ds_getma(ds_dict['z1_backup']), mask=dc_mask)\n",
    "\n",
    "\n",
    "            if verbose:\n",
    "                print('\\n\\n# z1 pixels:', gf.z1.count(), '\\n')\n",
    "            if gf.z1.count() == 0:\n",
    "                if verbose:\n",
    "                    print(\"No z1 pixels\")\n",
    "        else:\n",
    "            print(\"Unable to load z1 ds\")\n",
    "\n",
    "        # ===== ADD VARIOUS LAYERS TO gf =====\n",
    "        if nglac == 0:\n",
    "            print('\\n\\nHACK TO BYPASS VALID AREA\\n\\n')\n",
    "        gf.valid_area_perc = 100\n",
    "\n",
    "        if gf.valid_area_perc < (100. * debris_prms.min_valid_area_perc):\n",
    "            if verbose:\n",
    "                print(\"Not enough valid pixels. %0.1f%% percent of glacier polygon area\" % (gf.valid_area_perc))\n",
    "        #     return None\n",
    "\n",
    "        else:\n",
    "            #Filter dz - throw out abs differences >150 m\n",
    "\n",
    "            #Compute dz, volume change, mass balance and stats\n",
    "            gf.z1_stats = malib.get_stats(gf.z1)\n",
    "            z1_elev_med = gf.z1_stats[5]\n",
    "            z1_elev_min, z1_elev_max = malib.calcperc(gf.z1, (0.1, 99.9))\n",
    "\n",
    "            #Caluclate stats for aspect and slope using z2\n",
    "            #Requires GDAL 2.1+\n",
    "            gf.z1_aspect = np.ma.array(geolib.gdaldem_mem_ds(ds_dict['z1'], processing='aspect', returnma=True), \n",
    "                                       mask=glac_geom_mask)\n",
    "            gf.z1_aspect_stats = malib.get_stats(gf.z1_aspect)\n",
    "            z1_aspect_med = gf.z1_aspect_stats[5]\n",
    "            gf.z1_slope = np.ma.array(geolib.gdaldem_mem_ds(ds_dict['z1'], processing='slope', returnma=True), \n",
    "                                      mask=glac_geom_mask)\n",
    "            gf.z1_slope_stats = malib.get_stats(gf.z1_slope)\n",
    "            z1_slope_med = gf.z1_slope_stats[5]\n",
    "\n",
    "            #Can estimate ELA values computed from hypsometry and typical AAR\n",
    "            #For now, assume ELA is mean\n",
    "            gf.z1_ela = None\n",
    "            gf.z1_ela = gf.z1_stats[3]\n",
    "            #Note: in theory, the ELA should get higher with mass loss\n",
    "            #In practice, using mean and same polygon, ELA gets lower as glacier surface thins\n",
    "\n",
    "            # copy for Ts because it change the mask otherwise and messes up binned statistics for whole glacier\n",
    "            glac_geom_mask_copy = glac_geom_mask.copy()\n",
    "\n",
    "            if extra_layers and (gf.glac_area_km2 > debris_prms.min_glac_area_writeout):\n",
    "                if 'ice_thick' in ds_dict:\n",
    "                    #Load ice thickness\n",
    "                    gf.H = np.ma.array(iolib.ds_getma(ds_dict['ice_thick']), mask=glac_geom_mask)\n",
    "                    gf.H_mean = gf.H.mean()\n",
    "                    if verbose:\n",
    "                        print('mean ice thickness [m]:', gf.H_mean)\n",
    "\n",
    "                if 'vx' in ds_dict and 'vy' in ds_dict:\n",
    "                    #Load surface velocity maps\n",
    "                    gf.vx = np.ma.array(iolib.ds_getma(ds_dict['vx']), mask=glac_geom_mask)\n",
    "                    gf.vy = np.ma.array(iolib.ds_getma(ds_dict['vy']), mask=glac_geom_mask)\n",
    "                    gf.vm = np.ma.sqrt(gf.vx**2 + gf.vy**2)\n",
    "                    gf.vm_mean = gf.vm.mean()\n",
    "                    if verbose:\n",
    "                        print('mean velocity [m/s]:', gf.vm_mean)\n",
    "\n",
    "                    if gf.H is not None:\n",
    "                        #Compute flux\n",
    "                        gf.Q = gf.H * debris_prms.v_col_f * np.array([gf.vx, gf.vy])\n",
    "                        #Note: np.gradient returns derivatives relative to axis number, so (y, x) in this case\n",
    "                        #Want x-derivative of x component\n",
    "                        gf.divQ = np.gradient(gf.Q[0])[1] + np.gradient(gf.Q[1])[0]\n",
    "\n",
    "        #                 gf.divQ = gf.H*(np.gradient(v_col_f*gf.vx)[1] + np.gradient(v_col_f*gf.vy)[0]) \\\n",
    "        #                         + v_col_f*gf.vx*(np.gradient(gf.H)[1]) + v_col_f*gf.vy*(np.gradient(gf.H)[0])\n",
    "\n",
    "                        #Should smooth divQ, better handling of data gaps\n",
    "            \n",
    "                # Emergence velocity\n",
    "                if calc_emergence and 'vx' in ds_dict and 'vy' in ds_dict and gf.H is not None:\n",
    "                    vx = np.ma.filled(gf.vx,0)\n",
    "                    vy = np.ma.filled(gf.vy,0)\n",
    "                    H = np.ma.filled(gf.H,0)\n",
    "                    vx[gf.z1 > gf.z1.max()] = 0\n",
    "                    vy[gf.z1 > gf.z1.max()] = 0\n",
    "                    H[gf.z1 > gf.z1.max()] = 0\n",
    "                    vmax = np.nanmax((vx**2 + vy**2)**0.5)\n",
    "\n",
    "                    # Emergence computation\n",
    "                    emvel = emergence_pixels(gf, vx, vy, H, gf.res[0], gf.res[1], \n",
    "                                             positive_is_east=True, positive_is_north=True, \n",
    "                                             constant_icethickness=False, max_velocity=vmax, vel_min=0, debug=False)\n",
    "                    # 3x3 filter to reduce\n",
    "                    if debris_prms.emvel_filter_pixsize > 0:\n",
    "                        emvel = ndimage.filters.convolve(\n",
    "                            emvel, weights=np.full((debris_prms.emvel_filter_pixsize, \n",
    "                                                    debris_prms.emvel_filter_pixsize), \n",
    "                                                    1.0/debris_prms.emvel_filter_pixsize**2))\n",
    "                    # Add to glacier feature\n",
    "                    gf.emvel = np.ma.masked_array(emvel, mask=np.ma.getmask(gf.z1))\n",
    "\n",
    "                if 'ts' in ds_dict:\n",
    "                    #Load surface temperature maps\n",
    "                    gf.ts = np.ma.array(iolib.ds_getma(ds_dict['ts']), mask=glac_geom_mask_copy)\n",
    "                    gf.ts.mask = np.ma.mask_or(glac_geom_mask, \n",
    "                                               np.ma.getmask(np.ma.masked_array(gf.ts.data, np.isnan(gf.ts.data))))\n",
    "                else:\n",
    "                    gf.ts = None\n",
    "                    \n",
    "                if 'dhdt' in ds_dict:\n",
    "                    gf.dhdt = np.ma.array(iolib.ds_getma(ds_dict['dhdt']), mask=glac_geom_mask_copy)\n",
    "                    gf.dhdt.mask = np.ma.mask_or(\n",
    "                        glac_geom_mask, np.ma.getmask(np.ma.masked_array(gf.dhdt.data, np.isnan(gf.dhdt.data))))\n",
    "                    gf.mb = gf.dhdt.copy() * debris_prms.density_ice / debris_prms.density_water\n",
    "                    \n",
    "                    # Debris only\n",
    "                    gf.dc_dhdt = np.ma.array(iolib.ds_getma(ds_dict['dhdt']), mask=glac_geom_mask_copy)\n",
    "                    gf.dc_dhdt.mask = dc_mask\n",
    "                    gf.dc_mb = gf.dc_dhdt.copy() * debris_prms.density_ice / debris_prms.density_water\n",
    "\n",
    "                if 'debris_thick_ts' in ds_dict:\n",
    "                    # Load debris thickness map\n",
    "                    gf.debris_thick_ts = np.ma.array(\n",
    "                        iolib.ds_getma(ds_dict['debris_thick_ts']), mask=glac_geom_mask_copy)\n",
    "                    gf.meltfactor_ts = None\n",
    "                else:\n",
    "                    gf.debris_thick_ts = None\n",
    "                    gf.meltfactor_ts = None\n",
    "\n",
    "            if verbose:\n",
    "                print('Area [km2]:', gf.glac_area / 1e6)\n",
    "                print('-------------------------------')\n",
    "\n",
    "\n",
    "            gf.z1 = np.ma.array(gf.z1, mask=glac_geom_mask)\n",
    "\n",
    "#             # ===== PLOTS =====\n",
    "#             titles = [glac_str + ' DEM']\n",
    "#             var_full2plot = gf.z1.copy()\n",
    "#             clim = malib.calcperc(var_full2plot, (2,98))\n",
    "#             plot_array(var_full2plot, clim, titles, 'inferno', 'elev (masl)', \n",
    "#                        close_fig=False)\n",
    "            \n",
    "#             titles = [glac_str + ' velocity']\n",
    "#             var_full2plot = (gf.vx.copy()**2 + gf.vy.copy()**2)**0.5\n",
    "#             clim = malib.calcperc(var_full2plot, (2,98))\n",
    "#             plot_array(var_full2plot, clim, titles, 'inferno', 'vel (m/yr)', \n",
    "#                        close_fig=False)\n",
    "            \n",
    "#             titles = [glac_str + ' emvel']\n",
    "#             var_full2plot = gf.emvel.copy()\n",
    "#             clim = malib.calcperc(var_full2plot, (2,98))\n",
    "#             plot_array(var_full2plot, clim, titles, 'inferno', 'emvel (m/yr)', \n",
    "#                        close_fig=False)\n",
    "            \n",
    "#             titles = [glac_str + ' Ts']\n",
    "#             var_full2plot = gf.ts.copy()\n",
    "#             clim = malib.calcperc(var_full2plot, (2,98))\n",
    "#             plot_array(var_full2plot, clim, titles, 'inferno', 'ts (degC)', \n",
    "#                        close_fig=False)\n",
    "            \n",
    "#             titles = [glac_str + ' dhdt']\n",
    "#             var_full2plot = gf.dhdt.copy()\n",
    "#             clim = malib.calcperc(var_full2plot, (2,98))\n",
    "#             plot_array(var_full2plot, clim, titles, 'inferno', 'dhdt (m/yr)', \n",
    "#                        close_fig=False)\n",
    "\n",
    "            # Bin data\n",
    "            outbins_df, z_bin_edges = gf.hist_plot(bin_width=debris_prms.mb_bin_size, exportcsv=True, \n",
    "                                                   outdir_csv=outdir_csv, csv_ending=csv_ending)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debris_thickness_global]",
   "language": "python",
   "name": "conda-env-debris_thickness_global-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
