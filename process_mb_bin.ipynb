{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate a 3-panel plot for input arrays\n",
    "def plot_array(dem, clim=None, titles=None, cmap='inferno', label=None, overlay=None, fn=None, close_fig=True):\n",
    "    fig, ax = plt.subplots(1,1, sharex=True, sharey=True, figsize=(10,5))\n",
    "    alpha = 1.0\n",
    "    #Gray background\n",
    "    ax.set_facecolor('0.5')\n",
    "    #Force aspect ratio to match images\n",
    "    ax.set(aspect='equal')\n",
    "    #Turn off axes labels/ticks\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if titles is not None:\n",
    "        ax.set_title(titles[0])\n",
    "    #Plot background shaded relief map\n",
    "    if overlay is not None:\n",
    "        alpha = 0.7\n",
    "        ax.imshow(overlay, cmap='gray', clim=(1,255))\n",
    "    #Plot each array\n",
    "    im_list = [ax.imshow(dem, clim=clim, cmap=cmap, alpha=alpha)]\n",
    "    fig.tight_layout()\n",
    "    fig.colorbar(im_list[0], label=label, extend='both', shrink=0.5)\n",
    "    if fn is not None:\n",
    "        fig.savefig(fn, bbox_inches='tight', pad_inches=0, dpi=150)\n",
    "    if close_fig:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "Compute debris thickness through sub-debris and temperature inversion methods\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from scipy import ndimage\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import median_absolute_deviation\n",
    "import xarray as xr\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "from pygeotools.lib import malib, warplib, geolib, iolib, timelib\n",
    "\n",
    "\n",
    "import debrisglobal.globaldebris_input as debris_prms\n",
    "from debrisglobal.glacfeat import GlacFeat, create_glacfeat\n",
    "\n",
    "calc_emergence = True\n",
    "\n",
    "debug=False\n",
    "extra_layers=True\n",
    "\n",
    "csv_ending = '_mb_bins.csv'\n",
    "outdir_csv = debris_prms.mb_binned_fp\n",
    "if os.path.exists(outdir_csv) == False:\n",
    "    os.makedirs(outdir_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219 glaciers in region 2 are included in this model run: ['00280', '00737', '00914', '01104', '01152', '01158', '01161', '01290', '01291', '01297', '01339', '01397', '01441', '01654', '01665', '01685', '01727', '01811', '01812', '01922', '01923', '02107', '02348', '02360', '02386', '02432', '02526', '02527', '02533', '02550', '02551', '02616', '02636', '02686', '02745', '02747', '02752', '02784', '02857', '02894', '02897', '02947', '02948', '02966', '03099', '03102', '03157', '03520', '03578', '03581'] and more\n",
      "This study is focusing on 219 glaciers in region [2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O1Index</th>\n",
       "      <th>RGIId</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>Zmax</th>\n",
       "      <th>Zmed</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Lmax</th>\n",
       "      <th>Form</th>\n",
       "      <th>TermType</th>\n",
       "      <th>Surging</th>\n",
       "      <th>RefDate</th>\n",
       "      <th>glacno</th>\n",
       "      <th>rgino_str</th>\n",
       "      <th>RGIId_float</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlacNo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>279</td>\n",
       "      <td>RGI60-02.00280</td>\n",
       "      <td>-122.57300</td>\n",
       "      <td>49.88620</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.938</td>\n",
       "      <td>1671</td>\n",
       "      <td>2340</td>\n",
       "      <td>1949</td>\n",
       "      <td>14.2</td>\n",
       "      <td>31</td>\n",
       "      <td>4652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20059999</td>\n",
       "      <td>280</td>\n",
       "      <td>02.00280</td>\n",
       "      <td>2.00280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>736</td>\n",
       "      <td>RGI60-02.00737</td>\n",
       "      <td>-116.52800</td>\n",
       "      <td>50.21440</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5.536</td>\n",
       "      <td>2237</td>\n",
       "      <td>3104</td>\n",
       "      <td>2586</td>\n",
       "      <td>13.6</td>\n",
       "      <td>358</td>\n",
       "      <td>4427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20059999</td>\n",
       "      <td>737</td>\n",
       "      <td>02.00737</td>\n",
       "      <td>2.00737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>913</td>\n",
       "      <td>RGI60-02.00914</td>\n",
       "      <td>-123.85700</td>\n",
       "      <td>50.31570</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.372</td>\n",
       "      <td>1056</td>\n",
       "      <td>2233</td>\n",
       "      <td>1486</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20059999</td>\n",
       "      <td>914</td>\n",
       "      <td>02.00914</td>\n",
       "      <td>2.00914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1103</td>\n",
       "      <td>RGI60-02.01104</td>\n",
       "      <td>-122.60500</td>\n",
       "      <td>50.41950</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.016</td>\n",
       "      <td>1850</td>\n",
       "      <td>2539</td>\n",
       "      <td>2054</td>\n",
       "      <td>11.1</td>\n",
       "      <td>9</td>\n",
       "      <td>3589</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20059999</td>\n",
       "      <td>1104</td>\n",
       "      <td>02.01104</td>\n",
       "      <td>2.01104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1151</td>\n",
       "      <td>RGI60-02.01152</td>\n",
       "      <td>-123.89000</td>\n",
       "      <td>50.34100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.021</td>\n",
       "      <td>1280</td>\n",
       "      <td>2505</td>\n",
       "      <td>1908</td>\n",
       "      <td>19.4</td>\n",
       "      <td>115</td>\n",
       "      <td>5490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20059999</td>\n",
       "      <td>1152</td>\n",
       "      <td>02.01152</td>\n",
       "      <td>2.01152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>18764</td>\n",
       "      <td>RGI60-02.18765</td>\n",
       "      <td>-121.01578</td>\n",
       "      <td>48.31119</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.845</td>\n",
       "      <td>1523</td>\n",
       "      <td>2642</td>\n",
       "      <td>2125</td>\n",
       "      <td>23.4</td>\n",
       "      <td>15</td>\n",
       "      <td>3570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19589999</td>\n",
       "      <td>18765</td>\n",
       "      <td>02.18765</td>\n",
       "      <td>2.18765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>18769</td>\n",
       "      <td>RGI60-02.18770</td>\n",
       "      <td>-121.00437</td>\n",
       "      <td>48.07234</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.125</td>\n",
       "      <td>1845</td>\n",
       "      <td>2490</td>\n",
       "      <td>2253</td>\n",
       "      <td>27.5</td>\n",
       "      <td>17</td>\n",
       "      <td>1431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19849999</td>\n",
       "      <td>18770</td>\n",
       "      <td>02.18770</td>\n",
       "      <td>2.18770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>18777</td>\n",
       "      <td>RGI60-02.18778</td>\n",
       "      <td>-121.05735</td>\n",
       "      <td>48.35698</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.924</td>\n",
       "      <td>1613</td>\n",
       "      <td>2196</td>\n",
       "      <td>1891</td>\n",
       "      <td>12.8</td>\n",
       "      <td>350</td>\n",
       "      <td>3338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19589999</td>\n",
       "      <td>18778</td>\n",
       "      <td>02.18778</td>\n",
       "      <td>2.18778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>18804</td>\n",
       "      <td>RGI60-02.18805</td>\n",
       "      <td>-109.63833</td>\n",
       "      <td>43.17324</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.061</td>\n",
       "      <td>3328</td>\n",
       "      <td>4052</td>\n",
       "      <td>3600</td>\n",
       "      <td>19.4</td>\n",
       "      <td>26</td>\n",
       "      <td>2927</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19669999</td>\n",
       "      <td>18805</td>\n",
       "      <td>02.18805</td>\n",
       "      <td>2.18805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>18816</td>\n",
       "      <td>RGI60-02.18817</td>\n",
       "      <td>-121.71492</td>\n",
       "      <td>46.83292</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3.567</td>\n",
       "      <td>1617</td>\n",
       "      <td>3387</td>\n",
       "      <td>2497</td>\n",
       "      <td>21.9</td>\n",
       "      <td>113</td>\n",
       "      <td>5602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19829999</td>\n",
       "      <td>18817</td>\n",
       "      <td>02.18817</td>\n",
       "      <td>2.18817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        O1Index           RGIId     CenLon    CenLat  O1Region  O2Region  \\\n",
       "GlacNo                                                                     \n",
       "0           279  RGI60-02.00280 -122.57300  49.88620         2         2   \n",
       "1           736  RGI60-02.00737 -116.52800  50.21440         2         3   \n",
       "2           913  RGI60-02.00914 -123.85700  50.31570         2         2   \n",
       "3          1103  RGI60-02.01104 -122.60500  50.41950         2         2   \n",
       "4          1151  RGI60-02.01152 -123.89000  50.34100         2         2   \n",
       "...         ...             ...        ...       ...       ...       ...   \n",
       "214       18764  RGI60-02.18765 -121.01578  48.31119         2         4   \n",
       "215       18769  RGI60-02.18770 -121.00437  48.07234         2         4   \n",
       "216       18777  RGI60-02.18778 -121.05735  48.35698         2         4   \n",
       "217       18804  RGI60-02.18805 -109.63833  43.17324         2         5   \n",
       "218       18816  RGI60-02.18817 -121.71492  46.83292         2         4   \n",
       "\n",
       "          Area  Zmin  Zmax  Zmed  Slope  Aspect  Lmax  Form  TermType  \\\n",
       "GlacNo                                                                  \n",
       "0        5.938  1671  2340  1949   14.2      31  4652     0         0   \n",
       "1        5.536  2237  3104  2586   13.6     358  4427     0         0   \n",
       "2        4.372  1056  2233  1486   14.0       5  5531     0         0   \n",
       "3        3.016  1850  2539  2054   11.1       9  3589     0         0   \n",
       "4       12.021  1280  2505  1908   19.4     115  5490     0         0   \n",
       "...        ...   ...   ...   ...    ...     ...   ...   ...       ...   \n",
       "214      4.845  1523  2642  2125   23.4      15  3570     0         0   \n",
       "215      2.125  1845  2490  2253   27.5      17  1431     0         0   \n",
       "216      2.924  1613  2196  1891   12.8     350  3338     0         0   \n",
       "217      3.061  3328  4052  3600   19.4      26  2927     0         0   \n",
       "218      3.567  1617  3387  2497   21.9     113  5602     0         0   \n",
       "\n",
       "        Surging   RefDate  glacno rgino_str  RGIId_float  \n",
       "GlacNo                                                    \n",
       "0             0  20059999     280  02.00280      2.00280  \n",
       "1             0  20059999     737  02.00737      2.00737  \n",
       "2             0  20059999     914  02.00914      2.00914  \n",
       "3             0  20059999    1104  02.01104      2.01104  \n",
       "4             0  20059999    1152  02.01152      2.01152  \n",
       "...         ...       ...     ...       ...          ...  \n",
       "214           0  19589999   18765  02.18765      2.18765  \n",
       "215           0  19849999   18770  02.18770      2.18770  \n",
       "216           0  19589999   18778  02.18778      2.18778  \n",
       "217           0  19669999   18805  02.18805      2.18805  \n",
       "218           0  19829999   18817  02.18817      2.18817  \n",
       "\n",
       "[219 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debris cover extent shapefile with statistics\n",
    "dc_shp = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[debris_prms.roi])\n",
    "dc_shp = dc_shp.sort_values(by=['RGIId'])\n",
    "\n",
    "# Subset by percent debris-covered or debris-covered area\n",
    "dc_shp_subset = dc_shp[((dc_shp['DC_Area__1'] > debris_prms.dc_percarea_threshold) | \n",
    "                        (dc_shp['DC_Area_v2'] / 1e6 > debris_prms.dc_area_threshold))\n",
    "                        & (dc_shp['Area'] > debris_prms.min_glac_area)].copy()\n",
    "dc_shp_subset.reset_index(inplace=True, drop=True)\n",
    "dc_shp_subset['CenLon_360'] = dc_shp_subset['CenLon']\n",
    "dc_shp_subset.loc[dc_shp_subset['CenLon_360'] < 0, 'CenLon_360'] = (\n",
    "    360 + dc_shp_subset.loc[dc_shp_subset['CenLon_360'] < 0, 'CenLon_360'])\n",
    "# dc_shp_subset\n",
    "\n",
    "rgiid_list = [x.split('-')[1] for x in dc_shp_subset['RGIId'].values]\n",
    "main_glac_rgi_subset = debris_prms.selectglaciersrgitable(rgiid_list)\n",
    "main_glac_rgi_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(main_glac_rgi_subset.rgino_str == '01.09616')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 RGI60-02.00280\n",
      "1 1 RGI60-02.00737\n",
      "2 2 RGI60-02.00914\n",
      "3 3 RGI60-02.01104\n",
      "4 4 RGI60-02.01152\n",
      "5 5 RGI60-02.01158\n",
      "6 6 RGI60-02.01161\n",
      "7 7 RGI60-02.01290\n",
      "8 8 RGI60-02.01291\n",
      "9 9 RGI60-02.01297\n",
      "10 10 RGI60-02.01339\n",
      "11 11 RGI60-02.01397\n",
      "12 12 RGI60-02.01441\n",
      "13 13 RGI60-02.01654\n",
      "14 14 RGI60-02.01665\n",
      "15 15 RGI60-02.01685\n",
      "16 16 RGI60-02.01727\n",
      "17 17 RGI60-02.01811\n",
      "18 18 RGI60-02.01812\n",
      "19 19 RGI60-02.01922\n",
      "20 20 RGI60-02.01923\n",
      "21 21 RGI60-02.02107\n",
      "22 22 RGI60-02.02348\n",
      "23 23 RGI60-02.02360\n",
      "24 24 RGI60-02.02386\n",
      "25 25 RGI60-02.02432\n",
      "26 26 RGI60-02.02526\n",
      "27 27 RGI60-02.02527\n",
      "28 28 RGI60-02.02533\n",
      "29 29 RGI60-02.02550\n",
      "30 30 RGI60-02.02551\n",
      "31 31 RGI60-02.02616\n",
      "32 32 RGI60-02.02636\n",
      "33 33 RGI60-02.02686\n",
      "34 34 RGI60-02.02745\n",
      "35 35 RGI60-02.02747\n",
      "36 36 RGI60-02.02752\n",
      "37 37 RGI60-02.02784\n",
      "38 38 RGI60-02.02857\n",
      "39 39 RGI60-02.02894\n",
      "40 40 RGI60-02.02897\n",
      "41 41 RGI60-02.02947\n",
      "42 42 RGI60-02.02948\n",
      "43 43 RGI60-02.02966\n",
      "44 44 RGI60-02.03099\n",
      "45 45 RGI60-02.03102\n",
      "46 46 RGI60-02.03157\n",
      "47 47 RGI60-02.03520\n",
      "48 48 RGI60-02.03578\n",
      "49 49 RGI60-02.03581\n",
      "50 50 RGI60-02.03586\n",
      "51 51 RGI60-02.03597\n",
      "52 52 RGI60-02.03664\n",
      "53 53 RGI60-02.03769\n",
      "54 54 RGI60-02.03922\n",
      "55 55 RGI60-02.03943\n",
      "56 56 RGI60-02.03963\n",
      "57 57 RGI60-02.03995\n",
      "58 58 RGI60-02.04103\n",
      "59 59 RGI60-02.04151\n",
      "60 60 RGI60-02.04306\n",
      "61 61 RGI60-02.04341\n",
      "62 62 RGI60-02.04379\n",
      "63 63 RGI60-02.04383\n",
      "64 64 RGI60-02.04403\n",
      "65 65 RGI60-02.04407\n",
      "66 66 RGI60-02.04418\n",
      "67 67 RGI60-02.04433\n",
      "68 68 RGI60-02.04479\n",
      "69 69 RGI60-02.04497\n",
      "70 70 RGI60-02.04503\n",
      "71 71 RGI60-02.04605\n",
      "72 72 RGI60-02.04629\n",
      "73 73 RGI60-02.04651\n",
      "74 74 RGI60-02.04724\n",
      "75 75 RGI60-02.04770\n",
      "76 76 RGI60-02.04808\n",
      "77 77 RGI60-02.04859\n",
      "78 78 RGI60-02.04897\n",
      "79 79 RGI60-02.04944\n",
      "80 80 RGI60-02.05153\n",
      "81 81 RGI60-02.05157\n",
      "82 82 RGI60-02.05166\n",
      "83 83 RGI60-02.05169\n",
      "84 84 RGI60-02.05350\n",
      "85 85 RGI60-02.05370\n",
      "86 86 RGI60-02.05413\n",
      "87 87 RGI60-02.05414\n",
      "88 88 RGI60-02.05515\n",
      "89 89 RGI60-02.05625\n",
      "90 90 RGI60-02.05655\n",
      "91 91 RGI60-02.06179\n",
      "92 92 RGI60-02.06209\n",
      "93 93 RGI60-02.06431\n",
      "94 94 RGI60-02.06464\n",
      "95 95 RGI60-02.06467\n",
      "96 96 RGI60-02.06482\n",
      "97 97 RGI60-02.06486\n",
      "98 98 RGI60-02.06503\n",
      "99 99 RGI60-02.06607\n",
      "100 100 RGI60-02.06677\n",
      "101 101 RGI60-02.06682\n",
      "102 102 RGI60-02.06862\n"
     ]
    }
   ],
   "source": [
    "# ===== PROCESS EACH GLACIER =====\n",
    "for nglac, glac_idx in enumerate(main_glac_rgi_subset.index.values):\n",
    "# for nglac, glac_idx in enumerate([main_glac_rgi_subset.index.values[0]]):\n",
    "# for nglac, glac_idx in enumerate([main_glac_rgi_subset.index.values[120]]): # Miage\n",
    "# for nglac, glac_idx in enumerate([main_glac_rgi_subset.index.values[2307]]): # Ngozumpa\n",
    "\n",
    "    glac_str = main_glac_rgi_subset.loc[glac_idx,'rgino_str']\n",
    "    rgiid = main_glac_rgi_subset.loc[glac_idx,'RGIId']\n",
    "    region = glac_str.split('.')[0]\n",
    "\n",
    "    if int(region) < 10:\n",
    "        glac_str_noleadzero = str(int(glac_str.split('.')[0])) + '.' + glac_str.split('.')[1]\n",
    "    else:\n",
    "        glac_str_noleadzero = glac_str\n",
    "\n",
    "    if os.path.exists(debris_prms.hd_fp + debris_prms.hd_fn_sample.replace('XXXX',glac_str_noleadzero)) == False:\n",
    "\n",
    "        print(nglac, glac_idx, rgiid)\n",
    "\n",
    "        # Create glacier feature from ice thickness raster\n",
    "        thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "        thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "        gf = create_glacfeat(thick_dir, thick_fn)\n",
    "        \n",
    "        # Debris shape layer processing\n",
    "        dc_shp_proj_fn = (debris_prms.glac_shp_proj_fp + glac_str + '_dc_crs' + \n",
    "                          str(gf.aea_srs.GetAttrValue(\"AUTHORITY\", 1)) + '.shp')\n",
    "        if os.path.exists(dc_shp_proj_fn) == False:\n",
    "            dc_shp_init = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[debris_prms.roi])\n",
    "            dc_shp_single = dc_shp_init[dc_shp_init['RGIId'] == rgiid]\n",
    "            dc_shp_single = dc_shp_single.reset_index()\n",
    "            dc_shp_proj = dc_shp_single.to_crs({'init': 'epsg:' + str(gf.aea_srs.GetAttrValue(\"AUTHORITY\", 1))})\n",
    "            dc_shp_proj.to_file(dc_shp_proj_fn)\n",
    "        dc_shp_ds = ogr.Open(dc_shp_proj_fn, 0)\n",
    "        dc_shp_lyr = dc_shp_ds.GetLayer()\n",
    "        \n",
    "        \n",
    "        # ==== CHECK IF TIF HAS DHDT DATA OVER THE GLACIER =====\n",
    "        mb_fullfns = []\n",
    "        find_mb = True\n",
    "        dhdt_fn_wglacier = None\n",
    "        for mb_fp in debris_prms.mb_fp_list_roi[debris_prms.roi]:\n",
    "            if find_mb:\n",
    "                for i in os.listdir(mb_fp):\n",
    "                    if i.endswith('.tif'):\n",
    "                        mb_fullfns.append(mb_fp + i)\n",
    "                tif_count = 0\n",
    "                while find_mb and tif_count < len(mb_fullfns):\n",
    "                    dhdt_fn = mb_fullfns[tif_count]\n",
    "                    if debug:\n",
    "                        print(tif_count, dhdt_fn.split('/')[-1])\n",
    "                    \n",
    "                    # Add the filenames\n",
    "                    fn_dict = OrderedDict()\n",
    "                    # DEM\n",
    "                    z1_fp = debris_prms.oggm_fp + 'dems/RGI60-' + str(region.zfill(2)) + '/'\n",
    "                    z1_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_dem.tif'\n",
    "                    fn_dict['z1'] = z1_fp + z1_fn\n",
    "                    # Ice thickness\n",
    "                    thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "                    thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "                    fn_dict['ice_thick'] = thick_dir + thick_fn\n",
    "                    # dh/dt\n",
    "                    fn_dict['dhdt'] = dhdt_fn\n",
    "                    # ===== PROCESS THE DATA =====\n",
    "                    #Expand extent to include buffered region around glacier polygon\n",
    "                    warp_extent = geolib.pad_extent(gf.glac_geom_extent, width=debris_prms.buff_dist)\n",
    "                    #Warp everything to common res/extent/proj\n",
    "                    z1_gt = gdal.Open(fn_dict['z1']).GetGeoTransform()\n",
    "                    z1_res = np.min([z1_gt[1], -z1_gt[5]])\n",
    "                    ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, extent=warp_extent, \n",
    "                                                       t_srs=gf.aea_srs, verbose=False, r='cubic')\n",
    "                    ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "                    gf.ds_dict = ds_dict\n",
    "                    if 'z1' in ds_dict:\n",
    "                        #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "                        glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1'])\n",
    "                        gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "                        glac_geom_mask_copy = glac_geom_mask.copy()\n",
    "                        if 'dhdt' in ds_dict:\n",
    "                            gf.dhdt = np.ma.array(iolib.ds_getma(ds_dict['dhdt']), mask=glac_geom_mask_copy)\n",
    "                            gf.dhdt.mask = np.ma.mask_or(\n",
    "                                glac_geom_mask, np.ma.getmask(np.ma.masked_array(gf.dhdt.data, \n",
    "                                                                                 np.isnan(gf.dhdt.data))))\n",
    "                            # Count dhdt pixels\n",
    "                            dhdt_pixels = len(gf.dhdt.nonzero()[0])\n",
    "                            if dhdt_pixels / gf.z1.count() * 100 > 75:\n",
    "                                dhdt_fn_wglacier = dhdt_fn\n",
    "                                find_mb = False\n",
    "                                if debug:\n",
    "                                    print('\\n# z1 pixels:', gf.z1.count())\n",
    "                                    print('# dhdt_pixels:', dhdt_pixels)\n",
    "                                    var_full2plot = gf.dhdt.copy()\n",
    "                                    clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                                    plot_array(var_full2plot, clim, [glac_str + ' dhdt'], 'inferno', 'dhdt (m/yr)', \n",
    "                                               close_fig=False)\n",
    "                    # Loop over layers        \n",
    "                    tif_count += 1\n",
    "                    \n",
    "                    \n",
    "        # ==== CHECK IF TIF HAS VELOCITY DATA OVER THE GLACIER =====\n",
    "        vel_fullfns = []\n",
    "        find_vel = True\n",
    "        vel_fn_wglacier = None\n",
    "        if find_vel:\n",
    "            vx_fns = debris_prms.vx_dir_dict_list[debris_prms.roi]\n",
    "            tif_count = 0\n",
    "            while find_vel and tif_count < len(vx_fns):\n",
    "                vx_fn = vx_fns[tif_count]\n",
    "\n",
    "                if debug:\n",
    "                    print(tif_count, vx_fn.split('/')[-1])\n",
    "\n",
    "                # Add the filenames\n",
    "                fn_dict = OrderedDict()\n",
    "                # DEM\n",
    "                z1_fp = debris_prms.oggm_fp + 'dems/RGI60-' + str(region.zfill(2)) + '/'\n",
    "                z1_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_dem.tif'\n",
    "                fn_dict['z1'] = z1_fp + z1_fn\n",
    "                # Ice thickness\n",
    "                thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "                thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "                fn_dict['ice_thick'] = thick_dir + thick_fn\n",
    "                # Velocity\n",
    "                fn_dict['vx'] = vx_fn\n",
    "                fn_dict['vy'] = vx_fn.replace('_vx', '_vy')\n",
    "\n",
    "                # ===== PROCESS THE DATA =====\n",
    "                #Expand extent to include buffered region around glacier polygon\n",
    "                warp_extent = geolib.pad_extent(gf.glac_geom_extent, width=debris_prms.buff_dist)\n",
    "                #Warp everything to common res/extent/proj\n",
    "                z1_gt = gdal.Open(fn_dict['z1']).GetGeoTransform()\n",
    "                z1_res = np.min([z1_gt[1], -z1_gt[5]])\n",
    "                ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, extent=warp_extent, \n",
    "                                                   t_srs=gf.aea_srs, verbose=False, r='cubic')\n",
    "                ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "                gf.ds_dict = ds_dict\n",
    "                if 'z1' in ds_dict:\n",
    "                    #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "                    glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1'])\n",
    "                    gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "                    glac_geom_mask_copy = glac_geom_mask.copy()\n",
    "                    if 'vx' in ds_dict and 'vy' in ds_dict:\n",
    "                        #Load surface velocity maps\n",
    "                        gf.vx = np.ma.array(iolib.ds_getma(ds_dict['vx']), mask=glac_geom_mask)\n",
    "                        gf.vy = np.ma.array(iolib.ds_getma(ds_dict['vy']), mask=glac_geom_mask)\n",
    "                        gf.vm = np.ma.sqrt(gf.vx**2 + gf.vy**2)\n",
    "                        gf.vm_mean = gf.vm.mean()\n",
    "                        if debug:\n",
    "                            print('mean velocity [m/s]:', gf.vm_mean)\n",
    "                            \n",
    "                        # Count vel pixels\n",
    "                        vel_pixels = len(gf.vm.nonzero()[0])\n",
    "                        if vel_pixels / gf.z1.count() * 100 > 75:\n",
    "                            vx_fn_wglacier = vx_fn\n",
    "                            find_vel = False\n",
    "                            if debug:\n",
    "                                print('\\n# z1 pixels:', gf.z1.count())\n",
    "                                print('# dhdt_pixels:', vel_pixels)\n",
    "                                var_full2plot = gf.vm.copy()\n",
    "                                clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                                plot_array(var_full2plot, clim, [glac_str + ' velocity'], 'inferno', 'vm (m/yr)', \n",
    "                                           close_fig=False)\n",
    "                # Loop over layers        \n",
    "                tif_count += 1\n",
    "\n",
    "        \n",
    "        # ===== Add layers =====\n",
    "        if dhdt_fn_wglacier is not None and vx_fn_wglacier is not None:\n",
    "            gf.add_layers(dc_shp_lyr, gf_add_dhdt=True, dhdt_fn=dhdt_fn_wglacier, gf_add_vel=True, vx_fn=vx_fn_wglacier, \n",
    "                          gf_add_ts=False, gf_add_slope_aspect=True, gf_add_ts_info=False, calc_emergence=True, \n",
    "                          debug_emergence=False)\n",
    "\n",
    "            # ===== PLOTS =====\n",
    "#             plot_layers = True\n",
    "            plot_layers = False\n",
    "            if plot_layers:\n",
    "                # DEM\n",
    "                var_full2plot = gf.z1.copy()\n",
    "                clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                plot_array(var_full2plot, clim, [glac_str + ' DEM'], 'inferno', 'elev (masl)', close_fig=False)\n",
    "                # Elevation change\n",
    "                var_full2plot = gf.dhdt.copy()\n",
    "                clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                plot_array(var_full2plot, clim, [glac_str + ' dhdt'], 'inferno', 'dhdt (m/yr)', close_fig=False)\n",
    "                # Velocity\n",
    "                var_full2plot = gf.vm.copy()\n",
    "                clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                plot_array(var_full2plot, clim, [glac_str + ' velocity'], 'inferno', 'vel (m/yr)', close_fig=False)\n",
    "                # Emergence velocity\n",
    "                if gf.emvel is not None:\n",
    "                    var_full2plot = gf.emvel.copy()\n",
    "                    clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                    plot_array(var_full2plot, clim, [glac_str + ' emvel'], 'inferno', 'emvel (m/yr)', close_fig=False)\n",
    "                # Surface temperature\n",
    "                if gf.ts is not None:\n",
    "                    var_full2plot = gf.ts.copy()\n",
    "                    clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                    plot_array(var_full2plot, clim, [glac_str + ' Ts'], 'inferno', 'ts (degC)', close_fig=False)\n",
    "\n",
    "            # Bin data\n",
    "            outbins_df, z_bin_edges = gf.hist_plot(bin_width=debris_prms.mb_bin_size)\n",
    "            # Export binned data\n",
    "            if int(gf.feat_fn.split('.')[0]) < 10:\n",
    "                outbins_fullfn = os.path.join(outdir_csv, gf.feat_fn[0:7] + csv_ending)\n",
    "            else:\n",
    "                outbins_fullfn = os.path.join(outdir_csv, gf.feat_fn[0:8] + csv_ending)\n",
    "            outbins_df.loc[:,:] = np.nan_to_num(outbins_df.loc[:,:],0)\n",
    "            outbins_df.to_csv(outbins_fullfn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\nDONE!\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SHEAN ESTIMATE OF FLUX DIVERGENCE QUICKLY ======\n",
    "#                 if gf.H is not None:\n",
    "#                     #Compute flux\n",
    "#                     gf.Q = gf.H * debris_prms.v_col_f * np.array([gf.vx, gf.vy])\n",
    "#                     #Note: np.gradient returns derivatives relative to axis number, so (y, x) in this case\n",
    "#                     #Want x-derivative of x component\n",
    "#                     gf.divQ = np.gradient(gf.Q[0])[1] + np.gradient(gf.Q[1])[0]\n",
    "# #                     gf.divQ = gf.H*(np.gradient(v_col_f*gf.vx)[1] + np.gradient(v_col_f*gf.vy)[0]) \\\n",
    "# #                             + v_col_f*gf.vx*(np.gradient(gf.H)[1]) + v_col_f*gf.vy*(np.gradient(gf.H)[0])\n",
    "#                     #Should smooth divQ, better handling of data gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== OLD CHECK DEM FOR ERRORS AND REPLACE SCRIPT (no longer needed with OGGM processing) =====\n",
    "#         #Create buffer around glacier polygon\n",
    "#         glac_geom_buff = gf.glac_geom.Buffer(debris_prms.buff_dist)\n",
    "#         #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "#         glac_geom_buff_mask = geolib.geom2mask(glac_geom_buff, ds_dict['ice_thick'])\n",
    "        \n",
    "#             # ds masks\n",
    "#             ds_list_masked = [iolib.ds_getma(i) for i in ds_list]\n",
    "#             dem1 = np.ma.masked_less_equal(ds_list_masked[0], 0)\n",
    "#             dems_mask = dem1.mask\n",
    "#             if verbose:\n",
    "#                 print('list of datasets:', len(ds_list_masked), fn_dict.values())\n",
    "\n",
    "#             #Combine to identify ~1 km buffer around glacier polygon over static rock\n",
    "#             static_buffer_mask = np.ma.mask_or(~glac_shp_lyr_mask, glac_geom_buff_mask)\n",
    "#             static_shp_lyr_mask = np.ma.mask_or(static_buffer_mask, dems_mask)\n",
    "        \n",
    "        \n",
    "#             # Check if DEM has huge errors or not - replace if necessary\n",
    "#             if input.roi in ['01']:\n",
    "\n",
    "#                 gf.z1_check = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "#                 if gf.z1_check.min() < 0:\n",
    "\n",
    "#                     # Add backup DEM for regions with known poor quality (ex. Alaska)\n",
    "#                     print('switching DEMs')\n",
    "#                     fn_dict['z1_backup'] = input.z1_backup_dict[input.roi]\n",
    "#                     # Warp everything to common res/extent/proj (a second time)\n",
    "#                     ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, \\\n",
    "#                             extent=warp_extent, t_srs=aea_srs, verbose=verbose, \\\n",
    "#                             r='cubic')\n",
    "#                     ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "\n",
    "#                     if verbose:\n",
    "#                         print(ds_list)\n",
    "#                         print(fn_dict.keys())\n",
    "\n",
    "#                     # ds masks\n",
    "#                     ds_list_masked = [iolib.ds_getma(i) for i in ds_list]\n",
    "#                     dem1 = np.ma.masked_less_equal(ds_list_masked[-1], 0)\n",
    "#                     dems_mask = dem1.mask\n",
    "#                     if verbose:\n",
    "#                         print('list of datasets:', len(ds_list_masked), fn_dict.values())\n",
    "\n",
    "#                     #Combine to identify ~1 km buffer around glacier polygon over static rock\n",
    "#                     static_buffer_mask = np.ma.mask_or(~glac_shp_lyr_mask, glac_geom_buff_mask)\n",
    "#                     static_shp_lyr_mask = np.ma.mask_or(static_buffer_mask, dems_mask)\n",
    "\n",
    "#                     #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "#                     glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1_backup'])\n",
    "#                     gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1_backup']), mask=glac_geom_mask)\n",
    "#                     #gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "\n",
    "#                     # Debris cover\n",
    "#                     dc_mask = np.ma.mask_or(dc_shp_lyr_mask, glac_geom_mask)\n",
    "#                     gf.dc_area = np.ma.array(iolib.ds_getma(ds_dict['z1_backup']), mask=dc_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debris_thickness_global]",
   "language": "python",
   "name": "conda-env-debris_thickness_global-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
