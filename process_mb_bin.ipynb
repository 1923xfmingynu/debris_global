{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate a 3-panel plot for input arrays\n",
    "def plot_array(dem, clim=None, titles=None, cmap='inferno', label=None, overlay=None, fn=None, close_fig=True):\n",
    "    fig, ax = plt.subplots(1,1, sharex=True, sharey=True, figsize=(10,5))\n",
    "    alpha = 1.0\n",
    "    #Gray background\n",
    "    ax.set_facecolor('0.5')\n",
    "    #Force aspect ratio to match images\n",
    "    ax.set(aspect='equal')\n",
    "    #Turn off axes labels/ticks\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if titles is not None:\n",
    "        ax.set_title(titles[0])\n",
    "    #Plot background shaded relief map\n",
    "    if overlay is not None:\n",
    "        alpha = 0.7\n",
    "        ax.imshow(overlay, cmap='gray', clim=(1,255))\n",
    "    #Plot each array\n",
    "    im_list = [ax.imshow(dem, clim=clim, cmap=cmap, alpha=alpha)]\n",
    "    fig.tight_layout()\n",
    "    fig.colorbar(im_list[0], label=label, extend='both', shrink=0.5)\n",
    "    if fn is not None:\n",
    "        fig.savefig(fn, bbox_inches='tight', pad_inches=0, dpi=150)\n",
    "    if close_fig:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "Compute debris thickness through sub-debris and temperature inversion methods\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from scipy import ndimage\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import median_absolute_deviation\n",
    "import xarray as xr\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "from pygeotools.lib import malib, warplib, geolib, iolib, timelib\n",
    "\n",
    "\n",
    "import debrisglobal.globaldebris_input as debris_prms\n",
    "from debrisglobal.glacfeat import GlacFeat, create_glacfeat\n",
    "\n",
    "calc_emergence = True\n",
    "\n",
    "debug=False\n",
    "extra_layers=True\n",
    "\n",
    "csv_ending = '_mb_bins.csv'\n",
    "outdir_csv = debris_prms.mb_binned_fp\n",
    "if os.path.exists(outdir_csv) == False:\n",
    "    os.makedirs(outdir_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209 glaciers in region 16 are included in this model run: ['00080', '00141', '00163', '00173', '00176', '00177', '00205', '00213', '00214', '00216', '00228', '00244', '00248', '00256', '00261', '00274', '00285', '00287', '00288', '00289', '00299', '00331', '00332', '00337', '00360', '00361', '00362', '00363', '00366', '00368', '00370', '00372', '00373', '00410', '00413', '00417', '00427', '00428', '00433', '00485', '00486', '00493', '00496', '00500', '00516', '00540', '00543', '00560', '00566', '00582'] and more\n",
      "This study is focusing on 209 glaciers in region [16]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O1Index</th>\n",
       "      <th>RGIId</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>Zmax</th>\n",
       "      <th>Zmed</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Lmax</th>\n",
       "      <th>Form</th>\n",
       "      <th>TermType</th>\n",
       "      <th>Surging</th>\n",
       "      <th>RefDate</th>\n",
       "      <th>glacno</th>\n",
       "      <th>rgino_str</th>\n",
       "      <th>RGIId_float</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlacNo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>RGI60-16.00080</td>\n",
       "      <td>-70.8085</td>\n",
       "      <td>-15.59680</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.350</td>\n",
       "      <td>5015</td>\n",
       "      <td>5301</td>\n",
       "      <td>5130</td>\n",
       "      <td>11.0</td>\n",
       "      <td>166</td>\n",
       "      <td>1592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20019999</td>\n",
       "      <td>80</td>\n",
       "      <td>16.00080</td>\n",
       "      <td>16.00080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>RGI60-16.00141</td>\n",
       "      <td>-70.7501</td>\n",
       "      <td>-15.30790</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.558</td>\n",
       "      <td>4944</td>\n",
       "      <td>5343</td>\n",
       "      <td>5165</td>\n",
       "      <td>18.8</td>\n",
       "      <td>194</td>\n",
       "      <td>1426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20019999</td>\n",
       "      <td>141</td>\n",
       "      <td>16.00141</td>\n",
       "      <td>16.00141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162</td>\n",
       "      <td>RGI60-16.00163</td>\n",
       "      <td>-70.6962</td>\n",
       "      <td>-15.34450</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.305</td>\n",
       "      <td>4988</td>\n",
       "      <td>5283</td>\n",
       "      <td>5155</td>\n",
       "      <td>15.5</td>\n",
       "      <td>156</td>\n",
       "      <td>1456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20019999</td>\n",
       "      <td>163</td>\n",
       "      <td>16.00163</td>\n",
       "      <td>16.00163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172</td>\n",
       "      <td>RGI60-16.00173</td>\n",
       "      <td>-70.7102</td>\n",
       "      <td>-15.37590</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.115</td>\n",
       "      <td>4952</td>\n",
       "      <td>5370</td>\n",
       "      <td>5176</td>\n",
       "      <td>19.3</td>\n",
       "      <td>201</td>\n",
       "      <td>1376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20019999</td>\n",
       "      <td>173</td>\n",
       "      <td>16.00173</td>\n",
       "      <td>16.00173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175</td>\n",
       "      <td>RGI60-16.00176</td>\n",
       "      <td>-70.7199</td>\n",
       "      <td>-15.35290</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.546</td>\n",
       "      <td>4987</td>\n",
       "      <td>5380</td>\n",
       "      <td>5185</td>\n",
       "      <td>16.2</td>\n",
       "      <td>231</td>\n",
       "      <td>1583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20019999</td>\n",
       "      <td>176</td>\n",
       "      <td>16.00176</td>\n",
       "      <td>16.00176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2490</td>\n",
       "      <td>RGI60-16.02497</td>\n",
       "      <td>-77.6912</td>\n",
       "      <td>-8.90350</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3.398</td>\n",
       "      <td>4638</td>\n",
       "      <td>5888</td>\n",
       "      <td>5191</td>\n",
       "      <td>31.6</td>\n",
       "      <td>239</td>\n",
       "      <td>2942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20031018</td>\n",
       "      <td>2497</td>\n",
       "      <td>16.02497</td>\n",
       "      <td>16.02497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2511</td>\n",
       "      <td>RGI60-16.02518</td>\n",
       "      <td>-77.7162</td>\n",
       "      <td>-8.88227</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3.588</td>\n",
       "      <td>4637</td>\n",
       "      <td>6165</td>\n",
       "      <td>5196</td>\n",
       "      <td>33.4</td>\n",
       "      <td>259</td>\n",
       "      <td>2611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20031018</td>\n",
       "      <td>2518</td>\n",
       "      <td>16.02518</td>\n",
       "      <td>16.02518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2559</td>\n",
       "      <td>RGI60-16.02566</td>\n",
       "      <td>-77.6638</td>\n",
       "      <td>-8.89992</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.068</td>\n",
       "      <td>4639</td>\n",
       "      <td>5990</td>\n",
       "      <td>5143</td>\n",
       "      <td>36.2</td>\n",
       "      <td>184</td>\n",
       "      <td>3028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20031018</td>\n",
       "      <td>2566</td>\n",
       "      <td>16.02566</td>\n",
       "      <td>16.02566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2579</td>\n",
       "      <td>RGI60-16.02586</td>\n",
       "      <td>-77.6924</td>\n",
       "      <td>-8.79950</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2.136</td>\n",
       "      <td>4703</td>\n",
       "      <td>5202</td>\n",
       "      <td>4967</td>\n",
       "      <td>20.6</td>\n",
       "      <td>268</td>\n",
       "      <td>1618</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20031018</td>\n",
       "      <td>2586</td>\n",
       "      <td>16.02586</td>\n",
       "      <td>16.02586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2937</td>\n",
       "      <td>RGI60-16.02944</td>\n",
       "      <td>-78.4280</td>\n",
       "      <td>-0.68772</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>9.337</td>\n",
       "      <td>4536</td>\n",
       "      <td>5864</td>\n",
       "      <td>5080</td>\n",
       "      <td>26.3</td>\n",
       "      <td>109</td>\n",
       "      <td>2419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>19979999</td>\n",
       "      <td>2944</td>\n",
       "      <td>16.02944</td>\n",
       "      <td>16.02944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        O1Index           RGIId   CenLon    CenLat  O1Region  O2Region   Area  \\\n",
       "GlacNo                                                                          \n",
       "0            79  RGI60-16.00080 -70.8085 -15.59680        16         1  2.350   \n",
       "1           140  RGI60-16.00141 -70.7501 -15.30790        16         1  2.558   \n",
       "2           162  RGI60-16.00163 -70.6962 -15.34450        16         1  2.305   \n",
       "3           172  RGI60-16.00173 -70.7102 -15.37590        16         1  2.115   \n",
       "4           175  RGI60-16.00176 -70.7199 -15.35290        16         1  2.546   \n",
       "...         ...             ...      ...       ...       ...       ...    ...   \n",
       "204        2490  RGI60-16.02497 -77.6912  -8.90350        16         1  3.398   \n",
       "205        2511  RGI60-16.02518 -77.7162  -8.88227        16         1  3.588   \n",
       "206        2559  RGI60-16.02566 -77.6638  -8.89992        16         1  2.068   \n",
       "207        2579  RGI60-16.02586 -77.6924  -8.79950        16         1  2.136   \n",
       "208        2937  RGI60-16.02944 -78.4280  -0.68772        16         1  9.337   \n",
       "\n",
       "        Zmin  Zmax  Zmed  Slope  Aspect  Lmax  Form  TermType  Surging  \\\n",
       "GlacNo                                                                   \n",
       "0       5015  5301  5130   11.0     166  1592     0         0        9   \n",
       "1       4944  5343  5165   18.8     194  1426     0         0        9   \n",
       "2       4988  5283  5155   15.5     156  1456     0         0        9   \n",
       "3       4952  5370  5176   19.3     201  1376     0         0        9   \n",
       "4       4987  5380  5185   16.2     231  1583     0         0        9   \n",
       "...      ...   ...   ...    ...     ...   ...   ...       ...      ...   \n",
       "204     4638  5888  5191   31.6     239  2942     0         0        9   \n",
       "205     4637  6165  5196   33.4     259  2611     0         0        9   \n",
       "206     4639  5990  5143   36.2     184  3028     0         0        9   \n",
       "207     4703  5202  4967   20.6     268  1618     0         0        9   \n",
       "208     4536  5864  5080   26.3     109  2419     0         0        9   \n",
       "\n",
       "         RefDate  glacno rgino_str  RGIId_float  \n",
       "GlacNo                                           \n",
       "0       20019999      80  16.00080     16.00080  \n",
       "1       20019999     141  16.00141     16.00141  \n",
       "2       20019999     163  16.00163     16.00163  \n",
       "3       20019999     173  16.00173     16.00173  \n",
       "4       20019999     176  16.00176     16.00176  \n",
       "...          ...     ...       ...          ...  \n",
       "204     20031018    2497  16.02497     16.02497  \n",
       "205     20031018    2518  16.02518     16.02518  \n",
       "206     20031018    2566  16.02566     16.02566  \n",
       "207     20031018    2586  16.02586     16.02586  \n",
       "208     19979999    2944  16.02944     16.02944  \n",
       "\n",
       "[209 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debris cover extent shapefile with statistics\n",
    "dc_shp = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[debris_prms.roi])\n",
    "dc_shp = dc_shp.sort_values(by=['RGIId'])\n",
    "\n",
    "# Subset by percent debris-covered or debris-covered area\n",
    "dc_shp_subset = dc_shp[((dc_shp['DC_Area__1'] > debris_prms.dc_percarea_threshold) | \n",
    "                        (dc_shp['DC_Area_v2'] / 1e6 > debris_prms.dc_area_threshold))\n",
    "                        & (dc_shp['Area'] > debris_prms.min_glac_area)].copy()\n",
    "dc_shp_subset.reset_index(inplace=True, drop=True)\n",
    "dc_shp_subset['CenLon_360'] = dc_shp_subset['CenLon']\n",
    "dc_shp_subset.loc[dc_shp_subset['CenLon_360'] < 0, 'CenLon_360'] = (\n",
    "    360 + dc_shp_subset.loc[dc_shp_subset['CenLon_360'] < 0, 'CenLon_360'])\n",
    "# dc_shp_subset\n",
    "\n",
    "rgiid_list = [x.split('-')[1] for x in dc_shp_subset['RGIId'].values]\n",
    "main_glac_rgi_subset = debris_prms.selectglaciersrgitable(rgiid_list)\n",
    "main_glac_rgi_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(debris_prms.dhdt_vel_fns_fp) == False:\n",
    "    os.makedirs(debris_prms.dhdt_vel_fns_fp)\n",
    "dhdt_vel_fns_fn = debris_prms.dhdt_vel_fns_fn.replace('XXXX',debris_prms.roi)\n",
    "if os.path.exists(debris_prms.dhdt_vel_fns_fp + dhdt_vel_fns_fn):\n",
    "    dhdt_vel_fns_df = pd.read_csv(debris_prms.dhdt_vel_fns_fp + dhdt_vel_fns_fn)\n",
    "else:\n",
    "    dhdt_vel_fns_df = pd.DataFrame(np.zeros((main_glac_rgi_subset.shape[0], 3)),\n",
    "                                   columns=['RGIId', 'dhdt_fullfn', 'vel_fullfn'])\n",
    "    dhdt_vel_fns_df['RGIId'] = main_glac_rgi_subset['RGIId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(main_glac_rgi_subset.rgino_str == '11.03005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 RGI60-16.00080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 RGI60-16.00141\n",
      "2 2 RGI60-16.00163\n",
      "3 3 RGI60-16.00173\n",
      "4 4 RGI60-16.00176\n",
      "5 5 RGI60-16.00177\n",
      "6 6 RGI60-16.00205\n",
      "7 7 RGI60-16.00213\n",
      "8 8 RGI60-16.00214\n",
      "9 9 RGI60-16.00216\n",
      "10 10 RGI60-16.00228\n",
      "11 11 RGI60-16.00244\n",
      "12 12 RGI60-16.00248\n",
      "13 13 RGI60-16.00256\n",
      "14 14 RGI60-16.00261\n",
      "15 15 RGI60-16.00274\n",
      "16 16 RGI60-16.00285\n",
      "17 17 RGI60-16.00287\n",
      "18 18 RGI60-16.00288\n",
      "19 19 RGI60-16.00289\n",
      "20 20 RGI60-16.00299\n",
      "21 21 RGI60-16.00331\n",
      "22 22 RGI60-16.00332\n",
      "23 23 RGI60-16.00337\n",
      "24 24 RGI60-16.00360\n",
      "25 25 RGI60-16.00361\n",
      "26 26 RGI60-16.00362\n",
      "27 27 RGI60-16.00363\n",
      "28 28 RGI60-16.00366\n",
      "29 29 RGI60-16.00368\n",
      "30 30 RGI60-16.00370\n",
      "31 31 RGI60-16.00372\n",
      "32 32 RGI60-16.00373\n",
      "33 33 RGI60-16.00410\n",
      "34 34 RGI60-16.00413\n",
      "35 35 RGI60-16.00417\n",
      "36 36 RGI60-16.00427\n",
      "37 37 RGI60-16.00428\n",
      "38 38 RGI60-16.00433\n",
      "39 39 RGI60-16.00485\n",
      "40 40 RGI60-16.00486\n",
      "41 41 RGI60-16.00493\n",
      "42 42 RGI60-16.00496\n",
      "43 43 RGI60-16.00500\n",
      "44 44 RGI60-16.00516\n",
      "45 45 RGI60-16.00540\n",
      "46 46 RGI60-16.00543\n",
      "47 47 RGI60-16.00560\n",
      "48 48 RGI60-16.00566\n",
      "49 49 RGI60-16.00582\n",
      "50 50 RGI60-16.00591\n",
      "51 51 RGI60-16.00611\n",
      "52 52 RGI60-16.00630\n",
      "53 53 RGI60-16.00636\n",
      "54 54 RGI60-16.00667\n",
      "55 55 RGI60-16.00670\n",
      "56 56 RGI60-16.00672\n",
      "57 57 RGI60-16.00678\n",
      "58 58 RGI60-16.00712\n",
      "59 59 RGI60-16.00716\n",
      "60 60 RGI60-16.00717\n",
      "61 61 RGI60-16.00721\n",
      "62 62 RGI60-16.00729\n",
      "63 63 RGI60-16.00736\n",
      "64 64 RGI60-16.00747\n",
      "65 65 RGI60-16.00749\n",
      "66 66 RGI60-16.00751\n",
      "67 67 RGI60-16.00755\n",
      "68 68 RGI60-16.00776\n",
      "69 69 RGI60-16.00782\n",
      "70 70 RGI60-16.00784\n",
      "71 71 RGI60-16.00787\n",
      "72 72 RGI60-16.00788\n",
      "73 73 RGI60-16.00792\n",
      "74 74 RGI60-16.00793\n",
      "75 75 RGI60-16.00794\n",
      "76 76 RGI60-16.00799\n",
      "77 77 RGI60-16.00805\n",
      "78 78 RGI60-16.00807\n",
      "79 79 RGI60-16.00808\n",
      "80 80 RGI60-16.00812\n",
      "81 81 RGI60-16.00814\n",
      "82 82 RGI60-16.00815\n",
      "83 83 RGI60-16.00816\n",
      "84 84 RGI60-16.00827\n",
      "85 85 RGI60-16.00829\n",
      "86 86 RGI60-16.00846\n",
      "87 87 RGI60-16.00855\n",
      "88 88 RGI60-16.00856\n",
      "89 89 RGI60-16.00866\n",
      "90 90 RGI60-16.00869\n",
      "91 91 RGI60-16.00872\n",
      "92 92 RGI60-16.00881\n",
      "93 93 RGI60-16.00886\n",
      "94 94 RGI60-16.00891\n",
      "95 95 RGI60-16.00893\n",
      "96 96 RGI60-16.00894\n",
      "97 97 RGI60-16.00895\n",
      "98 98 RGI60-16.00896\n",
      "99 99 RGI60-16.00897\n",
      "100 100 RGI60-16.00898\n",
      "101 101 RGI60-16.00899\n",
      "102 102 RGI60-16.00903\n",
      "103 103 RGI60-16.00905\n",
      "104 104 RGI60-16.00906\n",
      "105 105 RGI60-16.00912\n",
      "106 106 RGI60-16.00913\n",
      "107 107 RGI60-16.00921\n",
      "108 108 RGI60-16.00926\n",
      "109 109 RGI60-16.00927\n",
      "110 110 RGI60-16.00929\n",
      "111 111 RGI60-16.00932\n",
      "112 112 RGI60-16.00933\n",
      "113 113 RGI60-16.00935\n",
      "114 114 RGI60-16.00936\n",
      "115 115 RGI60-16.00937\n",
      "116 116 RGI60-16.00938\n",
      "117 117 RGI60-16.00951\n",
      "118 118 RGI60-16.00979\n",
      "119 119 RGI60-16.00980\n",
      "120 120 RGI60-16.00982\n",
      "121 121 RGI60-16.00983\n",
      "122 122 RGI60-16.00984\n",
      "123 123 RGI60-16.00987\n",
      "124 124 RGI60-16.01014\n",
      "125 125 RGI60-16.01015\n",
      "126 126 RGI60-16.01018\n",
      "127 127 RGI60-16.01021\n",
      "128 128 RGI60-16.01040\n",
      "129 129 RGI60-16.01046\n",
      "130 130 RGI60-16.01048\n",
      "131 131 RGI60-16.01051\n",
      "132 132 RGI60-16.01052\n",
      "133 133 RGI60-16.01053\n",
      "134 134 RGI60-16.01054\n",
      "135 135 RGI60-16.01059\n",
      "136 136 RGI60-16.01061\n",
      "137 137 RGI60-16.01063\n",
      "138 138 RGI60-16.01071\n",
      "139 139 RGI60-16.01077\n",
      "140 140 RGI60-16.01078\n",
      "141 141 RGI60-16.01079\n",
      "142 142 RGI60-16.01084\n",
      "143 143 RGI60-16.01099\n",
      "144 144 RGI60-16.01103\n",
      "145 145 RGI60-16.01128\n",
      "146 146 RGI60-16.01132\n",
      "147 147 RGI60-16.01146\n",
      "148 148 RGI60-16.01150\n",
      "149 149 RGI60-16.01151\n",
      "150 150 RGI60-16.01159\n",
      "151 151 RGI60-16.01196\n",
      "152 152 RGI60-16.01199\n",
      "153 153 RGI60-16.01221\n",
      "154 154 RGI60-16.01228\n",
      "155 155 RGI60-16.01249\n",
      "156 156 RGI60-16.01251\n",
      "157 157 RGI60-16.01259\n",
      "158 158 RGI60-16.01264\n",
      "159 159 RGI60-16.01272\n",
      "160 160 RGI60-16.01273\n",
      "161 161 RGI60-16.01275\n",
      "162 162 RGI60-16.01282\n",
      "163 163 RGI60-16.01283\n",
      "164 164 RGI60-16.01286\n",
      "165 165 RGI60-16.01289\n",
      "166 166 RGI60-16.01292\n",
      "167 167 RGI60-16.01311\n",
      "168 168 RGI60-16.01312\n",
      "169 169 RGI60-16.01317\n",
      "170 170 RGI60-16.01336\n",
      "171 171 RGI60-16.01337\n",
      "172 172 RGI60-16.01339\n",
      "173 173 RGI60-16.01345\n",
      "174 174 RGI60-16.01346\n",
      "175 175 RGI60-16.01350\n",
      "176 176 RGI60-16.01355\n",
      "177 177 RGI60-16.01363\n",
      "178 178 RGI60-16.01383\n",
      "179 179 RGI60-16.01394\n",
      "180 180 RGI60-16.01419\n",
      "181 181 RGI60-16.01435\n",
      "182 182 RGI60-16.01442\n",
      "183 183 RGI60-16.01443\n",
      "184 184 RGI60-16.01838\n",
      "185 185 RGI60-16.01891\n",
      "186 186 RGI60-16.01909\n",
      "187 187 RGI60-16.01963\n",
      "188 188 RGI60-16.02137\n",
      "189 189 RGI60-16.02172\n",
      "190 190 RGI60-16.02260\n",
      "191 191 RGI60-16.02296\n",
      "192 192 RGI60-16.02306\n",
      "193 193 RGI60-16.02322\n",
      "194 194 RGI60-16.02348\n",
      "195 195 RGI60-16.02394\n",
      "196 196 RGI60-16.02410\n",
      "197 197 RGI60-16.02412\n",
      "198 198 RGI60-16.02420\n",
      "199 199 RGI60-16.02433\n",
      "200 200 RGI60-16.02457\n",
      "201 201 RGI60-16.02474\n",
      "202 202 RGI60-16.02482\n",
      "203 203 RGI60-16.02483\n",
      "204 204 RGI60-16.02497\n",
      "205 205 RGI60-16.02518\n",
      "206 206 RGI60-16.02566\n",
      "207 207 RGI60-16.02586\n",
      "208 208 RGI60-16.02944\n"
     ]
    }
   ],
   "source": [
    "# ===== PROCESS EACH GLACIER =====\n",
    "for nglac, glac_idx in enumerate(main_glac_rgi_subset.index.values):\n",
    "# for nglac, glac_idx in enumerate([main_glac_rgi_subset.index.values[0]]):\n",
    "# for nglac, glac_idx in enumerate([main_glac_rgi_subset.index.values[120]]): # Miage\n",
    "# for nglac, glac_idx in enumerate([main_glac_rgi_subset.index.values[2307]]): # Ngozumpa\n",
    "\n",
    "    glac_str = main_glac_rgi_subset.loc[glac_idx,'rgino_str']\n",
    "    rgiid = main_glac_rgi_subset.loc[glac_idx,'RGIId']\n",
    "    region = glac_str.split('.')[0]\n",
    "\n",
    "    if int(region) < 10:\n",
    "        glac_str_noleadzero = str(int(glac_str.split('.')[0])) + '.' + glac_str.split('.')[1]\n",
    "    else:\n",
    "        glac_str_noleadzero = glac_str\n",
    "\n",
    "    if os.path.exists(debris_prms.hd_fp + debris_prms.hd_fn_sample.replace('XXXX',glac_str_noleadzero)) == False:\n",
    "\n",
    "        print(nglac, glac_idx, rgiid)\n",
    "\n",
    "        # Create glacier feature from ice thickness raster\n",
    "        thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "        thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "        \n",
    "        if os.path.exists(thick_dir + thick_fn):\n",
    "        \n",
    "            gf = create_glacfeat(thick_dir, thick_fn)\n",
    "\n",
    "            # Debris shape layer processing\n",
    "            dc_shp_proj_fn = (debris_prms.glac_shp_proj_fp + glac_str + '_dc_crs' + \n",
    "                              str(gf.aea_srs.GetAttrValue(\"AUTHORITY\", 1)) + '.shp')\n",
    "            if os.path.exists(dc_shp_proj_fn) == False:\n",
    "                dc_shp_init = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[debris_prms.roi])\n",
    "                dc_shp_single = dc_shp_init[dc_shp_init['RGIId'] == rgiid]\n",
    "                dc_shp_single = dc_shp_single.reset_index()\n",
    "                dc_shp_proj = dc_shp_single.to_crs({'init': 'epsg:' + str(gf.aea_srs.GetAttrValue(\"AUTHORITY\", 1))})\n",
    "                dc_shp_proj.to_file(dc_shp_proj_fn)\n",
    "            dc_shp_ds = ogr.Open(dc_shp_proj_fn, 0)\n",
    "            dc_shp_lyr = dc_shp_ds.GetLayer()\n",
    "\n",
    "\n",
    "            # ==== CHECK IF TIF HAS DHDT DATA OVER THE GLACIER =====\n",
    "            mb_fullfns = []\n",
    "            find_mb = True\n",
    "            dhdt_fn_wglacier = None\n",
    "            for mb_fp in debris_prms.mb_fp_list_roi[debris_prms.roi]:\n",
    "                if find_mb:\n",
    "                    for i in os.listdir(mb_fp):\n",
    "                        if i.endswith('.tif'):\n",
    "                            mb_fullfns.append(mb_fp + i)\n",
    "                    tif_count = 0\n",
    "                    while find_mb and tif_count < len(mb_fullfns):\n",
    "                        dhdt_fn = mb_fullfns[tif_count]\n",
    "                        if debug:\n",
    "                            print(tif_count, dhdt_fn.split('/')[-1])\n",
    "\n",
    "                        # Add the filenames\n",
    "                        fn_dict = OrderedDict()\n",
    "                        # DEM\n",
    "                        z1_fp = debris_prms.oggm_fp + 'dems/RGI60-' + str(region.zfill(2)) + '/'\n",
    "                        z1_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_dem.tif'\n",
    "                        fn_dict['z1'] = z1_fp + z1_fn\n",
    "                        # Ice thickness\n",
    "                        thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "                        thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "                        fn_dict['ice_thick'] = thick_dir + thick_fn\n",
    "                        # dh/dt\n",
    "                        fn_dict['dhdt'] = dhdt_fn\n",
    "                        # ===== PROCESS THE DATA =====\n",
    "                        #Expand extent to include buffered region around glacier polygon\n",
    "                        warp_extent = geolib.pad_extent(gf.glac_geom_extent, width=debris_prms.buff_dist)\n",
    "                        #Warp everything to common res/extent/proj\n",
    "                        z1_gt = gdal.Open(fn_dict['z1']).GetGeoTransform()\n",
    "                        z1_res = np.min([z1_gt[1], -z1_gt[5]])\n",
    "                        ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, extent=warp_extent, \n",
    "                                                           t_srs=gf.aea_srs, verbose=False, r='cubic')\n",
    "                        ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "                        gf.ds_dict = ds_dict\n",
    "\n",
    "                        if 'z1' in ds_dict:\n",
    "                            #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "                            glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1'])\n",
    "                            glac_geom_mask_copy = glac_geom_mask.copy()\n",
    "                            gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "                            # Debris cover\n",
    "                            dc_shp_lyr_mask = geolib.lyr2mask(dc_shp_lyr, ds_dict['ice_thick'])\n",
    "                            gf.dc_mask = np.ma.mask_or(dc_shp_lyr_mask, glac_geom_mask)\n",
    "                            if 'dhdt' in ds_dict:\n",
    "                                gf.dhdt = np.ma.array(iolib.ds_getma(ds_dict['dhdt']), mask=glac_geom_mask_copy)\n",
    "                                gf.dhdt.mask = np.ma.mask_or(\n",
    "                                    glac_geom_mask, np.ma.getmask(np.ma.masked_array(gf.dhdt.data, \n",
    "                                                                                     np.isnan(gf.dhdt.data))))\n",
    "                                gf.dc_dhdt = np.ma.array(iolib.ds_getma(ds_dict['dhdt']), mask=glac_geom_mask_copy)\n",
    "                                gf.dc_dhdt.mask = gf.dc_mask\n",
    "                                gf.dc_area = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=gf.dc_mask)\n",
    "                                # Count dhdt pixels\n",
    "                                dc_dhdt_pixels = len(gf.dc_dhdt.nonzero()[0])\n",
    "                                if dc_dhdt_pixels / gf.dc_area.count() * 100 > 75:\n",
    "                                    dhdt_fn_wglacier = dhdt_fn\n",
    "                                    find_mb = False\n",
    "                                    if debug:\n",
    "                                        print('\\n# z1 dc pixels:', gf.dc_area.count())\n",
    "                                        print('# dc_dhdt_pixels:', dc_dhdt_pixels)\n",
    "                                        var_full2plot = gf.dhdt.copy()\n",
    "                                        clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                                        plot_array(var_full2plot, clim, [glac_str + ' dhdt'], 'inferno', 'dhdt (m/yr)', \n",
    "                                                   close_fig=False)\n",
    "                        # Loop over layers        \n",
    "                        tif_count += 1\n",
    "\n",
    "            # ==== CHECK IF VELOCITY DATA OVER THE GLACIER =====\n",
    "            vel_fullfns = []\n",
    "            find_vel = True\n",
    "            vx_fn_wglacier = None\n",
    "            if find_vel and dhdt_fn_wglacier is not None:\n",
    "                vx_fns = debris_prms.vx_dir_dict_list[debris_prms.roi]\n",
    "                tif_count = 0\n",
    "                while find_vel and tif_count < len(vx_fns):\n",
    "                    vx_fn = vx_fns[tif_count]\n",
    "\n",
    "                    if debug:\n",
    "                        print(tif_count, vx_fn.split('/')[-1])\n",
    "\n",
    "                    # Add the filenames\n",
    "                    # Velocity\n",
    "                    fn_dict['vx'] = vx_fn\n",
    "                    fn_dict['vy'] = vx_fn.replace('_vx', '_vy')\n",
    "                    # ===== PROCESS THE DATA =====\n",
    "                    ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, extent=warp_extent, \n",
    "                                                       t_srs=gf.aea_srs, verbose=False, r='cubic')\n",
    "                    ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "                    gf.ds_dict = ds_dict\n",
    "                    if 'vx' in ds_dict and 'vy' in ds_dict:\n",
    "                        #Load surface velocity maps\n",
    "                        gf.vx = np.ma.array(iolib.ds_getma(ds_dict['vx']), mask=glac_geom_mask)\n",
    "                        gf.vy = np.ma.array(iolib.ds_getma(ds_dict['vy']), mask=glac_geom_mask)\n",
    "                        gf.vm = np.ma.sqrt(gf.vx**2 + gf.vy**2)\n",
    "                        gf.dc_vm = gf.vm.copy()\n",
    "                        gf.dc_vm.mask = gf.dc_mask\n",
    "                        # Count velocity pixels\n",
    "                        dc_vel_pixels = len(gf.dc_vm.nonzero()[0])\n",
    "                        if debug:\n",
    "                                print('\\n# z1 dc pixels:', gf.dc_area.count())\n",
    "                                print('# dc vel_pixels:', dc_vel_pixels)\n",
    "                                var_full2plot = gf.vm.copy()\n",
    "                                clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                                plot_array(var_full2plot, clim, [glac_str + ' velocity'], 'inferno', 'vm (m/yr)', \n",
    "                                           close_fig=False)\n",
    "                        if dc_vel_pixels / gf.dc_area.count() * 100 > 75:\n",
    "                            vx_fn_wglacier = vx_fn\n",
    "                            find_vel = False\n",
    "\n",
    "                    # Loop over layers        \n",
    "                    tif_count += 1\n",
    "\n",
    "\n",
    "            # ===== Add layers =====\n",
    "            if dhdt_fn_wglacier is not None and vx_fn_wglacier is not None:\n",
    "                gf.add_layers(dc_shp_lyr, gf_add_dhdt=True, dhdt_fn=dhdt_fn_wglacier, gf_add_vel=True, vx_fn=vx_fn_wglacier, \n",
    "                              gf_add_ts=False, gf_add_slope_aspect=True, gf_add_ts_info=False, calc_emergence=True, \n",
    "                              debug_emergence=False)\n",
    "                # Save dhdt and vel filenames\n",
    "                dhdt_vel_fns_df.loc[glac_idx,:] = [rgiid, dhdt_fn_wglacier, vx_fn_wglacier]\n",
    "\n",
    "                # ===== PLOTS =====\n",
    "    #             plot_layers = True\n",
    "                plot_layers = False\n",
    "                if plot_layers:\n",
    "                    # DEM\n",
    "                    var_full2plot = gf.z1.copy()\n",
    "                    clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                    plot_array(var_full2plot, clim, [glac_str + ' DEM'], 'inferno', 'elev (masl)', close_fig=False)\n",
    "                    # Elevation change\n",
    "                    var_full2plot = gf.dhdt.copy()\n",
    "                    clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                    plot_array(var_full2plot, clim, [glac_str + ' dhdt'], 'inferno', 'dhdt (m/yr)', close_fig=False)\n",
    "                    # Velocity\n",
    "                    var_full2plot = gf.vm.copy()\n",
    "                    clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                    plot_array(var_full2plot, clim, [glac_str + ' velocity'], 'inferno', 'vel (m/yr)', close_fig=False)\n",
    "                    # Emergence velocity\n",
    "                    if gf.emvel is not None:\n",
    "                        var_full2plot = gf.emvel.copy()\n",
    "                        clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                        plot_array(var_full2plot, clim, [glac_str + ' emvel'], 'inferno', 'emvel (m/yr)', close_fig=False)\n",
    "                    # Surface temperature\n",
    "                    if gf.ts is not None:\n",
    "                        var_full2plot = gf.ts.copy()\n",
    "                        clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                        plot_array(var_full2plot, clim, [glac_str + ' Ts'], 'inferno', 'ts (degC)', close_fig=False)\n",
    "\n",
    "                # Bin data\n",
    "                outbins_df, z_bin_edges = gf.hist_plot(bin_width=debris_prms.mb_bin_size)\n",
    "                # Export binned data\n",
    "                if int(gf.feat_fn.split('.')[0]) < 10:\n",
    "                    outbins_fullfn = os.path.join(outdir_csv, gf.feat_fn[0:7] + csv_ending)\n",
    "                else:\n",
    "                    outbins_fullfn = os.path.join(outdir_csv, gf.feat_fn[0:8] + csv_ending)\n",
    "                outbins_df.loc[:,:] = np.nan_to_num(outbins_df.loc[:,:],0)\n",
    "                outbins_df.to_csv(outbins_fullfn, index=False)\n",
    "\n",
    "# Save updated filenames\n",
    "dhdt_vel_fns_df.to_csv(debris_prms.dhdt_vel_fns_fp + dhdt_vel_fns_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DONE!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\nDONE!\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SHEAN ESTIMATE OF FLUX DIVERGENCE QUICKLY ======\n",
    "#                 if gf.H is not None:\n",
    "#                     #Compute flux\n",
    "#                     gf.Q = gf.H * debris_prms.v_col_f * np.array([gf.vx, gf.vy])\n",
    "#                     #Note: np.gradient returns derivatives relative to axis number, so (y, x) in this case\n",
    "#                     #Want x-derivative of x component\n",
    "#                     gf.divQ = np.gradient(gf.Q[0])[1] + np.gradient(gf.Q[1])[0]\n",
    "# #                     gf.divQ = gf.H*(np.gradient(v_col_f*gf.vx)[1] + np.gradient(v_col_f*gf.vy)[0]) \\\n",
    "# #                             + v_col_f*gf.vx*(np.gradient(gf.H)[1]) + v_col_f*gf.vy*(np.gradient(gf.H)[0])\n",
    "#                     #Should smooth divQ, better handling of data gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== OLD CHECK DEM FOR ERRORS AND REPLACE SCRIPT (no longer needed with OGGM processing) =====\n",
    "#         #Create buffer around glacier polygon\n",
    "#         glac_geom_buff = gf.glac_geom.Buffer(debris_prms.buff_dist)\n",
    "#         #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "#         glac_geom_buff_mask = geolib.geom2mask(glac_geom_buff, ds_dict['ice_thick'])\n",
    "        \n",
    "#             # ds masks\n",
    "#             ds_list_masked = [iolib.ds_getma(i) for i in ds_list]\n",
    "#             dem1 = np.ma.masked_less_equal(ds_list_masked[0], 0)\n",
    "#             dems_mask = dem1.mask\n",
    "#             if verbose:\n",
    "#                 print('list of datasets:', len(ds_list_masked), fn_dict.values())\n",
    "\n",
    "#             #Combine to identify ~1 km buffer around glacier polygon over static rock\n",
    "#             static_buffer_mask = np.ma.mask_or(~glac_shp_lyr_mask, glac_geom_buff_mask)\n",
    "#             static_shp_lyr_mask = np.ma.mask_or(static_buffer_mask, dems_mask)\n",
    "        \n",
    "        \n",
    "#             # Check if DEM has huge errors or not - replace if necessary\n",
    "#             if input.roi in ['01']:\n",
    "\n",
    "#                 gf.z1_check = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "#                 if gf.z1_check.min() < 0:\n",
    "\n",
    "#                     # Add backup DEM for regions with known poor quality (ex. Alaska)\n",
    "#                     print('switching DEMs')\n",
    "#                     fn_dict['z1_backup'] = input.z1_backup_dict[input.roi]\n",
    "#                     # Warp everything to common res/extent/proj (a second time)\n",
    "#                     ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, \\\n",
    "#                             extent=warp_extent, t_srs=aea_srs, verbose=verbose, \\\n",
    "#                             r='cubic')\n",
    "#                     ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "\n",
    "#                     if verbose:\n",
    "#                         print(ds_list)\n",
    "#                         print(fn_dict.keys())\n",
    "\n",
    "#                     # ds masks\n",
    "#                     ds_list_masked = [iolib.ds_getma(i) for i in ds_list]\n",
    "#                     dem1 = np.ma.masked_less_equal(ds_list_masked[-1], 0)\n",
    "#                     dems_mask = dem1.mask\n",
    "#                     if verbose:\n",
    "#                         print('list of datasets:', len(ds_list_masked), fn_dict.values())\n",
    "\n",
    "#                     #Combine to identify ~1 km buffer around glacier polygon over static rock\n",
    "#                     static_buffer_mask = np.ma.mask_or(~glac_shp_lyr_mask, glac_geom_buff_mask)\n",
    "#                     static_shp_lyr_mask = np.ma.mask_or(static_buffer_mask, dems_mask)\n",
    "\n",
    "#                     #This is False over glacier polygon surface, True elsewhere - can be applied directly\n",
    "#                     glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1_backup'])\n",
    "#                     gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1_backup']), mask=glac_geom_mask)\n",
    "#                     #gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "\n",
    "#                     # Debris cover\n",
    "#                     dc_mask = np.ma.mask_or(dc_shp_lyr_mask, glac_geom_mask)\n",
    "#                     gf.dc_area = np.ma.array(iolib.ds_getma(ds_dict['z1_backup']), mask=dc_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debris_thickness_global]",
   "language": "python",
   "name": "conda-env-debris_thickness_global-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
